<!DOCTYPE html> <meta charset=utf-8  /> <meta name=viewport  content="width=device-width, initial-scale=1.0" /><meta name=generator  content="Docutils 0.17.1: http://docutils.sourceforge.net/" /> <meta name=viewport  content="width=device-width,initial-scale=1"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name="lang:clipboard.copy" content="Copy to clipboard"> <meta name="lang:clipboard.copied" content="Copied to clipboard"> <meta name="lang:search.language" content=en > <meta name="lang:search.pipeline.stopwords" content=True > <meta name="lang:search.pipeline.trimmer" content=True > <meta name="lang:search.result.none" content="No matching documents"> <meta name="lang:search.result.one" content="1 matching document"> <meta name="lang:search.result.other" content="# matching documents"> <meta name="lang:search.tokenizer" content="[\s\-]+"> <link href="https://fonts.gstatic.com/" rel=preconnect  crossorigin> <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel=stylesheet > <style> body, input { font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif } code, kbd, pre { font-family: "Roboto Mono", "Courier New", Courier, monospace } </style> <link rel=stylesheet  href="_static/stylesheets/application.css"/> <link rel=stylesheet  href="_static/stylesheets/application-palette.css"/> <link rel=stylesheet  href="_static/stylesheets/application-fixes.css"/> <link rel=stylesheet  href="_static/fonts/material-icons.css"/> <meta name=theme-color  content="#2196f3"> <script src="_static/javascripts/modernizr.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-151397036-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'UA-151397036-1'); </script> <title>Internal and External Validity &#8212; Unifying Data Science</title> <link rel=stylesheet  type="text/css" href="_static/pygments.css" /> <link rel=stylesheet  type="text/css" href="_static/material.css" /> <script data-url_root="./" id=documentation_options  src="_static/documentation_options.js"></script> <script src="_static/jquery.js"></script> <script src="_static/underscore.js"></script> <script src="_static/doctools.js"></script> <script crossorigin=anonymous  integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script> <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script> <script defer=defer  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <link rel="shortcut icon" href="_static/mids_logo.svg"/> <link rel=index  title=Index  href=genindex.html  /> <link rel=search  title=Search  href=search.html  /> <link rel=next  title="Evaluating Real Studies" href=evaluating_real_studies.html  /> <link rel=prev  title="Limitations of Experiments (and Average Treatment Effects)" href=limitations_of_ATE.html  /> <body dir=ltr data-md-color-primary=blue-grey data-md-color-accent=blue> <svg class=md-svg > <defs data-children-count=0 > <svg xmlns="http://www.w3.org/2000/svg" width=416  height=448  viewBox="0 0 416 448" id=__github ><path fill=currentColor  d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle  data-md-toggle=drawer  type=checkbox  id=__drawer > <input class=md-toggle  data-md-toggle=search  type=checkbox  id=__search > <label class=md-overlay  data-md-component=overlay  for=__drawer ></label> <a href="#internal_v_external_validity" tabindex=1  class=md-skip > Skip to content </a> <header class=md-header  data-md-component=header > <nav class="md-header-nav md-grid"> <div class="md-flex navheader"> <div class="md-flex__cell md-flex__cell--shrink"> <a href=index.html  title="Unifying Data Science" class="md-header-nav__button md-logo"> <img src="_static/mids_logo.svg" height=26  alt="Unifying Data Science logo"> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer ></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title > <span class=md-header-nav__topic >Unifying Data Science</span> <span class=md-header-nav__topic > Internal and External Validity </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search ></label> <div class=md-search  data-md-component=search  role=dialog > <label class=md-search__overlay  for=__search ></label> <div class=md-search__inner  role=search > <form class=md-search__form  action=search.html  method=get  name=search > <input type=text  class=md-search__input  name=q  placeholder=Search  autocapitalize=off  autocomplete=off  spellcheck=false  data-md-component=query  data-md-state=active > <label class="md-icon md-search__icon" for=__search ></label> <button type=reset  class="md-icon md-search__icon" data-md-component=reset  tabindex=-1 > &#xE5CD; </button> </form> <div class=md-search__output > <div class=md-search__scrollwrap  data-md-scrollfix> <div class=md-search-result  data-md-component=result > <div class=md-search-result__meta > Type to start searching </div> <ol class=md-search-result__list ></ol> </div> </div> </div> </div> </div> </div> <script src="_static/javascripts/version_dropdown.js"></script> <script> var json_loc = ""versions.json"", target_loc = "../", text = "Versions"; $( document ).ready( add_version_dropdown(json_loc, target_loc, text)); </script> </div> </nav> </header> <div class=md-container > <nav class=md-tabs  data-md-component=tabs > <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list > <li class=md-tabs__item ><a href=index.html  class=md-tabs__link >Home</a> <li class=md-tabs__item ><a href=class_schedule.html  class=md-tabs__link >Class Schedule</a> <li class=md-tabs__item ><a href=topic_list.html  class=md-tabs__link >Topic List</a> <li class=md-tabs__item ><a href="https://www.nickeubank.com" class=md-tabs__link >About The Author</a> </ul> </div> </nav> <main class=md-main > <div class="md-main__inner md-grid" data-md-component=container > <div class="md-sidebar md-sidebar--primary" data-md-component=navigation > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--primary" data-md-level=0 > <label class="md-nav__title md-nav__title--site" for=__drawer > <a href=index.html  title="Unifying Data Science" class="md-nav__button md-logo"> <img src="_static/mids_logo.svg" alt=" logo" width=48  height=48 > </a> <a href=index.html  title="Unifying Data Science">Unifying Data Science</a> </label> <ul class=md-nav__list > <li class=md-nav__item > <a href=class_schedule.html  class=md-nav__link >CLASS SCHEDULE</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Causal Inference</span></span> <li class=md-nav__item > <a href=limitations_of_ATE.html  class=md-nav__link >Limitations of ATE</a> <li class=md-nav__item > <input class="md-toggle md-nav__toggle" data-md-toggle=toc  type=checkbox  id=__toc > <label class="md-nav__link md-nav__link--active" for=__toc > Internal v. External Validity </label> <a href="#" class="md-nav__link md-nav__link--active">Internal v. External Validity</a> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title  for=__toc >Contents</label> <ul class=md-nav__list  data-md-scrollfix=""> <li class=md-nav__item ><a href="#internal-v-external-validity--page-root" class=md-nav__link >Internal and External Validity</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Internal-Validity" class=md-nav__link >Internal Validity</a> <li class=md-nav__item ><a href="#External-Validity" class=md-nav__link >External Validity</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#External-Validity-Considerations" class=md-nav__link >External Validity Considerations</a> </ul> </nav> <li class=md-nav__item ><a href="#Trade-Offs-Between-Internal-and-External-Validity" class=md-nav__link >Trade-Offs Between Internal and External Validity</a> <li class=md-nav__item ><a href="#Conclusion" class=md-nav__link >Conclusion</a> </ul> </nav> </ul> </nav> <li class=md-nav__item > <a href=evaluating_real_studies.html  class=md-nav__link >Evaluating A Real Study</a> <li class=md-nav__item > <a href=causal_inference_beyond_ab_testing.html  class=md-nav__link >Beyond AB Testing</a> <li class=md-nav__item > <a href=matching_why.html  class=md-nav__link >Matching (Why)</a> <li class=md-nav__item > <a href=matching_how.html  class=md-nav__link >Matching (How)</a> <li class=md-nav__item > <a href=interpreting_indicator_vars.html  class=md-nav__link >Indicator Variables</a> <li class=md-nav__item > <a href=fixed_effects.html  class=md-nav__link >Fixed Effects (FEs)</a> <li class=md-nav__item > <a href=fixed_effects_and_causal_inference.html  class=md-nav__link >FEs & Causality</a> <li class=md-nav__item > <a href=fixed_effects_v_hierarchical.html  class=md-nav__link >FEs & Hierarchical Models</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Data Science Project Design</span></span> <li class=md-nav__item > <a href=backwards_design.html  class=md-nav__link >Backwards Design</a> <li class=md-nav__item > <a href=taxonomy_of_questions.html  class=md-nav__link >Taxonomy of Questions</a> <li class=md-nav__item > <a href=moving_from_problems_to_questions.html  class=md-nav__link >From Problems to Questions</a> <li class=md-nav__item > <a href=descriptive_questions.html  class=md-nav__link >Discretion and Description</a> <li class=md-nav__item > <a href=ethical_ml_recommendations.html  class=md-nav__link >Ethical Machine Learning</a> <li class=md-nav__item > <a href=writing_to_stakeholders.html  class=md-nav__link >Writing for Lay Audiences</a> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--secondary"> <label class=md-nav__title  for=__toc >Contents</label> <ul class=md-nav__list  data-md-scrollfix=""> <li class=md-nav__item ><a href="#internal-v-external-validity--page-root" class=md-nav__link >Internal and External Validity</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Internal-Validity" class=md-nav__link >Internal Validity</a> <li class=md-nav__item ><a href="#External-Validity" class=md-nav__link >External Validity</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#External-Validity-Considerations" class=md-nav__link >External Validity Considerations</a> </ul> </nav> <li class=md-nav__item ><a href="#Trade-Offs-Between-Internal-and-External-Validity" class=md-nav__link >Trade-Offs Between Internal and External Validity</a> <li class=md-nav__item ><a href="#Conclusion" class=md-nav__link >Conclusion</a> </ul> </nav> </ul> </nav> </div> </div> </div> <div class=md-content > <article class="md-content__inner md-typeset" role=main > <section id=Internal-and-External-Validity > <h1 id=internal-v-external-validity--page-root >Internal and External Validity<a class=headerlink  href="#internal-v-external-validity--page-root" title="Permalink to this headline">¶</a></h1> <p>When evaluating any study, it is often helpful to think about two different types of study validity: internal and external.</p> <p>The <strong>internal validity</strong> of a study is the degree to which it has accurately interpreted its case. In the context of causal inference research, internal validity is about whether a study has accurately measured a causal effect <em>in the context being studied.</em> That is to say, how confident are we that the reported causal effect is the real causal effect <em>for the specific entities in the study</em>?</p> <p><strong>External validity</strong>, by constrast, is about whether we think the results of a given study are likely to generalize to other contexts.</p> <p>To illustrate the difference, suppose a new video streaming service sent out an e-mail offering new users a deal on subscriptions, and then measured the difference in sign-up rates between the users who got the deal and users who just got a generic e-mail with information about the service.</p> <p>The <strong>internal validity</strong> of the study is the degree to which the study accurately measured the causal effect of the offer on signup rates. Internal validity hinges on things we’ve talked about a lot in class, like whether the people who received the deal had the same potential outcomes as the people who got the generic email.</p> <p>The <strong>external validity</strong> of the study, by contrast, is about whether we think the estimated effect is the same effect we would see if we tried to send out a similar email to recruit customers to an <em>established</em> streaming service (instead of a new one), or if we tried to use a similar offer to recruit people to a new <em>music</em> streaming service.</p> <p>All studies are subject to both types of concerns, and as we’ll discuss below, there are often trade-offs between internal and external validity, especially in causal research.</p> <section id=Internal-Validity > <h2 id=Internal-Validity >Internal Validity<a class=headerlink  href="#Internal-Validity" title="Permalink to this headline">¶</a></h2> <p>As described above, internal validity is about whether we think a study has accurately interpreted the case it is studying. In the context of causal inference, this amounts to asking whether the study properly estimated the causal effect studied <em>for the set of entities it was focused on.</em></p> <p>Internal validity is about the concerns we’ve been focused on in this class so far, like whether our control and treatment groups have the same potential outcomes. As we will discuss again and again, the validity of <em>any</em> causal estimate depends on whether we believe a set of unverifiable assumptions are met. Evaluating whether those assumptions are met is a big part of evaluating the internal validity of a study.</p> <p>With that said, internal validity also rests on all sorts of more banal concerns, like whether the researchers actually measured their outcomes correctly, calculated the right standard errors, and chose a reasonable model specification.</p> <p>Internal validity is often the focus of causal inference textbooks and classes, and we’ll introduce even more conditions that have to be met for a study to have good internal validity as we continue (like SUTVA). But while internal validity is important, it’s not the <em>only</em> thing we care about, because there’s also…</p> </section> <section id=External-Validity > <h2 id=External-Validity >External Validity<a class=headerlink  href="#External-Validity" title="Permalink to this headline">¶</a></h2> <p>External validity is fundamentally about the <em>generalizability</em> of a study: whether the causal estimate found in a study is likely to also be a good guess for the causal effect in a different context.</p> <p>External validity is one of the most important things to think about as a <em>consumer</em> of other people’s research, because when you read other people’s research, you’re usually doing so because you’re looking for information you can use to address a specific problem you face. In these situations, it’s critical that you always ask yourself: are the results from this study likely to also be valid in the context of my problem?</p> <p>Of course, when asking about the external validity of a study, we have to specify the setting to which we want to generalize its results. A study that looks at how Duke undergraduates’ consumer behavior changes when faced with different types of ads on google may have good external validity in terms of its generalizability to other elite Univerities like Emory, Vanderbilt, or UNC. But it might not generalize to the US population as a whole.</p> <p>This means that external validity is different from internal validity in an important way: when faced with the same facts about a study, everyone should <em>generally</em> agree on the internal validity of a study, but the external validity of a study really depends on how you want to use the results.</p> <section id=External-Validity-Considerations > <h3 id=External-Validity-Considerations >External Validity Considerations<a class=headerlink  href="#External-Validity-Considerations" title="Permalink to this headline">¶</a></h3> <p>There are many reasons that the results of a study may not generalize to a new context. Here are a handful of the most common issues to bear in mind:</p> <p><strong>The study population may be different from the population in the new context.</strong></p> <p>Almost by definition, the entities in the new context will be different from the entities in the original study (even if we’re working with the same people, we’re looking at them at a different time). But the key question for external validity is whether the entities in the new context are different <em>in a way that would impact their response to a given treatment</em>.</p> <p>It’s not hard to think of reasons that different populations may respond differently to a given treatment. For example, suppose a company finds ads for luxury cars increase sales among rich people in New York. It’s hard to imagine that the same ad run in a poor neighborhood in Detroit would have the same effect.</p> <p>As you think about population differences, make sure you consider not only standard demographic attributes (age, gender, wealth, education), but also cultural or social differences. Many issues businesses deal with – especially advertising and brand image – may be culturally specific, and so may not generalize to all communities.</p> <p>This may all seem obvious as you read it, but using unrepresentative samples in research and medicine, then making recommendations for the general public is a huge problem in the real world.</p> <p>White men are massively over-represented in <a class="reference external" href="https://www.theatlantic.com/health/archive/2016/06/why-are-health-studies-so-white/487046/">medical trials</a>, for example. Unsurprisingly, this means that when the results of those trials are generalized to the population as a whole, we suddenly discover (SURPRISE) that the predicted results didn’t always hold for women or people of color! (e.g. <a class="reference external" href="https://www.theguardian.com/lifeandstyle/2015/apr/30/fda-clinical-trials-gender-gap-epa-nih-institute-of-medicine-cardiovascular-disease">drug doses set for men are often too high for women</a>; some heart drugs work great for White men, <a class="reference external" href="https://www.vice.com/en/article/mbjjnp/medical-studies-still-exclude-people-of-color">but often interact poorly with a gene common in Asians and Pacific Islanders; and Multiple sclerosis turns out to be drive by a different mutation in Black patients than European descendants</a>).</p> <p>And for the longest time, psychology research was based almost entirely on studies conducted using student volunteers. But of course, students at elite universities are not a representative population – they’re disproportionately Western, Educated, from Industrialized, Rich, and Democratic countries (they’re WEIRD). And as a result, our academic model of human behavior is really just a <a class="reference external" href="https://slate.com/technology/2013/05/weird-psychology-social-science-researchers-rely-too-much-on-western-college-students.html">model of a bunch of WEIRD kids</a>.</p> <p>Unrepresentative training data is also one of the reasons that so many machine learning algorithms are just plain racist (this isn’t causal inference, but it’s the same idea) – if you train a facial recognition algorithm using predominantly white faces, turns out that they will either <a class="reference external" href="http://www.cnn.com/2009/TECH/12/22/hp.webcams/index.html">not see Black faces</a>, or worse, mis-identify people of color (which is a <a class="reference external" href="https://www.wired.com/story/best-algorithms-struggle-recognize-black-faces-equally/">really bad thing when those algorithms are being used by the police</a>).</p> <p>So while internal validity issues may seem more sophisticated and thus interesting, don’t overlook the importance of these kinds of external validity issues!</p> <p><strong>The treatment might differ between study and new context</strong></p> <p>A study may declare that it has measured the effect of billboard ads on sales, or an infinite scroll on engagement. But it’s always important to remember that while we may interprete studies in these general terms, the reality is that that billboard study probably measured the effect <em>of a specific set of billboard ads</em> on sales, and the infinite scroll study looked at the effect of infinite scroll <em>in a specific app</em>.</p> <p>So always be careful to think about what <em>exactly</em> the treatment in a study was, and whether its likely to generalize to the case you study about.</p> <p><strong>There may be scaling effects</strong></p> <p>Often times when we’re thinking about external validity, we’re not just thinking re-using a treatment or intervention; we’re thinking about scaling them up.</p> <p>But an intervention that works on a few people / is only in place for a short period may not be a perfect model for what happens when that same intervention is applied at scale or permanently. For example, the returns to showing people a TV ad about your company for the first time is probably not the same as the returns to airing that ad the 1,000,000th time. Or sales from selling a special product at one store for a limited time may not be a good indicator of the sales you would see if your “special product” were available everywhere all the time.</p> <p>People may also respond differently to an intervention when it gets big or becomes permanent. To illustrate, I’d like to tell a story about a famous experiment in India (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2826809/">paper</a>).</p> <p>Rural health clinics in India have a huge problem: nurse absenteeism. To try and address the problem, in the late 2000s an NGO (along with some MIT economists) decided to see if they could fix the problem. The NGO started keeping track of when nurses clocked in and out, and then shared the information with the government, who then applied fines or punishments to nurses who weren’t showing up for work.</p> <p>Initially, the intervention was successful, leading to very large increases in attendance (doubling it in fact!) after a few months. But as nurses came to realize this wasn’t just a little study but actually something that was going to be around for a while, they mobilized politically, and soon administrators were allowing nurses to claim an increasing number of “exempt days”, avoiding punishment. And so sure enough, nurses stopped coming to work, and absenteeism had returned to pre-intervention levels 16 months after the program began.</p> <p>This is an example of what economists call a “general equilibrium” effect – when we introduce a treatment to the world, the world responds. But often these responses don’t happen in small trials the same way they do when policies go big, creating serious generalizability problems.</p> <p>Relatedly: if you are a public policy person or an economic development person, I cannot recommend <a class="reference external" href="https://www.nber.org/papers/w22595">this paper</a> by Angus Deaton and Nancy Cartwright enough for discussing the limitations of RCTs for learning about the effects of policy or nature of social processes. It’s a long, very thoughtful paper, but it’s really, <em>really</em> good.</p> </section> </section> <section id=Trade-Offs-Between-Internal-and-External-Validity > <h2 id=Trade-Offs-Between-Internal-and-External-Validity >Trade-Offs Between Internal and External Validity<a class=headerlink  href="#Trade-Offs-Between-Internal-and-External-Validity" title="Permalink to this headline">¶</a></h2> <p>OK, great. So let’s just maximize internal AND external validity whenever we’re doing research!</p> <p>The problem is that there is often a <strong>trade-off</strong> between internal and external validity. That’s because the best way to ensure internal validity is to try and control <em>everything you can</em> about the entities being studied, which often means doing things like bring people into a lab setting, or making an experiment quick so you can monitor people carefully. After all, the more control you have, the more sure you are that all the assumptions necessary for your design to generate a valid causal estimate are met.</p> <p>But… the more you try to control everything, the more artificial the environment you’re studying becomes, and (potentially) the less likely the results you see in the lab are to match what we’d see in the real world.</p> <p>We’ve actually already seen examples of this in our reading. As you may recall, in the first chapter of <em>Mastering ’Metrics</em>, we learned about two studies of the effects of having health insurance.</p> <p>The first was a study conducted by RAND in which participants were enrolled in different kinds of insurance. Everyone who was enrolled got at least catastrophic coverage, and then participants were enrolled in plans with different co-pay structures.</p> <p>The second was the Oregon Health Plan (OHP, the Oregon version of Medicaid). In the OHP study, a lottery was conducted to determine which applicants to Medicaid would actually be allowed to enroll (since they didn’t have the funds to enroll everyone who was eligible).</p> <p>On the one hand, the RAND study could probably be said to have better internal validity – everyone who enrolled got the insurance policy they were assigned. In the OHP program, by contrast, only about 25% of the people who won the lottery actually enrolled in OHP, meaning that the lottery winners who actually got insurance may have been different from the average person who won the lottery (something called “low compliance”, which we’ll talk about next week).</p> <p>But participants in the RAND study were much older, wealthier, and better educated than the average uninsured American. Moreover, to get people to enroll in their carefully conducted study, RAND had to give everyone in the study at least catastrophic coverage. That means the people in the study didn’t look like average Americans, and the control group wasn’t fully uninsured.</p> <p>In the OHP study, by contrast, the people in the study were <em>exactly</em> the population of people who are uninsured in the US, and the exact type of insurance they got was Medicaid.</p> <p>So in terms of internal validity, RAND was probably more successful; but in terms of external validity with respect to whether the results would generalize to expansion of government insurance in the US, many would argue that despite its internal validity problems, the OHP study is probably more informative.</p> <p>This tension between internal and external validity exists everywhere: bringing users into a lab allows researchers to study how users interact with different user interfaces with remarkable precision, and researchers can be sure participants are only using the interface their supposed to; but who knows if those same users would act differently if they were at home and their dog was barking and they were hurrying to answer an email from their boss?</p> </section> <section id=Conclusion > <h2 id=Conclusion >Conclusion<a class=headerlink  href="#Conclusion" title="Permalink to this headline">¶</a></h2> <p>Internal validity is really important, and understanding how to evaluate internal validity is hard because of the the challenges caused by the fundamental problem of causal inference.</p> <p>But remember that internal validity isn’t everything, and that when evaluating research, also think about <em>both</em> internal <em>and</em> external validity.</p> </section> </section> </article> </div> </div> </main> </div> <footer class=md-footer > <div class=md-footer-nav > <nav class="md-footer-nav__inner md-grid"> <a href=limitations_of_ATE.html  title="Limitations of Experiments (and Average Treatment Effects)" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel=prev > <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i> </div> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class=md-flex__ellipsis > <span class=md-footer-nav__direction > Previous </span> Limitations of Experiments (and Average Treatment Effects) </span> </div> </a> <a href=evaluating_real_studies.html  title="Evaluating Real Studies" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel=next > <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span class=md-flex__ellipsis > <span class=md-footer-nav__direction > Next </span> Evaluating Real Studies </span> </div> <div class="md-flex__cell md-flex__cell--shrink"><i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright > <div class=md-footer-copyright__highlight > &#169; Copyright 2022, Nick Eubank. </div> Created using <a href="http://www.sphinx-doc.org/">Sphinx</a> 4.5.0. and <a href="https://github.com/bashtage/sphinx-material/">Material for Sphinx</a> </div> </div> </div> </footer> <script src="_static/javascripts/application.js"></script> <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>