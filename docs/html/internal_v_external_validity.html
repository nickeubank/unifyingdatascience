
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Internal and External Validity &#8212; Unifying Data Science</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="Internal-and-External-Validity">
<h1>Internal and External Validity<a class="headerlink" href="#Internal-and-External-Validity" title="Permalink to this headline">¶</a></h1>
<p>When evaluating a study that makes a causal claim, it is often helpful to think about two different types of study validity: internal and external.</p>
<p>The <strong>internal validity</strong> of a study is the degree to which we think it has accurately interpreted its data. In the context of causal studies, internal validity is about whether a study has accurately measured a causal effect <em>in the context being studied.</em> That is to say, how confident are we that the reported causal effect is the real causal effect <em>for the specific entities in the study</em>?</p>
<p><strong>External validity</strong>, by constrast, is about whether we think the results of a given study are likely to generalize to other contexts.</p>
<p>To illustrate the difference, suppose a new video streaming service send out an e-mail offering new users a deal on subscriptions, and then measured the difference in sign-up rates between the users who got the deal and users who just got a generic e-mail with information about the service.</p>
<p>The <strong>internal validity</strong> of the study is the degree to which the study accurately measured the causal effect of the deal on signup rates among recipients. Internal validity hinges on things we’ve talked about a lot in class, like whether the people who received the deal had the same potential outcomes as the people who got the generic email.</p>
<p>The <strong>external validity</strong> of the study, by contrast, is about whether we think the estimated effect is the same effect we would expect if we tried to send out a similar email to recruit customers to an established streaming service (instead of a new one), or if we tried to send a similar email to recruit people to a new music streaming service instead of a video streaming service.</p>
<p>All causal studies are subject to both types of concerns, and as we’ll discuss below, there are often trade-offs between internal and external validity in causal research.</p>
<div class="section" id="Internal-Validity">
<h2>Internal Validity<a class="headerlink" href="#Internal-Validity" title="Permalink to this headline">¶</a></h2>
<p>As described above, internal validity is about whether we think a study has accurately interpreted the case it is studying. In the context of causal inference, this amounts to asking whether the study properly estimated the causal effect studied <em>for the set of entities</em> it was focused on.</p>
<p>Internal validity is mostly about the types of concerns we’ve been focused on in this class up till now, like whether our control and treatment groups have the same potential outcomes. As we will discuss again and again, the validity of <em>any</em> causal estimate depends on whether we believe a set of unverifiable assumptions are met, and evaluating whether those assumptions are met is a big part of evaluating the internal validity of a study.</p>
<p>With that said, internal validity can also include all sorts of more banal concerns, like whether the researchers actually measured their outcomes correctly, calculated the right standard errors, and chose a reasonable model specification.</p>
<p>Internal validity is often the focus of causal inference textbooks and classes, and we’ll introduce <em>even more</em> conditions that have to be met for a study to have good internal validity as we continue (like SUTVA). But while internal validity is important, it’s not the <em>only</em> thing we care about, because there’s also…</p>
</div>
<div class="section" id="External-Validity">
<h2>External Validity<a class="headerlink" href="#External-Validity" title="Permalink to this headline">¶</a></h2>
<p>External validity is fundamentally abou the <em>generalizability</em> of a study: whether the causal estimate found in a study is likely to also also be a good guess for the causal effect in a different context.</p>
<p>External validity is one of the most important things to think about as a <em>consumer</em> of other people’s research, because when you read other people’s research, you’re usually doing so because you’re looking for information you can use to address a specific problem you face. In these situations, it’s critical that you always ask yourself: do I think the results from this study are likely to also be valid in the context of my problem?</p>
<p>Of course, when asking about the external validity of a study, we have to specify the setting to which we want to generalize its results. A study that looks at how Duke undergraduates’ consumer behavior changes when faced with different types of ads on google may have good external validity in terms of its generalizability to other elite Univerities like Emory, Vanderbilt, or UNC, but it might not generalize to the US population as a whole.</p>
<p>This means that external validity is different from internal validity in an important way: when faced with the same facts about a study, everyone should (in theory) generally agree on the internal validity of a study, but the external validity of a study really depends on how you want to use the results.</p>
<div class="section" id="External-Validity-Considerations">
<h3>External Validity Considerations<a class="headerlink" href="#External-Validity-Considerations" title="Permalink to this headline">¶</a></h3>
<p>There are many reasons that the results of a study may not have a lot of external validity (e.g. they may not generalize) to a new context. Here are a handful of the most common issues to bear in mind:</p>
<p><strong>The study population may be different from the population in the new context.</strong></p>
<p>Almost by definition, the entities in the new context will be different from the entities in the original study (even if we’re working with the same units of observation, we’re looking at them at a different time, so things about those units may have changed). But the key question for external validity is whether the entities in the new context are different <em>in a way that would impact their response to a given treatment</em>.</p>
<p>It’s not hard to think about reasons that different populations may respond differently to treatments. For example, the fact that a company has found ads for luxury cars increased sales among rich people in New York doesn’t mean the same ad would impact luxury car sales if it were run in a poor neighborhood in Detroit.</p>
<p>As you think about population differences, make sure you consider not only standard demographic attributes (age, gender, wealth, education), but also cultural or social differences (e.g. a brand built on a specific type of sarcastic humor that works in San Franciso may not generalize to Tokyo).</p>
<p>This may seem obvious, but generalizing studies conducted with unrepresentative samples to bigger populations has historically been a HUGE problem. For the longest time, psychology research was based almost entirely on studies conducted using student volunteers. But of course, students at elite universities are not a representative population – they’re disproportionately Western, Educated, from Industrialized, Rich, and Democratic countries (they’re WEIRD). And as a result, our academic model of
human behavior is really just a <a class="reference external" href="https://slate.com/technology/2013/05/weird-psychology-social-science-researchers-rely-too-much-on-western-college-students.html">model of a bunch of WEIRD kids</a>.</p>
<p>Similar issues have <a class="reference external" href="https://www.theatlantic.com/health/archive/2016/06/why-are-health-studies-so-white/487046/">emerged in medical research</a> – medical trial participants are predominantly White men. Unsurprisingly, this means that when the results of those trials are generalized to the population as a whole, we suddenly discover (SURPRISE) that the predicted results didn’t always hold for women or people of color! (e.g. <a class="reference external" href="https://www.theguardian.com/lifeandstyle/2015/apr/30/fda-clinical-trials-gender-gap-epa-nih-institute-of-medicine-cardiovascular-disease">drug doses set for men are often too high for
women</a>; some heart drugs work great for White men, <a class="reference external" href="https://www.vice.com/en/article/mbjjnp/medical-studies-still-exclude-people-of-color">but often interact poorly with a gene common in Asians and Pacific Islanders; and Multiple sclerosis turns out to be drive by a different mutations in Black patients than European descendants</a>).</p>
<p>So while internal validity issues may seem more sophisticated and thus interesting, don’t overlook the importance of these kinds of external validity issues!</p>
<p><strong>The treatment might differ between study and new context</strong></p>
<p>A study may declare that it has measured the effect of billboard ads on sales, or an infinite scrolling page in an app on engagement. But it’s always important to remember that while we may interprete studies in these general terms, the reality is that that billboard study probably measured the effect <em>of a specific set of billboard ads</em> on sales, or an infinite scrolling page <em>in a specific app</em> on engagement. So always be careful to think about what <em>exactly</em> the treatment in a study was, and
whether its likely to generalize to the case you study about.</p>
<p><strong>There may be scaling effects</strong></p>
<p>Often times when we’re thinking about external validity, we have in mind not just applying a treatment from an experiment in a different setting, but also applying it at a different scale. For example, many small experiments are efforts to evaluate a policy intervention before it gets implemented for everyone.</p>
<p>But an intervention that works on a few people may not be a perfect model for what happens when that same intervention is applied to everyone. The returns to airing a TV ad to tell people about your company is probably not the same as the returns to airing that ad the 1,000,000th time.</p>
<p>People may also respond different to an intervention when it gets big. To illustrate, I’d like to tell a story about a famous experiment in India. Before I start, though, I want to be clear that it’s possible that this story is apocryphal – I heard it from a good source, but I have never found a published account of this, so it’s possible it’s just a story that’s spread. Nevertheless, I include it here because it’s precisely the <em>type</em> of concern a person should have when scaling an
intervention.</p>
<p>Rural schools in India have a huge problem: teacher absenteeism. Many suspected that teachers not showing up to school was hurting students, so they decided to put it to the test. They ran a randomized trial in which teachers were required to take a picture of themselves in class every day or they wouldn’t be paid their salary for the day. (<a class="reference external" href="https://www.povertyactionlab.org/media/file-research-paper/incentives-work-getting-teachers-come-school">The paper</a>).</p>
<p>Sure enough, this policy drove down teacher absenteeism by 21 percentage points, and test scores increased by 0.17 standard deviations (a reasonably large effect in the education literature).</p>
<p>So the school administrators scaled up the system to all schools in the district, docking teacher pay when teachers didn’t show up.</p>
<p>And what happened? The teachers union lobbied to create a set of reasons for “excused absenses”, and teachers started invoking those when not in class.</p>
<p>This is an example of what economists call a “general equilibrium” effect – when we introduce a treatment to the world, the world responds. But often these responses don’t happen in small trials the same way they do when policies go big, creating serious generalizability problems.</p>
<p>Relatedly: if you are a public policy person or an economic development person, I cannot recommend <a class="reference external" href="https://www.nber.org/papers/w22595">this paper</a> by Angus Deaton and Nancy Cartwright enough for discussing the limitations of RCTs for learning about the effects of policy or nature of social processes. It’s a long, very thoughtful paper, but it’s really, <em>really</em> good.</p>
</div>
</div>
<div class="section" id="Trade-Offs-Between-Internal-and-External-Validity">
<h2>Trade-Offs Between Internal and External Validity<a class="headerlink" href="#Trade-Offs-Between-Internal-and-External-Validity" title="Permalink to this headline">¶</a></h2>
<p>An important thing to bear in mind about internal and external validity is that there is often a trade-off between internal and external validity. That’s because the best way to ensure internal validity is to try and control <em>everything you can</em> about the entities being studied, which often means doing things like bring people into a lab setting, or making an experiment quick so you can monitor people carefully. After all, the more control you have, the more sure you are that all the assumptions
necessary for your design to generate a valid causal estimate are met.</p>
<p>But… the more you try to control everything, the more artificial the environment you’re studying becomes, and (potentially) the less likely the results you see in the lab are to match what we’d see in the real world.</p>
<p>We’ve actually already seen examples of this in our reading. As you may recall, in the first chapter of <em>Mastering ’Metrics</em>, we learned about two studies of the effects of having health insurance.</p>
<p>The first was a study conducted by RAND in which participants were enrolled in a set of different kinds of insurance. Everyone who was enrolled got at least catastrophic coverage, and then participants were enrolled in plans with different co-pay structures.</p>
<p>The second was the Oregon Health Plan (OHP, the Oregon version of Medicaid). In the OHP study, a lottery was conducted to determine which applicants to Medicaid would actually be allowed to enroll (since they didn’t have the funds to enroll everyone who was eligible).</p>
<p>On the one hand, the RAND study could probably be said to have better internal validity – everyone who enrolled got the insurance policy they were assigned. In the OHP program, by contrast, only about 25% of the people who won the lottery actually enrolled in OHP, meaning that they may have been different from the average person (something called “low compliance”, which we’ll talk about next week).</p>
<p>But participants in the RAND study were much older, wealthier, and better educated than the average uninsured American. Moreover, to get people to enroll in their carefully conducted study, RAND had to give everyone in the study at least catastrophic coverage. That means the control group wasn’t quite the same as the average uninsured American.</p>
<p>In the OHP study, by contrast, the people in the study were <em>exactly</em> the population of people who are uninsured in the US, and the exact type of insurance they got was Medicaid.</p>
<p>So in terms of internal validity, RAND was probably more successful; but in terms of external validity with respect to whether the results would generalize to expansion of government insurance in the US, many would argue that despite its problems, the OHP study is probably more informative.</p>
<p>This tension between internal and external validity exists everywhere: bringing users into a lab allows researchers to study how users interact with different user interfaces with remarkable precision, and researchers can be sure participants are only using the interface their supposed to; but who knows if those same users would act differently if they were at home and their dog was barking and they were hurrying to answer an email from their boss?</p>
</div>
<div class="section" id="Conclusion">
<h2>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this headline">¶</a></h2>
<p>Internal validity is really important, and understanding how to evaluate internal validity is hard because of the the challenges caused by the fundamental problem of causal inference.</p>
<p>But remember that internal validity isn’t everything, and that when evaluating research, also think about <em>both</em> internal <em>and</em> external validity.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Unifying DS</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="class_schedule.html">CLASS SCHEDULE</a></li>
</ul>
<p class="caption"><span class="caption-text">QUESTIONS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="taxonomy_of_questions.html">Taxonomy of Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="moving_from_problems_to_questions.html">From Problems to Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="descriptive_questions.html">Discretion and Description</a></li>
<li class="toctree-l1"><a class="reference internal" href="limitations_of_ATE.html">Limitations of Experiments</a></li>
</ul>
<p class="caption"><span class="caption-text">METHODS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="interpreting_indicator_vars.html">Indicator Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="fixed_effects.html">Fixed Effects</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Nick Eubank.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.4.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/internal_v_external_validity.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-151397036-1']);
      _gaq.push(['_setDomainName', 'none']);
      _gaq.push(['_setAllowLinker', true]);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    
  </body>
</html>