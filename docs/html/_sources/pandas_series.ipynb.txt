{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Lesson 1: Series\n",
    "\n",
    "This tutorial introduces the fundamental building block of `pandas`: `Series`. By the end of this section, you will learn how to create different types of Series, subset them, modify them, and summarize them.\n",
    "\n",
    "## 1. What is a Series?\n",
    "\n",
    "In the simpliest terms, a `Series` is an ordered collection of values, generally all of the same type. For example, you can have a Series that contains the ages of everyone in your class (a numeric Series), or a Series of all the names of people in your family (a string Series). \n",
    "\n",
    "This may sound familiar: isn't that how we described `numpy` vectors (i.e. one-dimensional numpy arrays)? Yes! In fact, Series are basically one-dimensional `numpy` arrays with lots of extra features added on top of them. As we'll see, most everything you could do with a `numpy` array you can do with a Series; Series can just do *more*. \n",
    "\n",
    "Series are central to `pandas` because `pandas` was designed for statistics, and Series are a perfect way to collect lots of different observations of a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of ways to create Series, but the easiest is to just pass a list or an array to the `pd.Series` constructor. \n",
    "\n",
    "To illustrate, let me tell you about a week at the zoo I wish I owned. Here's what attendance looked like at my zoo last week:\n",
    "\n",
    "| Day of Week | Attendees  |\n",
    "|-------------|------------|\n",
    "| Monday      | 132 people |\n",
    "| Tuesday     | 94 people  |\n",
    "| Wednesday   | 112 people |\n",
    "| Thursday    | 84 people  |\n",
    "| Friday      | 254 people |\n",
    "| Saturday    | 322 people |\n",
    "| Sunday      | 472 people |\n",
    "\n",
    "Let's make a Series for this attendance pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    132\n",
       "1     94\n",
       "2    112\n",
       "3     84\n",
       "4    254\n",
       "5    322\n",
       "6    472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # We have to import pandas to use Series!\n",
    "\n",
    "attendance = pd.Series([132, 94, 112, 84, 254, 322, 472])\n",
    "attendance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indices\n",
    "\n",
    "One of the fundamental differences between `numpy` arrays and Series is that all Series are associated with an `index`. An index is a set of labels for each observation in a Series. If you don't specify an `index` when you create a Series, `pandas` will just create a default index that just labels each row with it's initial row number, but you can specify an index if you want. \n",
    "\n",
    "In this case, for example, we know that these entries are associated with different days of the week, so let's specify an index for our `attendance` Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       132\n",
       "Tuesday       94\n",
       "Wednesday    112\n",
       "Thursday      84\n",
       "Friday       254\n",
       "Saturday     322\n",
       "Sunday       472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance = pd.Series([132, 94, 112, 84, 254, 322, 472],\n",
    "                       index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', \n",
    "                              'Friday', 'Saturday', 'Sunday'])\n",
    "attendance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we see the rows are labeled with days of the week on the left side, rather than with initial row numbers. \n",
    "\n",
    "Note that you can always access a Series' index with the `.index` property: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday',\n",
       "       'Sunday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important property of index labels is that they stay with each row, even if you sort your data. So if I sort my Series by attendance, not only will rows re-order, but so will the index labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thursday      84\n",
       "Tuesday       94\n",
       "Wednesday    112\n",
       "Monday       132\n",
       "Friday       254\n",
       "Saturday     322\n",
       "Sunday       472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance = attendance.sort_values()\n",
    "attendance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This seems intuitive with days-of-the-week as our index labels, but it can be confusing when your index starts out as row numbers. For example, if you had not changed our index to be days of the week, then the default index would look like the index labels were just row numbers. But if we then *sort* the Series, the numbers will shuffle, and they will no longer correspond to row numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    132\n",
       "1     94\n",
       "2    112\n",
       "3     84\n",
       "4    254\n",
       "5    322\n",
       "6    472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance = pd.Series([132, 94, 112, 84, 254, 322, 472])\n",
    "attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     84\n",
       "1     94\n",
       "2    112\n",
       "0    132\n",
       "4    254\n",
       "5    322\n",
       "6    472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance = attendance.sort_values()\n",
    "attendance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Subsetting Series\n",
    "\n",
    "Extracting a subset of elements from a Series is an extremely important task, not least because it generalizes nicely to working with bigger datasets (which are at the heart of data science). This process --- whether applied to a Series or a dataset --- is often referred to as \"taking a subset\", \"subsetting\", or \"filtering\". If there is one skill you need to master as quickly as possible, it's this.\n",
    "\n",
    "In `pandas`, there are three ways to filter a Series: using a separate logical Series, using row-number indexing, and using index labels. I tend to use the\n",
    "first method most, but all three are useful. The first and second of these you will recognize from `numpy` arrays, while the last once (since it uses index labels which only exist in `pandas`) is unique to `pandas`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting using row-number indexing\n",
    "\n",
    "A different way to subset a Series is to specify the row-numbers you want to keep using the `iloc` function. (`iloc` stands for \"integer location\", since row numbers are always integers). This will give you the behavior you're more familiar with from `R` or `numpy`. Just remember that, as in all of Python, the first row is numbered `0`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = pd.Series([\"apple\", \"banana\"])\n",
    "fruits.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also subset with lists of rows, or ranges, just like in `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    banana\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits.iloc[[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    banana\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits.iloc[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting using index values\n",
    "\n",
    "Lastly, we can subset our rows using the index values associated with each row using the `loc` function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance = pd.Series([132, 94, 112, 84, 254, 322, 472],\n",
    "                       index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', \n",
    "                              'Friday', 'Saturday', 'Sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance.loc[\"Monday\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also ask for ranges of index labels. Note that unlike in integer ranges (like the `0:2` we used above to get rows 0 and 1), index label ranges *include* the last item in the range. So for example if I ask for `.loc[\"Monday\":\"Friday\"]`, I will get Friday included, even if `.iloc[0:2]` doesn't include 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       132\n",
       "Tuesday       94\n",
       "Wednesday    112\n",
       "Thursday      84\n",
       "Friday       254\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance.loc[\"Monday\":\"Friday\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting with logicals \n",
    "\n",
    "Let's jump right into an example, using our Zoo attendance Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       132\n",
       "Tuesday       94\n",
       "Wednesday    112\n",
       "Thursday      84\n",
       "Friday       254\n",
       "Saturday     322\n",
       "Sunday       472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance = pd.Series([132, 94, 112, 84, 254, 322, 472],\n",
    "                       index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', \n",
    "                              'Friday', 'Saturday', 'Sunday'])\n",
    "attendance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to only get days with at least 100 people attending. We can subset our Series by using a simple test to build a Series of booleans (True and False values), then asking `pandas` for the rows of our Series for which the entry in our test Series is `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday        True\n",
       "Tuesday      False\n",
       "Wednesday     True\n",
       "Thursday     False\n",
       "Friday        True\n",
       "Saturday      True\n",
       "Sunday        True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "was_busy = attendance > 100\n",
    "was_busy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       132\n",
       "Wednesday    112\n",
       "Friday       254\n",
       "Saturday     322\n",
       "Sunday       472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "busy_days = attendance.loc[was_busy]\n",
    "busy_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one really important distinction between how subsetting works in `pandas` and most other languages though, which has to do with indices. Suppose we want to subset a Series with fruits to only get the entry \"apple\". Would could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    apple\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = pd.Series([\"apple\", \"banana\"])\n",
    "apple_selector = pd.Series([True, False])\n",
    "fruits.loc[apple_selector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks familiar from `numpy`, *but*: \n",
    "\n",
    "A very important difference between `pandas` and other languages and libraries (like `R` and `numpy`) is that when a logical Series is passed into `loc`, evaluation is done *not* on the basis of the order of entries, but on the basis of index values. In the case above, because we did not specify indices for either `fruits` or `apple_selector`, they both got the usual default index values of their initial row numbers. But let's see what happens if we change their indices so they don't match their order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    banana\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits # We can leave fruits as they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     True\n",
       "0    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_selector = pd.Series([True, False], index=[1, 0])\n",
    "apple_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've *flipped* the index order for `apple_selector`: the first row has index value 1, and the second row has value 2. Now watch what happens when we put `apple_selector` in square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    banana\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits.loc[apple_selector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get `banana`! That's because in `apple_selector`, the index value associated with the `True` entry as 1, and the row of `fruit` that had index value 1 was `banana`, even though they are in different rows. This is called `index alignment`, and is absolutely crucial to keep in mind while using `pandas`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But note this only happens *if* your boolean array is a Series (and thus has an index). If you pass a `numpy` boolean array or a list of booleans (neither of which have a concept of an index), then despite using `loc`, alignment will be based on row numbers not index values (because there *are* no index values to align). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    apple\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits.loc[[True, False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UGH** I know. If I wrote pandas, this would not work and this would throw an exception. But that's how it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this distinction between row numbers and index values is important, though, it comes up less often than you'd think. That's because usually we subset by feeding in a new Series of booleans we made by hand; instead we build a new Series by executing a test on the Series we're using. And when we do that, the new Series of booleans will have the same index as the old Series, so they align naturally. Look back at our example of `was_busy`: you'll see that it automatically got  the same index as our original Series, `attendance`. As a result, the first row of our boolean Series will have the same index value as the first row of our original Series, the second row of our boolean Series will have the same index value as the second row of our original Series, and so on. As a result, there's no difference between matching on row order and matching on index value. But it does *occassionally* come up (like if you tried to re-sort one of these), so keep it in mind!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Square Brackets (`[]`)\n",
    "\n",
    "As discussed above, because Series have both an order of rows, and labels for each row, you should always think carefully about which method of subsetting you are invoking. My advice: **Always using the `.loc` (for index labels) and `.iloc` (for row numbers) selectors. If you use these, the *only* surprising behavior to watch out for is that `loc` will align on row numbers if you pass a list or array of booleans with no index.** But since you *can't* align on an index in that case, there's no alternative behavior you would be expecting in that situation.\n",
    "\n",
    "However, there is another way to subset Series that is a little... stranger. In an effort to be easier for users, `pandas` allows subsetting using *just* square brackets (without a `.loc` or `.iloc`). With just square brackets, `pandas` will do different things depending on what you put in the square brackets. *In theory* this should always \"do what you want it to do\", but in my experience it's a recipe for errors. With that in mind, I don't suggest using it, but I will detail how it works here so you know. If this makes your head swim, just remember: **you can always use `loc` and `iloc`. Single square brackets do not offer any functionality you can't get with `.loc` or `.iloc`.**\n",
    "\n",
    "So, if you pass an index values into square brackets, `pandas` will subset based on index values (as though you were using `.loc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       132\n",
       "Tuesday       94\n",
       "Wednesday    112\n",
       "Thursday      84\n",
       "Friday       254\n",
       "Saturday     322\n",
       "Sunday       472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance['Sunday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if you pass booleans to square brackets, then `pandas` will behave like you are using `.loc` as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       132\n",
       "Wednesday    112\n",
       "Friday       254\n",
       "Saturday     322\n",
       "Sunday       472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance[attendance > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If it's not clear to you why `attendance[attendance > 100]` is a test with an index: Python first evaluates `attendance > 100`. That generates a new Series of booleans with the same index as `attendance`. Then Python evaluates the `attendance[]` part of the problem.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUT**: *if* your Series index is not integer based, *and* if you pass integers into the square brackets, it will act like you're using `iloc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Most* of the time, this works out. But you can get confused you are working with a Series that has a numeric index. If you pass an integer into `[]`, *and* you have an index of integers, then `[0]` will be treated like your typing `.loc[0]`, not `.iloc[0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     dog\n",
       "1     cat\n",
       "0    fish\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_w_numeric_index = pd.Series([\"dog\", \"cat\", \"fish\"], index=[2, 1, 0])\n",
    "series_w_numeric_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fish'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_w_numeric_index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So personally, I try to always use `loc` or `iloc` to avoid this kind of confusion. But if you do use `[]` on their own, just be very careful that you don't inadvertently select row based on index values when you think you're selecting on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Series\n",
    "\n",
    "Before we dive too far into Series manipulations, it's important to talk about datatypes. Every Series, as we will see, has a \"dtype\" (short for datatype). The `dtype` of a Series is important to understand because a Series' `dtype` determines what manipulations you can apply to that series. \n",
    "\n",
    "There are, broadly, two types of Series: \n",
    "\n",
    "- Numeric: these hold numbers that `pandas` understands are numbers. Specific numeric datatypes include things like `int64`, and `int32` (integers), or `float64` and `float32` (floating point numbers).\n",
    "- Object: these are Series that can hold any Python object, like strings, numbers, Sets, you name it. They have dtype `O` for \"objects\". They are flexible, but also very slow and actually harder to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric Series are by far the easiest to work with, and are generally either *integers* (`int64`, `int32`, etc.) or *floating point numbers* (`float64`, `float32`). We'll talk more about the differences between these data types later, but for the moment it's enough to know that *integer* Series (datatypes that start with `int`) can *only* hold... well, integers (whole numbers), while *floating point numbers* Series (datatypes that start with `float`) can hold integers, numbers with decimal points, and even missing values. \n",
    "\n",
    "The numbers at the end of these types (`64`, `32`, etc.) have to do with how many actual bits of data are allocated to each number, something we'll discuss later in the course. For the moment, the differences between them don't matter, and in general you'll likely always see (and should use) the `64` suffix.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the `dtype` of a Series by typing `.dtype`. For example, here are some different kinds of Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "s.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3.14])\n",
    "s.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, \"a string\"])\n",
    "s.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, integer (`int64`) Series can *only* hold integers. If we add one number with a decimal component, the whole thing becomes a `float64`. Similarly, floating point Series can only hold numbers. If we add a single String, the whole thing becomes an Object (`O`) type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting datatypes\n",
    "\n",
    "If you want to change the datatype of a Series, you can do so with the `.asdtype()` method... provided a conversion is possible! For example, you can always convert integer arrays to floating point Series because a whole number can be represented as a floating point number (just trust me on this for now... we'll discuss why later!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "s = s.astype('float64')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But be careful: since integers can't ever hold decimals, if you try and convert a floating point Series to an integer Series, it will just drop the decimal part of numbers with decimals! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3.14])\n",
    "s = s.astype('int64')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note Pandas is just doing the same thing regular python would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(3.14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if you try and convert an \"object\" Series to numeric and there are numbers that can't be converted, `pandas` will throw an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'a string'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c0312cc33b10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5689\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 5691\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m   5692\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 534\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'a string'"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, \"a string\"])\n",
    "s.astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Series Arithmetics\n",
    "\n",
    "One of the nice things about Series is that, like `numpy` arrays, we can easily do things like multiple *all* the values by another number easily. For example, suppose tickets to my zoo cost $15 per person. What is the total money generated by ticket sales each day? Let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       132\n",
       "Tuesday       94\n",
       "Wednesday    112\n",
       "Thursday      84\n",
       "Friday       254\n",
       "Saturday     322\n",
       "Sunday       472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance = pd.Series([132, 94, 112, 84, 254, 322, 472],\n",
    "                       index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', \n",
    "                              'Friday', 'Saturday', 'Sunday'])\n",
    "attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       1980\n",
       "Tuesday      1410\n",
       "Wednesday    1680\n",
       "Thursday     1260\n",
       "Friday       3810\n",
       "Saturday     4830\n",
       "Sunday       7080\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revenue = attendance * 15\n",
    "revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if we want to know to the total amount raised in a week, instead of just the amount on each day? We can use one of R's many helper functions -- in this case `sum` -- which adds up all the values of a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revenue.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! \n",
    "\n",
    "This is an example of one of the three forms of Series arithmetic:\n",
    "\n",
    "1. A Series with more than one element and a Series with only one element.\n",
    "2. A Series modified by a function. \n",
    "3. Two Series with the same number of elements. **When working with two Series, elements are matched based on index values, not row numbers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But note that the types of things you can do with a Series depends on the Series `dtype`. Math functions, for example, can only be applied to numeric datatypes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing with Functions \n",
    "\n",
    "We often want to get summary statistics from a Series --- that is, learn something general about it by looking beyond its constituent elements. If we have a Series in which each element represents a person's height, we may want to know who the shortest or tallest person is, what the median or mean height is, what the standard deviation is, etc. Here are common summary facts for numeric Series (some also work for object types):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "my_numbers = pd.Series([1, 2, 3, 4])\n",
    "\n",
    "my_numbers.dtype #check the dtype\n",
    "len(my_numbers) #number of elements \n",
    "my_numbers.max() #maximum value\n",
    "my_numbers.min() #minimum value\n",
    "my_numbers.sum() #sum of all values in the Series\n",
    "my_numbers.mean() #mean\n",
    "my_numbers.median() #median\n",
    "my_numbers.var() #variance\n",
    "my_numbers.std() #standard deviation\n",
    "my_numbers.quantile() #return specified quantile, 0.5 if none specified\n",
    "my_numbers.describe() #function that contains many summary stats from above\n",
    "my_numbers.value_counts() # Tabulate out all the values. Add the argument `normalize=True` to get shares in each big. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of those, two of the most powerful are `.describe()` (for numeric Series that take on lots of values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean      49.500000\n",
       "std       29.011492\n",
       "min        0.000000\n",
       "25%       24.750000\n",
       "50%       49.500000\n",
       "75%       74.250000\n",
       "max       99.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_numbers = pd.Series(range(100))\n",
    "my_numbers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and `.value_counts()` for numeric series with only a few unique values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2    4\n",
       " 1    3\n",
       "-1    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_numbers = pd.Series([1, 2, 2, 2, 2, 1, 1, -1, -1])\n",
    "my_numbers.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `.value_counts()` can be combined with the `normalize=True` argument to get the share of observations that have each unique value, rather than the count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2    0.444444\n",
       " 1    0.333333\n",
       "-1    0.222222\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_numbers.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modifying Series Elements\n",
    "\n",
    "The subsetting logic from above can be used to modify Series. The idea here is that instead of keeping elements that meet a logical\n",
    "condition or occur at a specific index, we can change them. For example, what if we had mis-entered attendance for our zoo? We can fix it using a logical test, row-number indexing (`iloc`), or by index-value (`loc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       132\n",
       "Tuesday       94\n",
       "Wednesday    112\n",
       "Thursday      84\n",
       "Friday       254\n",
       "Saturday     322\n",
       "Sunday       472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance = pd.Series([132, 94, 112, 84, 254, 322, 472],\n",
    "                       index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', \n",
    "                              'Friday', 'Saturday', 'Sunday'])\n",
    "attendance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! Turns out Tuesday attendance was 194, not 94! (It was a holiday). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit with a test:\n",
    "attendance[attendance == 94] = 194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit with `iloc`:\n",
    "attendance.iloc[1] = 194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit with `loc`:\n",
    "attendance.loc['Tuesday'] = 194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       132\n",
       "Tuesday      194\n",
       "Wednesday    112\n",
       "Thursday      84\n",
       "Friday       254\n",
       "Saturday     322\n",
       "Sunday       472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element Modification and DataTypes\n",
    "\n",
    "One of the big differences between Series and `numpy` arrays is that Series are \"dynamically typed\", meaning that if you have an integer Series and you try and add a number like 3.14 (which has a decimal component, and thus cannot be represented as a floating point number), `pandas` will just convert your whole array to floating point numbers so that it can hold 3.14. Similarly, if you try and add a string to a floating point array, `pandas` will just convert the whole array to an Object Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday       132.00\n",
       "Tuesday        3.14\n",
       "Wednesday    112.00\n",
       "Thursday      84.00\n",
       "Friday       254.00\n",
       "Saturday     322.00\n",
       "Sunday       472.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance.loc['Tuesday'] = 3.14\n",
    "attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday                                   132\n",
       "Tuesday      no one showed up on Tuesday! :(\n",
       "Wednesday                                112\n",
       "Thursday                                  84\n",
       "Friday                                   254\n",
       "Saturday                                 322\n",
       "Sunday                                   472\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance.loc['Tuesday'] = 'no one showed up on Tuesday! :('\n",
    "attendance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is different than `numpy`, where once an array has a type, it will only change types if you ask `numpy` to change the type explicitly. If you try and stick 3.14 into an integer array, it will just coerce the value 3.14 into an integer by dropping the decimal component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "my_array = np.array([1, 2, 3], dtype='int')\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_array[0] = 3.14\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you try and insert a string, you'll get an exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'first entry'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-39825a86f88a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'first entry'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'first entry'"
     ]
    }
   ],
   "source": [
    "my_array[0] = 'first entry'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. numpy Under The Hood\n",
    "\n",
    "As you may recall, at the start of this tutorial I recommended thinking of Series as augmented 1-dimensional `numpy` arrays. It turns out that's more than just a metaphor: behind every Series *is* a numpy array which you can access with the `.values` method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([132.0, 'no one showed up on Tuesday! :(', 112.0, 84.0, 254.0,\n",
       "       322.0, 472.0], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good to know because every now and then you my find a tool that works with `numpy` arrays but *not* `pandas`. And when that happens, you now know how to pull out the `numpy` array underlying your Series and use it directly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exercises!\n",
    "\n",
    "*If you are enrolled in Practical Data Science at Duke, don't do these exercises on your own -- we'll do them in class!*\n",
    "\n",
    "[Series Exercises](exercises/Exercise_series.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
