{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Languages: Why So Many?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R, Python, Stata, Matlab, Julia: there are a *lot* of languages people use for data science. So why are there so many, and which should you use?\n",
    "\n",
    "The truth is that there are pros and cons to each of these languages, and what is best for you will likely depend not only on what you want to do with the language, but also on factors like your prior experience, risk aversion, and what the people in you office (the easiest people to ask for help, and potential collaborators) already use. \n",
    "\n",
    "### Stata\n",
    "\n",
    "*Note: First thing to keep in mind about Stata: unlike R, Python and Julia, it is **not** free!*\n",
    "\n",
    "Stata is one of the most popular tools among applied economists, and for good reason. It is an extremely powerful tool for data manipulation and econometric analysis. Its syntax is simpler than that of R, has lots of in-built statistical tools, lots of good add-ones, is very good for data-cleaning, and has a strong support community (the [statalist community](http://www.statalist.org/forums/help) can solve almost any problem you have). \n",
    "\n",
    "Basically, Stata was designed specifically for doing statistical analysises of *tabular data*. Tabular data is data that looks like a spreadsheet where each row is an observation and each column is a different variable. And because of this focus, it has a syntax that is very specialized for this purpose (and thus much simpler and easier to read than, say, R), and *tons* of inbuilt tools for statistics. But this focus does come at a bit of a cost. In particular:\n",
    "\n",
    "- It doesn't really work for anything *BUT* tabular data manipulations and statistical, so it's not a good choice if your interest is in spatial analyses, network analysis, or text analysis.\n",
    "- Stata's programming language is easy to read and work with, but it's also a little unusual. As a result, people with programming experience tend to hate it, and learning to code in Stata doesn't do a great job of setting you up for working in another language in the future. \n",
    "\n",
    "But if you just want to do econometrics, and don't have a lot of programming background, Stata is hard to beat!\n",
    "\n",
    "\n",
    "### R\n",
    "\n",
    "R was the first data science programming language, and in many circles (like the social sciences outside of economics) it is by far the dominant choice. \n",
    "\n",
    "R's biggest asset is the huge library of tools (\"packages\") that have been written by users and published online over the years to add new functionalities to R. There are packages for econometric analysis, geospatial analysis, network analysis, textual analysis, etc.\n",
    "\n",
    "But R's flexibility also comes at a cost -- its scope can be overwhelming, and the language is not the most intuitive or accessible for people without a background in programming. It's syntax (the rules of the programming language) are also rather quirky, and have driven many a programmer crazy. \n",
    "\n",
    "The reason is that the creator of R had the goal of creating a language that was easy for non-programmers to start using, but which would allow people who wanted to use more sophisticated functionality to dive deeper into the language. As a result, it's fundamentally a compromise language, designed to offer much of the flexibility of a full programming language while being more accessible to non-programmers and those just getting started. This compromise is both R's greatest strength and weakness -- Stata users often complain that the syntax is more complex than a simple language should be, while those used to full programming languages (like Python) don't like some of the compromises the language has made in favor of accessibility. \n",
    "\n",
    "This compromise has also lead to variability in the quality of packages available for R. Because anyone can easily write and publish a package for R, there is a huge world of good libraries to choose from, but it is also the case that some libraries are poorly written -- making them a little hard to figure out -- and some are just wrong. Make sure to check with someone more familiar with R for their impressions of a given library before using it in your analysis. \n",
    "\n",
    "R also has issues with performance. As dicussed in [Speed](performance.ipynb), this doesn't really come up if you're using a core library (which was actually written in a really fast language like C or C++). But if you want to write *custom* code that does things that a good, high performance, off-the-shelf library doesn't already do, code you write yourself in R is likely to be painfully slow. \n",
    "\n",
    "Moreover, R also has a reputation for not being very memory efficient, which means that if you're working with big datasets, R may also not be your best choice. \n",
    "\n",
    "\n",
    "### Python\n",
    "\n",
    "Python was invented in the early 1990s to be a light, friendly, general purpose programming language. However, programmers found it so intuitive and easy to use, it quickly moved from being a tool for doing little jobs quickly into one of the dominant programming languages in the world. Dropbox, for example, is written in Python. And indeed, most Python programmers aren't data scientists, they're software developers or web developers. But in the last decade or so, Python has taken off in popularity for data science, and is currently the dominant language choice among natural scientists and computer scientists doing data science. \n",
    "\n",
    "Because of this centrality in any number of fields, almost anything you can imagine can be accessed through Python -- it integrates easily with tools like ArcGIS, other geospatial tools, network analysis tools, webscrapers, text analysis libraries, etc. \n",
    "\n",
    "The main downside to data science in Python is that the language wasn't initially developed with data science in mind, so to make it a good data science tool, two libraries were invented to expand it's capabilities: `numpy` and `pandas`. Before `numpy`, Python didn't have vectors, matrices, or arrays, and was relatively slow when doing numerical work. `numpy` provides those functionalities. But `numpy` didn't handle \"heterogeneous tabular data\", meaning data that looks like a spreadsheet where one column might be strings (like people's names) and another column is numeric (say, those people's incomes). So `pandas` was developed on top of `numpy` to make that possible. As a result, you can now do most anything in Python (though statisticians still like R and Stata more, so the statistical libraries are a little better in those libraries), but it almost requires learning three languages: base Python, numpy, and then pandas. That's not actually as bad as learning three languages (they *try* to have a consistent logic), but it's definitely more complicated than something like R. With that said, learning Python will give you *very* generalizable programming skills since it's a full general purpose language.\n",
    "\n",
    "One last note: If you're working with really large datasets, want to connect to cloud services, need performance, or want to use something like Hadoop or Spark (don't worry if you don't know what those are), Python *crushes* R for flexibility and performance.\n",
    "\n",
    "### Julia\n",
    "\n",
    "Julia is the new kid on the block. Though it was in development and use by risk-loving developers for many years, version 1.0 was only released in 2018. This is both it's strength and it's weakness. \n",
    "\n",
    "The advantage of being a really new language is that Julia has taken advantage of all sorts of modern technologies behind the scenes to develop a language that is basically as easy to use as R or Python (the syntax is a lot like basic Python, but it has matrices and vectors built in so no need to deal with extra layers like numpy and pandas in Python), but is *extremely* fast. Like... [tens or hundreds of times faster](https://julialang.org/benchmarks/) than custom functions you might write in R and Python. Moreover, it's built for the modern era, so things like parallel processing is easy, graphics are integrated, and it has learned from (and stolen the best features of) older languages like Python, R, and Matlab. \n",
    "\n",
    "Julia was also built for the sole purpose of doing *scientific computing* --- the computer science term for statistics, numerical simulation, data analysis, etc. So everything was designed with data science in mind. \n",
    "\n",
    "The *downside* of being new is that while the core language is amazing, and there are lots of libraries already available (for example, statisticians love Julia, so there are lots of tools for statistical simulations and such), it does not have the full compliment currently available in a language like R or Python. Uptake of Julia has been fast, so that will change, but if you need specific functionalities, it's best to look around to see what's been developed before jumping in.\n",
    "\n",
    "Julia also has one really important advantage over other libraries. When working in R and Python, *most* of the time the tools you're using weren't actually written in R or Python; it was written in C or C++. You are just able to *access* those tools in R or Python. This is great in that it allows you to get the speed benefits of C without having to program in C (C is *awful*) so long as you're using a standard library. But the downside is that if you ever want to see how a tool you're using works, or want to modify the tool you're writing, when you go look for the code it'll be in a language that you can't read, nevermind modify. \n",
    "\n",
    "Julia is different. While you can use C libraries in Julia, Julia is so fast that the entire language is written... in Julia. And so are most packages. It's Julia all the way down. And that means that if you want to see how a tool you're using works, or tweak it for your specific application, you'll find you understand the code your tools were written in. If you're happy just using pre-packaged libraries, this may not matter to you; but if you're a researcher or someone who sometimes needs to do things that may not already be possible in an existing library, it's *incredibly* nice. \n",
    "\n",
    "(If you want to know more about Julia, you can find a talk I have in mid-2018 on the value of the language for researchers [here](https://www.youtube.com/watch?v=C4dMYHzW-SY)!)\n",
    "\n",
    "\n",
    "\n",
    "## Considerations for Picking a Language \n",
    "\n",
    "When choosing a software environment / language to use for you statistical work, there are a number of important considerations to take into account. Here are a few:\n",
    "\n",
    "**What do the people around you use?**\n",
    "\n",
    "You will inevitably run into problems working with a new language, and your best resource will likely be the people around you. Before picking a language, ask around to see what your friends and colleagues use. For example, development economists mostly use Stata; political scientists mostly use R; serious econometricians in some departments use Matlab.\n",
    "\n",
    "**What do you need to do?**\n",
    "\n",
    "Different environments have strengths in different areas. For example, if you just want to do data manipulation and standard regressions, Stata really shines. If you also want to do network analysis, you may want to consider R or Python, which have network analysis packages. \n",
    "\n",
    "**Mix and match?**\n",
    "\n",
    "Many people use a mix of environments for their projects. For example, one might do their data cleaning and organization in Stata, then move into R to run a statistical model that isn't support in Stata. This allows the user to use the program that is strongest for each task, but this strategy requires (a) learning multiple languages, and (b) keeping track of how you're moving data back and forth between programs, both of which introduce a lot of costs. With that in mind, I would recommend trying to limit this behavior. \n",
    "\n",
    "**How much data do you have? **\n",
    "\n",
    "Most of the environments / languages discussed on this page are for manipulating data that fits comfortably into RAM. If you have a data set that's quite large (more than 1/2 the amount of RAM you have on your computer), please read the page on [[Big Data]]\n",
    "\n",
    "\n",
    "## Example Code from Each Language\n",
    "\n",
    "You can get a feel for different environments pretty quickly by looking at example code, although as with any language keep in mind that some things that may seem bizarre or foreign at first can become intuitive with some practice. Here, are code snippets for each language to: open a dataset from a file; create a new variable using existing variables; recode a variable; run a basic OLS regression, and run a slightly more complicated OLS regression. Since presumably you are reading this because you don't yet know these languages, don't worry too much if not everything makes sense -- these snippets are just provided to give you a glimpse of what the languages look like and how readable they are. Comments are included to explain a little of each step. \n",
    "\n",
    "```\n",
    "    * Open a dataset from a file: \n",
    "    use myDataFile.dta\n",
    "    \n",
    "    * Create new variable called age_squared equal to each person's age squared: \n",
    "    generate age_squared = age*age\n",
    "    \n",
    "    * Set variable youngMan values to 1 if male and under 25: \n",
    "    replace youngMan = 1 if gender == \"male\" & age < 25\n",
    "        \n",
    "    * Rename a variable from myVariable to myRenamedVariable: \n",
    "    rename myVariable myRenamedVariable\n",
    "        \n",
    "    * Run an OLS regression of income on age and height:\n",
    "    regress income age height\n",
    "     \n",
    "   * Run an OLS regression of income and age and a categorical variable for level of education for men:\n",
    "    xi: regress income age i.education if gender == \"male\"\n",
    "```\n",
    "\n",
    "A few examples of R commands:\n",
    "\n",
    "```R\n",
    "    # Open a dataset from the file myfile.RData and name it myData: \n",
    "    myData <- load(\"myfile.RData\") \n",
    "    \n",
    "    # Create new variable called age_squared equal to each person's age squared: \n",
    "    myData$agesquared <- myData$age * myData$age \n",
    "    \n",
    "    # Set variable youngMan values to 1 if male and under 25: \n",
    "    myData$youngMan[gender == \"male\" & age < 25] <- 1 \n",
    "    \n",
    "    # Rename a variable from myVariable to myRenamedVariable: \n",
    "    myData <- rename(myData, c(myVariable=\"myRenamedVariable\")) \n",
    "    \n",
    "    # Run an OLS regression of income on age and height:\n",
    "    olsResults <- lm(income ~ age + height, data = myData) \n",
    "    \n",
    "    # Run an OLS regression of income and age and a categorical variable for level of education:\n",
    "    myData$educationDummies <- factor(myData$education)\n",
    "    myData_menOnly <- subset(myData, gender == \"male\")\n",
    "    olsResults <- lm(income ~ age + educationDummies, data = myData_menOnly)\n",
    "```\n",
    "\n",
    "A few Python commands (all from the pandas library):\n",
    "```python\n",
    "\n",
    "    # Open a dataset from a file (pickle is a file format): \n",
    "    myData = pandas.read_pickle('myFile.pkl')\n",
    "    \n",
    "    # Create new variable called age_squared equal to each person's age squared: \n",
    "    myData['age_squared'] = myData['age'] * myData['age']\n",
    "    \n",
    "    # Set variable youngMan values to 1 if male and under 25: \n",
    "    myData.loc[(myData['gender'] == \"male\") & (myData['age'] < 25) ,'youngMan'] = 1\n",
    "    \n",
    "    # Rename a variable from myVariable to myRenamedVariable: \n",
    "    myData = myData.rename(columns = {'myVariable':'myRenamedVariable'})\n",
    "    \n",
    "    # Run an OLS regression of income and age and height:\n",
    "    from pandas.stats.api import ols\n",
    "    olsResults = ols(y=myData['income'], x=myData[['age','height']])\n",
    "    \n",
    "    # Run an OLS regression of income and age and a categorical variable for level of education for men:\n",
    "    from pandas.stats.api import ols\n",
    "    myData[\"educationDummies\"] = df[\"education\"].astype('category')\n",
    "    myData_menOnly = myData.query('gender == \"male\"')\n",
    "    olsResults = ols(y=myData_menOnly['income'], x=myData_menOnly[  [ 'age','educationDummies' ]  ])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
