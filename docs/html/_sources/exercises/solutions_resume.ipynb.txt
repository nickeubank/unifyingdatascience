{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Experiment Analysis\n",
    "\n",
    "How much harder is it to get a job in the United States if you are Black than if you are White? Or, expressed differently, what is the *effect* of race on the difficulty of getting a job in the US?\n",
    "\n",
    "In this exercise, we will be analyzing data from a real world experiment designed to help answer this question. Namely, we will be analyzing data from a randomized experiment in which 4,870 ficticious resumes were sent out to employers in response to job adverts in Boston and Chicago in 2001. The resumes differ in various attributes including the names of the applicants, and different resumes were randomly allocated to job openings. \n",
    "\n",
    "The \"experiment\" part of the experiment is that resumes were randomly assigned Black- or White-sounding names, and then watched to see whether employers called the \"applicants\" with Black-sounding names at the same rate as the applicants with the White-sounding names.\n",
    "\n",
    "(Which names constituted \"Black-sounding names\" and \"White-sounding names\" was determined by analyzing names on Massachusetts birth certificates to determine which names were most associated with Black and White children, and then surveys were used to validate that the names were perceived as being associated with individuals of one racial category or the other). \n",
    "\n",
    "You can get access to original article [here](https://www.aeaweb.org/articles?id=10.1257/0002828042002561). \n",
    "\n",
    "**Note to Duke students:** if you are on the Duke campus network, you'll be able to access almost any academic journal articles directly; if you are off campus and want access, you can just go to the [Duke Library](https://library.duke.edu/) website and search for the article title. Once you find it, you'll be asked to log in, after which you'll have full access to the article. You will also find this pattern holds true at nearly any major University in the US.\n",
    "\n",
    "- Download the data set `resume_experiment.dta` from [github here](https://github.com/nickeubank/MIDS_Data/tree/master/resume_experiment), or by doing to `www.github.com/nickeubank/MIDS_Data` and opening the `resume_experiment` folder.\n",
    "- For `python` users, use `read_stata` in `pandas` to load the data set; For `R` users, use `read_dta` in `haven` to load the data set\n",
    "- `black` is the treatment variable in the data set (whether the resume has a Black-sounding name). \n",
    "- `call` is the dependent variable of interest (did the employer call the fictitious applicant for an interview)\n",
    "\n",
    "In addition, the data include a number of variables to describe the other features in each fictitious resume, including applicants education level (`education`), years of experience (`yearsexp`), gender (`female`), computer skills (`computerskills`), and number of previous jobs (`ofjobs`). Each resume has a random selection of these attributes, so on average the Black-named fictitious applicant resumes have the same qualifications as the White-named applicant resumes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Balance\n",
    "\n",
    "The first step in analyzing any experiment is to check whether you have *balance* across your treatment arms—that is to say, do the people who were randomly assigned to the treatment group look like the people who were randomly assigned to the control group. Or in this case, do the resumes that ended up with Black-sounding names look like the resumes with White-sounding names. \n",
    "\n",
    "Checking for balance is critical for two reasons. First, it's always possible that random assignment will create profoundly different groups—the *Large of Large Numbers* is only a \"law\" in the limit. So we want to make sure we have reasonably similar groups from the outset. And second, it's also always possible that the randomization wasn't actually implemented correctly—you would be amazed at the number of ways that \"random assignment\" can go wrong! So if you ever do find you're getting unbalanced data, you should worry not only about whether the groups have baseline differences, but also whether the \"random assignment\" was actually random!\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "\n",
    "Check for balance in terms of the average values of applicant gender (`female`), computer skills (`computerskills`), and years of experience (`yearsexp`) across the two arms of the experiment (i.e. by `black`). Calculate both the differences in means across treatment arms *and* test for statistical significance of these differences. Do gender and computer skills look balanced across race groups?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "resumes = pd.read_stata(\n",
    "    \"https://github.com/nickeubank/MIDS_Data/blob/master/resume_experiment/\"\n",
    "    \"resume_experiment.dta?raw=true\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>ofjobs</th>\n",
       "      <th>yearsexp</th>\n",
       "      <th>computerskills</th>\n",
       "      <th>call</th>\n",
       "      <th>female</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   education  ofjobs  yearsexp  computerskills  call  female  black\n",
       "0          4       2         6               1   0.0     1.0    0.0\n",
       "1          3       3         6               1   0.0     1.0    0.0\n",
       "2          4       1         6               1   0.0     1.0    1.0\n",
       "3          3       4         6               1   0.0     1.0    1.0\n",
       "4          3       3        22               1   0.0     1.0    0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For female, the mean for Black applicants is 0.77,\n",
      "            the mean for White applicants is 0.76,\n",
      "and the p-value for this difference is 0.38\n",
      "\n",
      "\n",
      "For computerskills, the mean for Black applicants is 0.83,\n",
      "            the mean for White applicants is 0.81,\n",
      "and the p-value for this difference is 0.03\n",
      "\n",
      "\n",
      "For yearsexp, the mean for Black applicants is 7.83,\n",
      "            the mean for White applicants is 7.86,\n",
      "and the p-value for this difference is 0.85\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covariates = [\"female\", \"computerskills\", \"yearsexp\"]\n",
    "for i in covariates:\n",
    "    black = resumes.loc[resumes.black == 1, i].mean()\n",
    "    white = resumes.loc[resumes.black == 0, i].mean()\n",
    "    pvalue = stats.ttest_ind(\n",
    "        resumes.loc[resumes.black == 1, i].values,\n",
    "        resumes.loc[resumes.black == 0, i].values,\n",
    "    ).pvalue\n",
    "    print(f\"For {i}, the mean for Black applicants is {black:.2f},\")\n",
    "    print(f\"            the mean for White applicants is {white:.2f},\")\n",
    "    print(f\"and the p-value for this difference is {pvalue:.2f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, gender and experience are roughly balanced across race groups.\n",
    "# Black shows a statisticallly significantly higher level of computer\n",
    "# computer skills than White, but the magnitude isn't too worrying.\n",
    "# Provided other things seem balanced, this is hopefully spurious.\n",
    "# Later we will add computer skills as a control to see if it makes a difference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Do a similar tabulation for education (`education`). Education is a categorical variable coded as follows:\n",
    "\n",
    "- 0: Education not reported\n",
    "- 1: High school dropout\n",
    "- 2: High school graduate\n",
    "- 3: Some college\n",
    "- 4: College graduate or higher\n",
    "\n",
    "Because these are categorical, you shouldn't just calculate and compare means—you should compare share or count of observations with each value (e.g., a chi-squared contingency table). You may also find the `pd.crosstab` function useful.\n",
    "\n",
    "Does education look balanced across racial groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>black</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>513</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744</td>\n",
       "      <td>1760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "black       0.0   1.0\n",
       "education            \n",
       "0            18    28\n",
       "1            18    22\n",
       "2           142   132\n",
       "3           513   493\n",
       "4          1744  1760"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick and dirty:\n",
    "ctab = pd.crosstab(resumes[\"education\"], resumes[\"black\"])\n",
    "ctab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4917640058792273"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "chi2, p, dof, expected = scipy.stats.chi2_contingency(ctab.values)\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So not statistically different. Pretty darn similar!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "What do you make of the overall results on resume characteristics? Why do we care about whether these variables look similar across the race groups? And if they didn't look similar, would that be a threat to internal or external validity?\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking on the balance across groups on a number of key variables ensures that the resumes sent\n",
    "# out are the same or almost the same, which allows us to confidently isolate the independent\n",
    "# variable, the \"Black-ness\" or \"White-ness\" of the name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Effect of Race"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "The variable of interest in the data set is the variable `call`, which indicates a call back for an interview. Perform a two-sample t-test comparing applicants with black sounding names and white sounding names.\n",
    "\n",
    "Interpret your results—in both percentage terms *and* in percentage points, what is the effect of having a Black-sounding name (as opposed to a White-sounding name) on your resume?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean callback rates are:\n",
      "6.4% for Black applicants, and\n",
      "9.7% for White applicants.\n",
      "Thats a difference of  3.2 percentage points, a difference of 39.8% difference.\n",
      "This difference has a (naive) p-value of 0.000\n"
     ]
    }
   ],
   "source": [
    "black = resumes[resumes.black == 1][\"call\"]\n",
    "white = resumes[resumes.black == 0][\"call\"]\n",
    "t2, p2 = stats.ttest_ind(black, white)\n",
    "\n",
    "print(f\"The mean callback rates are:\")\n",
    "print(f\"{black.mean():.1%} for Black applicants, and\")\n",
    "print(f\"{white.mean():.1%} for White applicants.\")\n",
    "print(\n",
    "    f\"Thats a difference of {(white.mean() - black.mean()) * 100: .1f} percentage points, \"\n",
    "    f\"a difference of {(white.mean() - black.mean()) / (resumes.call.mean()) :.1%} difference.\"\n",
    ")\n",
    "print(f\"This difference has a (naive) p-value of {p2:.3f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Now, use a linear probability model (regression!) to estimate the differential likelihood of being called back by applicant race (i.e. the racial discrimination by employers). \n",
    "\n",
    "Since we have a limited dependent variable, be sure to use [heteroskedastic robust standard errors.](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLSResults.get_robustcov_results.html) Personally, I prefer the `HC3` implementation, as it tends to do better with smaller samples than other implementations.\n",
    "\n",
    "Interpret these results—what is the *effect* of having a Black-sounding name (as opposed to a White-sounding name) on your resume in terms of the likelihood you'll be called back?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 04 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>3.96e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:16:45</td>     <th>  Log-Likelihood:    </th> <td> -562.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1128.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4868</td>      <th>  BIC:               </th> <td>   1141.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0965</td> <td>    0.006</td> <td>   16.121</td> <td> 0.000</td> <td>    0.085</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>   -0.0320</td> <td>    0.008</td> <td>   -4.114</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2969.205</td> <th>  Durbin-Watson:     </th> <td>   1.440</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18927.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.068</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.458</td>  <th>  Cond. No.          </th> <td>    2.62</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.003\n",
       "Model:                            OLS   Adj. R-squared:                  0.003\n",
       "Method:                 Least Squares   F-statistic:                     16.92\n",
       "Date:                Sat, 04 Mar 2023   Prob (F-statistic):           3.96e-05\n",
       "Time:                        14:16:45   Log-Likelihood:                -562.24\n",
       "No. Observations:                4870   AIC:                             1128.\n",
       "Df Residuals:                    4868   BIC:                             1141.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0965      0.006     16.121      0.000       0.085       0.108\n",
       "black         -0.0320      0.008     -4.114      0.000      -0.047      -0.017\n",
       "==============================================================================\n",
       "Omnibus:                     2969.205   Durbin-Watson:                   1.440\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18927.068\n",
       "Skew:                           3.068   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.458   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols(\"call ~ black\", resumes).fit()\n",
    "model.get_robustcov_results(cov_type=\"HC3\").summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Now let's see if we can improve our estimates by adding in other variables as controls. Add in `education`, `yearsexp`, `female`, and `computerskills`—be sure to treat education as a categorical variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 04 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>3.04e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:16:45</td>     <th>  Log-Likelihood:    </th> <td> -551.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1120.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4861</td>      <th>  BIC:               </th> <td>   1178.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>    0.0821</td> <td>    0.040</td> <td>    2.053</td> <td> 0.040</td> <td>    0.004</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.1]</th> <td>   -0.0017</td> <td>    0.057</td> <td>   -0.030</td> <td> 0.976</td> <td>   -0.113</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.2]</th> <td>-8.953e-05</td> <td>    0.042</td> <td>   -0.002</td> <td> 0.998</td> <td>   -0.082</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.3]</th> <td>   -0.0025</td> <td>    0.039</td> <td>   -0.065</td> <td> 0.948</td> <td>   -0.079</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.4]</th> <td>   -0.0047</td> <td>    0.038</td> <td>   -0.124</td> <td> 0.901</td> <td>   -0.080</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>             <td>   -0.0316</td> <td>    0.008</td> <td>   -4.076</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>          <td>    0.0032</td> <td>    0.001</td> <td>    3.665</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th>    <td>   -0.0186</td> <td>    0.011</td> <td>   -1.616</td> <td> 0.106</td> <td>   -0.041</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>            <td>    0.0112</td> <td>    0.010</td> <td>    1.165</td> <td> 0.244</td> <td>   -0.008</td> <td>    0.030</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2950.646</td> <th>  Durbin-Watson:     </th> <td>   1.448</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18631.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.047</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.395</td>  <th>  Cond. No.          </th> <td>    225.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.008\n",
       "Model:                            OLS   Adj. R-squared:                  0.006\n",
       "Method:                 Least Squares   F-statistic:                     4.350\n",
       "Date:                Sat, 04 Mar 2023   Prob (F-statistic):           3.04e-05\n",
       "Time:                        14:16:45   Log-Likelihood:                -551.02\n",
       "No. Observations:                4870   AIC:                             1120.\n",
       "Df Residuals:                    4861   BIC:                             1178.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept             0.0821      0.040      2.053      0.040       0.004       0.160\n",
       "C(education)[T.1]    -0.0017      0.057     -0.030      0.976      -0.113       0.110\n",
       "C(education)[T.2] -8.953e-05      0.042     -0.002      0.998      -0.082       0.082\n",
       "C(education)[T.3]    -0.0025      0.039     -0.065      0.948      -0.079       0.074\n",
       "C(education)[T.4]    -0.0047      0.038     -0.124      0.901      -0.080       0.070\n",
       "black                -0.0316      0.008     -4.076      0.000      -0.047      -0.016\n",
       "yearsexp              0.0032      0.001      3.665      0.000       0.001       0.005\n",
       "computerskills       -0.0186      0.011     -1.616      0.106      -0.041       0.004\n",
       "female                0.0112      0.010      1.165      0.244      -0.008       0.030\n",
       "==============================================================================\n",
       "Omnibus:                     2950.646   Durbin-Watson:                   1.448\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18631.250\n",
       "Skew:                           3.047   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.395   Cond. No.                         225.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols(\n",
    "    \"call ~ black + C(education) + yearsexp + computerskills + female\", resumes\n",
    ").fit()\n",
    "model.get_robustcov_results(cov_type=\"HC3\").summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically no change in estimate or statistical power. Though given \n",
    "# the sample size and balance, that isn't super surprising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Heterogeneous Effects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "What we've been estimating up until this point are the *average* effects. Now let's look for evidence of *heterogeneous treatment effects*—effects that are different for different types of people in our data.\n",
    "\n",
    "Is there more or less racial discrimination among applicants who do *not* have a college degree? What is the difference in both percentage terms and in percentage points? Is the difference statistically significant?\n",
    "\n",
    "Please still include `education`, `yearsexp`, `female`, and `computerskills` as controls.\n",
    "\n",
    "*(Hint: use an interaction term)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 04 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>4.06e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:16:46</td>     <th>  Log-Likelihood:    </th> <td> -550.77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1116.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4863</td>      <th>  BIC:               </th> <td>   1161.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>    0.0759</td> <td>    0.014</td> <td>    5.318</td> <td> 0.000</td> <td>    0.048</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>non_college_grads[T.True]</th>       <td>    0.0090</td> <td>    0.014</td> <td>    0.652</td> <td> 0.514</td> <td>   -0.018</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>                           <td>   -0.0281</td> <td>    0.009</td> <td>   -3.090</td> <td> 0.002</td> <td>   -0.046</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black:non_college_grads[T.True]</th> <td>   -0.0123</td> <td>    0.017</td> <td>   -0.705</td> <td> 0.481</td> <td>   -0.047</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>                        <td>    0.0032</td> <td>    0.001</td> <td>    3.673</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th>                  <td>   -0.0188</td> <td>    0.011</td> <td>   -1.660</td> <td> 0.097</td> <td>   -0.041</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>                          <td>    0.0110</td> <td>    0.010</td> <td>    1.147</td> <td> 0.251</td> <td>   -0.008</td> <td>    0.030</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2950.206</td> <th>  Durbin-Watson:     </th> <td>   1.448</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18624.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.047</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.393</td>  <th>  Cond. No.          </th> <td>    50.5</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.008\n",
       "Model:                            OLS   Adj. R-squared:                  0.007\n",
       "Method:                 Least Squares   F-statistic:                     5.874\n",
       "Date:                Sat, 04 Mar 2023   Prob (F-statistic):           4.06e-06\n",
       "Time:                        14:16:46   Log-Likelihood:                -550.77\n",
       "No. Observations:                4870   AIC:                             1116.\n",
       "Df Residuals:                    4863   BIC:                             1161.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                           0.0759      0.014      5.318      0.000       0.048       0.104\n",
       "non_college_grads[T.True]           0.0090      0.014      0.652      0.514      -0.018       0.036\n",
       "black                              -0.0281      0.009     -3.090      0.002      -0.046      -0.010\n",
       "black:non_college_grads[T.True]    -0.0123      0.017     -0.705      0.481      -0.047       0.022\n",
       "yearsexp                            0.0032      0.001      3.673      0.000       0.001       0.005\n",
       "computerskills                     -0.0188      0.011     -1.660      0.097      -0.041       0.003\n",
       "female                              0.0110      0.010      1.147      0.251      -0.008       0.030\n",
       "==============================================================================\n",
       "Omnibus:                     2950.206   Durbin-Watson:                   1.448\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18624.275\n",
       "Skew:                           3.047   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.393   Cond. No.                         50.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One could also drop people whose education is 0 here.\n",
    "# But my guess is that if you don't report education on a resume,\n",
    "# it is assumed that your education is not very good\n",
    "# by the hiring parties\n",
    "\n",
    "resumes[\"non_college_grads\"] = resumes.education != 4\n",
    "model = smf.ols(\n",
    "    \"call ~ black*non_college_grads + yearsexp + computerskills + female\", resumes\n",
    ").fit()\n",
    "results = model.get_robustcov_results(cov_type=\"HC3\").summary()\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrimination against noncollege grads is 43.8% greater\n"
     ]
    }
   ],
   "source": [
    "# So discrimination is greater for less educated applicants,\n",
    "# and the magnitude of the difference looks relatively large:\n",
    "\n",
    "print(f\"Discrimination against noncollege grads is {-0.0123 / -0.0281:.1%} greater\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But with that said, the difference is far from statistically significant,\n",
    "# so it should be taken with a few grains of salt, but also not ignored.\n",
    "\n",
    "# One thing to bear in mind is that this is a situation where our standard errors are relatively large\n",
    "# with respect to the statistical quantities of interest, suggesting that this is just a little bit underpowered\n",
    "# for analyzing our subpopulations, not a situation where we can't reject the null hypothesis of no effect\n",
    "# because we had a very precisely estimated estimate of zero effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 04 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:16:46</td>     <th>  Log-Likelihood:    </th> <td> -372.64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3504</td>      <th>  AIC:               </th> <td>   755.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3499</td>      <th>  BIC:               </th> <td>   786.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    0.0736</td> <td>    0.016</td> <td>    4.704</td> <td> 0.000</td> <td>    0.043</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>          <td>   -0.0286</td> <td>    0.009</td> <td>   -3.145</td> <td> 0.002</td> <td>   -0.046</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>       <td>    0.0019</td> <td>    0.001</td> <td>    1.899</td> <td> 0.058</td> <td>-6.02e-05</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th> <td>   -0.0108</td> <td>    0.013</td> <td>   -0.864</td> <td> 0.388</td> <td>   -0.035</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>         <td>    0.0197</td> <td>    0.010</td> <td>    1.972</td> <td> 0.049</td> <td>    0.000</td> <td>    0.039</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2165.854</td> <th>  Durbin-Watson:     </th> <td>   1.522</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>14157.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.096</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.657</td>  <th>  Cond. No.          </th> <td>    35.7</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.005\n",
       "Model:                            OLS   Adj. R-squared:                  0.004\n",
       "Method:                 Least Squares   F-statistic:                     4.245\n",
       "Date:                Sat, 04 Mar 2023   Prob (F-statistic):            0.00198\n",
       "Time:                        14:16:46   Log-Likelihood:                -372.64\n",
       "No. Observations:                3504   AIC:                             755.3\n",
       "Df Residuals:                    3499   BIC:                             786.1\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          0.0736      0.016      4.704      0.000       0.043       0.104\n",
       "black             -0.0286      0.009     -3.145      0.002      -0.046      -0.011\n",
       "yearsexp           0.0019      0.001      1.899      0.058   -6.02e-05       0.004\n",
       "computerskills    -0.0108      0.013     -0.864      0.388      -0.035       0.014\n",
       "female             0.0197      0.010      1.972      0.049       0.000       0.039\n",
       "==============================================================================\n",
       "Omnibus:                     2165.854   Durbin-Watson:                   1.522\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14157.448\n",
       "Skew:                           3.096   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.657   Cond. No.                         35.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split sample calculations\n",
    "college_grads = resumes[resumes.education == 4]\n",
    "model = smf.ols(\n",
    "    \"call ~ black + yearsexp + computerskills + female\", college_grads\n",
    ").fit()\n",
    "model.get_robustcov_results(cov_type=\"HC3\").summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 04 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>1.90e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:16:46</td>     <th>  Log-Likelihood:    </th> <td> -170.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1366</td>      <th>  AIC:               </th> <td>   350.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1361</td>      <th>  BIC:               </th> <td>   376.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    0.1315</td> <td>    0.035</td> <td>    3.806</td> <td> 0.000</td> <td>    0.064</td> <td>    0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>          <td>   -0.0408</td> <td>    0.015</td> <td>   -2.750</td> <td> 0.006</td> <td>   -0.070</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>       <td>    0.0062</td> <td>    0.002</td> <td>    3.757</td> <td> 0.000</td> <td>    0.003</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th> <td>   -0.0412</td> <td>    0.026</td> <td>   -1.592</td> <td> 0.112</td> <td>   -0.092</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>         <td>   -0.0460</td> <td>    0.031</td> <td>   -1.490</td> <td> 0.137</td> <td>   -0.107</td> <td>    0.015</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>795.855</td> <th>  Durbin-Watson:     </th> <td>   1.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4394.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.880</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.636</td>  <th>  Cond. No.          </th> <td>    46.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.026\n",
       "Model:                            OLS   Adj. R-squared:                  0.023\n",
       "Method:                 Least Squares   F-statistic:                     6.837\n",
       "Date:                Sat, 04 Mar 2023   Prob (F-statistic):           1.90e-05\n",
       "Time:                        14:16:46   Log-Likelihood:                -170.01\n",
       "No. Observations:                1366   AIC:                             350.0\n",
       "Df Residuals:                    1361   BIC:                             376.1\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          0.1315      0.035      3.806      0.000       0.064       0.199\n",
       "black             -0.0408      0.015     -2.750      0.006      -0.070      -0.012\n",
       "yearsexp           0.0062      0.002      3.757      0.000       0.003       0.009\n",
       "computerskills    -0.0412      0.026     -1.592      0.112      -0.092       0.010\n",
       "female            -0.0460      0.031     -1.490      0.137      -0.107       0.015\n",
       "==============================================================================\n",
       "Omnibus:                      795.855   Durbin-Watson:                   1.621\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4394.951\n",
       "Skew:                           2.880   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.636   Cond. No.                         46.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_college_grads = resumes[resumes.education != 4]\n",
    "model = smf.ols(\n",
    "    \"call ~ black + yearsexp + computerskills + female\", non_college_grads\n",
    ").fit()\n",
    "model.get_robustcov_results(cov_type=\"HC3\").summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "Now let's compare men and women—is the penalty for having a Black-sounding name greater for Black men or Black women?\n",
    "\n",
    "Again, please still include `education`, `yearsexp`, `female`, and `computerskills` as controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 04 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>6.76e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:16:46</td>     <th>  Log-Likelihood:    </th> <td> -551.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1122.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4860</td>      <th>  BIC:               </th> <td>   1187.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>    0.0807</td> <td>    0.040</td> <td>    1.996</td> <td> 0.046</td> <td>    0.001</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.1]</th> <td>   -0.0021</td> <td>    0.057</td> <td>   -0.037</td> <td> 0.971</td> <td>   -0.114</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.2]</th> <td>   -0.0001</td> <td>    0.042</td> <td>   -0.003</td> <td> 0.998</td> <td>   -0.082</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.3]</th> <td>   -0.0026</td> <td>    0.039</td> <td>   -0.066</td> <td> 0.947</td> <td>   -0.079</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.4]</th> <td>   -0.0048</td> <td>    0.038</td> <td>   -0.125</td> <td> 0.900</td> <td>   -0.080</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>             <td>   -0.0287</td> <td>    0.016</td> <td>   -1.840</td> <td> 0.066</td> <td>   -0.059</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>            <td>    0.0131</td> <td>    0.014</td> <td>    0.919</td> <td> 0.358</td> <td>   -0.015</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black:female</th>      <td>   -0.0038</td> <td>    0.018</td> <td>   -0.213</td> <td> 0.831</td> <td>   -0.039</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>          <td>    0.0032</td> <td>    0.001</td> <td>    3.668</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th>    <td>   -0.0186</td> <td>    0.011</td> <td>   -1.618</td> <td> 0.106</td> <td>   -0.041</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2950.616</td> <th>  Durbin-Watson:     </th> <td>   1.448</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18630.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.047</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.395</td>  <th>  Cond. No.          </th> <td>    226.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.008\n",
       "Model:                            OLS   Adj. R-squared:                  0.006\n",
       "Method:                 Least Squares   F-statistic:                     3.866\n",
       "Date:                Sat, 04 Mar 2023   Prob (F-statistic):           6.76e-05\n",
       "Time:                        14:16:46   Log-Likelihood:                -551.00\n",
       "No. Observations:                4870   AIC:                             1122.\n",
       "Df Residuals:                    4860   BIC:                             1187.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept             0.0807      0.040      1.996      0.046       0.001       0.160\n",
       "C(education)[T.1]    -0.0021      0.057     -0.037      0.971      -0.114       0.110\n",
       "C(education)[T.2]    -0.0001      0.042     -0.003      0.998      -0.082       0.082\n",
       "C(education)[T.3]    -0.0026      0.039     -0.066      0.947      -0.079       0.074\n",
       "C(education)[T.4]    -0.0048      0.038     -0.125      0.900      -0.080       0.070\n",
       "black                -0.0287      0.016     -1.840      0.066      -0.059       0.002\n",
       "female                0.0131      0.014      0.919      0.358      -0.015       0.041\n",
       "black:female         -0.0038      0.018     -0.213      0.831      -0.039       0.031\n",
       "yearsexp              0.0032      0.001      3.668      0.000       0.001       0.005\n",
       "computerskills       -0.0186      0.011     -1.618      0.106      -0.041       0.004\n",
       "==============================================================================\n",
       "Omnibus:                     2950.616   Durbin-Watson:                   1.448\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18630.964\n",
       "Skew:                           3.047   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.395   Cond. No.                         226.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As interaction\n",
    "model = smf.ols(\n",
    "    \"call ~ black*female + yearsexp + computerskills + C(education)\", resumes\n",
    ").fit()\n",
    "model.get_robustcov_results(cov_type=\"HC3\").summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little bit more discrimination for women maybe, but not only is it\n",
    "# extremely insignificant statistically, but the point estimate is also very small\n",
    "# (unlike above) -- ~ fifteen percent?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "Calculate and/or lookup the following online:\n",
    "\n",
    "- What is the share of applicants in our dataset with college degrees?\n",
    "- What share of Black adult Americans have college degrees (i.e. have completed a bachelors degree)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.0% of applicants have a college degree in the experimental data\n"
     ]
    }
   ],
   "source": [
    "# In our data:\n",
    "print(\n",
    "    f\"{ (resumes['education'] == 4).mean():.1%} of applicants have a college degree in the experimental data\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the US, about 16% of Black adults have a college degree\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "Bearing in mind your answers to Exercise 7 and to Exercise 9, how do you think the Average Treatment Effect you estimated in Exercise 6 might generalize to the experience of the average Black American (i.e., how do you think the ATE for the average Black American would compare to the ATE estimated from this experiment)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the obvious caveat that the statistical significance of the difference is low,\n",
    "# but where we also acknowledge that is probably because our test is underpowered,\n",
    "# given that discrimination seems higher for less educated job applicants\n",
    "# and the resume experiment over-represented people with college degrees,\n",
    "# real workplace discrimination is likely higher than suggested by the\n",
    "# ATE estimated in Exercise 6.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "\n",
    "What does your answer to Exercise 10 imply about the study's *internal* validity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing! It's unrelated to internal validity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12\n",
    "\n",
    "What does your answer to Exercise 10 imply about the study's *external* validity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It implies that the study may not have external validity \n",
    "# with respect to the broader US population."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Did We Just Measure?\n",
    "\n",
    "It's worth pausing for a moment to think about exactly what we've measured in this experiment. Was it the effect of race on hiring? Or the difference in the experience of the average White job applicant from the average Black job applicant?\n",
    "\n",
    "Well... no. What we have measured in this experiment is **just** the effect of having a Black-sounding name (as opposed to a White-sounding name) on your resume on the likelihood of getting a followup call from someone hiring in Boston or Chicago given identical resumes. In that sense, what we've measured is a small *piece* of the difference in the experience of Black and White Americans when seeking employment. As anyone looking for a job knows, getting a call-back is obviously a crucial step in getting a job, so this difference—even if it's just one part of the overall difference—is remarkable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "718fed28bf9f8c7851519acf2fb923cd655120b36de3b67253eeb0428bd33d2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
