
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Evaluating Real Studies &#8212; Unifying Data Science</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="Evaluating-Real-Studies">
<h1>Evaluating Real Studies<a class="headerlink" href="#Evaluating-Real-Studies" title="Permalink to this headline">¶</a></h1>
<p>In our past classes, we’ve discussed in detail – and derived mathematically – the conditions required for a correlation to constitute a valid causal estimate. In particular, we saw that if we see a correlation between a treatment (say, seeing an advertisement) and an outcome (the amount a consumer spends at a store), that correlation will only be a good causal estimate of the Average Treatment Effect (ATE) for the population in the study if:</p>
<ol class="arabic simple">
<li><p>There are no baseline differences in outcome between the treated and untreated groups.</p></li>
<li><p>The treated and untreated groups would respond, on average, the same way to the treatment.</p></li>
</ol>
<p>We’ve seen mathematically what these two conditions look like:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(E(Y_0 | D=1) = E(Y_0 | D=0)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(E(Y_1 | D=1) - E(Y_0 | D=1) = E(Y_1 | D=0) - E(Y_0 | D=0)\)</span></p></li>
</ol>
<p>But when you see a study, how should you think about whether these conditions have been met?</p>
<div class="section" id="The-Sun-Is-Bright-for-Dogs-Too">
<h2>The Sun Is Bright for Dogs Too<a class="headerlink" href="#The-Sun-Is-Bright-for-Dogs-Too" title="Permalink to this headline">¶</a></h2>
<p>To make this concrete, let’s begin with an example study. Suppose you’re running a website that sells designer sunglass for dogs: Pawda.</p>
<img alt="dog_in_glasses" src="_images/dog_in_glasses.jpg" />
<p>To promote your business, you start running ads with a 10% off coupon on the New York Times website, because you figure people who live in NY are the kind of people who would buy their dogs sunglasses.</p>
<p>You then look at the amount that people coming to your website spend, and compare the people who came to your site through your ad (e.g. the people getting the discount) and those who came to your site after seeing your normal ads on other sites. And sure enough, you find that people who saw the ad spend 30% more on your website – enough that you made more money on them than your average customer, even after the 10% discount.</p>
<p>So now you’re thinking, should I roll out this ad all over Facebook and Instagram?!</p>
<p>In effect, what you want to know in this example is the <em>effect</em> rolling out that ad would have on the behavior of all your customers. So clearly, we’re in the world of causal inference.</p>
<p>But do we think this correlation between getting the 10% discount and spending 30% more is a good causal estimate?</p>
</div>
<div class="section" id="Evaluating-Baseline-Differences">
<h2>Evaluating Baseline Differences<a class="headerlink" href="#Evaluating-Baseline-Differences" title="Permalink to this headline">¶</a></h2>
<p>The first question to ask is whether we think there are baseline differences between the people who got the discount on the NYTimes website, and the people who saw ads elsewhere.</p>
<p>It is tempting when asked if we can think of a reason that the baseline difference condition might be violated to say “Well, the people who go to the NYTimes may be different that people who go to facebook, so those groups may be different.” But that answer, while true, is actually <em>vacuously</em> true – saying “people are different, so there may be differences in baseline outcomes” is something you can say about <em>any</em> study. In fact, you can even say that about a randomized experiment! Yes,
randomization means that it’s <em>unlikely</em> you’ll get large differences in the people who receive the treatment and those that do not, but it doesn’t guarantee it!</p>
<p>So assuming we’re will to <em>ever</em> accept that a study may be telling us meaningful about a causal effect, we need to set a higher bar.</p>
<p>In particular, a good reason for worrying about baseline differences should include three things:</p>
<ol class="arabic simple">
<li><p>A way in which people may be different,</p></li>
<li><p>That we have an <em>affirmative</em> reason to think is correlated with who got treated, and</p></li>
<li><p>Which is related to the outcome we care about (<span class="math notranslate nohighlight">\(Y\)</span>).</p></li>
</ol>
<p>So in our New York Times example, we might think that people who go to the NYTimes website are likely to be wealthier than the average Instagram user because the NYTimes has lots of news about finance that only relativley well-off people care about (1 and 2), and because they have more disposable income, are more likely to spend money on dog sunglasses (3).</p>
<div class="section" id="Why-we-need-all-three">
<h3>Why we need all three<a class="headerlink" href="#Why-we-need-all-three" title="Permalink to this headline">¶</a></h3>
<p>No two of these things is sufficient. For example, imagine we ran an experiment in which we split people into two groups, gave one group 100 dollars, then asked both groups how happy they were as a way to measure the effect of free money on short-term happiness.</p>
<p>Now suppose that the groups weren’t randomly assigned, but rather we put people whose height (in cm) is even in one group, and people whose height (in cm) is odd in another. Here we have a difference (1) that’s correlated with treatment (2), but unless you have a reason to think that people with even heights are happier than people with odd heights, we haven’t violated condition 3.</p>
<p>Similarly, if we randomly assigned people to groups, and you then pointed out that some people are happier than other people, and so it could be that all the happy people ended up in the treated group… we’ll, you’re not wrong. It <em>could</em> happen. But provided we see balance on other attributes we can measure, and we have a reasonable sample size (so LLN has kicked in), then don’t have an affirmative reason to think this has happened, so we kinda just have to accept this as the risk of doing
research.</p>
</div>
</div>
<div class="section" id="Evaulating-Differential-Treatment-Effects">
<h2>Evaulating Differential Treatment Effects<a class="headerlink" href="#Evaulating-Differential-Treatment-Effects" title="Permalink to this headline">¶</a></h2>
<p>If we don’t have a reason to think that we have baseline differences, then the good news is that we do have a valid causal estimate – the Average Treatment on the Treated (ATT). Yay!</p>
<p>But now we want to know how likely it is that the treatment effect we estimated when we treated NYTimes users will be the same as the treatment effect we’d get if we rolled this discount out on Facebook and Instagram. In other words, we want to know if people on those other platforms would respond to our discount the same way the NYTimes users would.</p>
<p>So how do we think about this?</p>
<p>Again, in evaluating if there are differential treatment effects exist, it’s not really productive to just say “there may be differences in how people respond to treatment, and so there may be differential treatment effects.” It’s <em>true</em>, but again, vacuously true since it holds everywhere.</p>
<p>So again, we need three things:</p>
<ol class="arabic simple">
<li><p>A reason people may differ</p></li>
<li><p>An <em>affirmative</em> reason to think these differences are correlated with who got treated, and</p></li>
<li><p>A reason these differences might give rise to different treatment effects.</p></li>
</ol>
<p>What would that look like here? Let’s start by supposing that we’ve already convinced ourselves that there are no baseline differences in our study – we have data from before we started offering the discount, and that data shows that people coming from the NYTimes were spending the same amount as people coming from Instagram and Facebook before we offered the 10% discount (we’ll talk about formally doing this type of analysis soon). So we think that 30% increase in sales is a valid estimate of
the ATT of the 10% discount on people coming from the NYTimes. But we still want to know if we’d expect the same effect if we ran the ad on Facebook and Instagram.</p>
<p>Well, as before, we might think that people who go to the NYTimes website are likely to be wealthier than the average Instagram user because the NYTimes has lots of news about finance that only relativley well-off people care about (1 and 2). Given they’re wealthier, we might think that discounts would actually matter <em>less</em> to them since they have more disposable income (3).</p>
<p>Given that, we might actually think that our ATT is an <em>understimate</em> of the true ATE, and we might see <em>more</em> than a 30% rise in sales from Facebook and Instagram users.</p>
</div>
<div class="section" id="What-Comes-Next?">
<h2>What Comes Next?<a class="headerlink" href="#What-Comes-Next?" title="Permalink to this headline">¶</a></h2>
<p>BUT… BUT… BUT… you say…</p>
<p>At this point, you’re probably full of objections, saying “but what if NYTimes readers go to the NYTimes to read the financial reporting because they care more about money, and so even if they have more money, they’re actually more obsessed with savings and so the discount has a LARGER effect for them than the average customer!”</p>
<p>Great question! That’s an entirely plausible story!</p>
<p>As we’ve discussed, oh, I dunno – a dozen times so far? – causal inference is the domain of critical thinking, not perfect absolute answers that drop out of regressions. And so when you end up in a situation like this where you have different potential stories, its up to you to think about ways to dig in further.</p>
<p>The great thing about a concrete story about why you may have baseline differences or differential treatment effects is that a concrete concern can be investigated. Remember where I said above:</p>
<blockquote>
<div><p>Let’s start by supposing that we’ve already convinced ourselves that there are no baseline differences in our study – we have data from before we started offering the discount, and that data shows that people coming from the NYTimes were spending the same amount as people coming from Instagram and Facebook before we offered the 10% discount (we’ll talk about formally doing this type of analysis soon).</p>
</div></blockquote>
<p>Because we started with a concrete concern, we were able to imagine a way to test whether its likely to be true. We can’t be certain that the evidence presented above means there aren’t baseline differences – the specific people who went to the NYTimes before you started running the 10% discount ads might be different from the people who were visiting when you were running them – but it provides <em>additional evidence</em> we can use to reason through the situation.</p>
<p>We could do something similar with the story you told about how people going to the NYTimes for financial advice may be more worried about money, so more interested in discounts. If we’ve ever run ads with discounts before, we could see if NYTimes users responded more strongly; or we could call up our friend who runs a business that sells flip-flop sandals for cats (Meow-dals) and ask about their experience with NYTimes referrals when they put their sandals on sale.</p>
<img alt="cat_in_sandals" src="_images/cat_in_sandals.jpg" />
</div>
<div class="section" id="Well-this-has-been-unsatisfying">
<h2>Well this has been unsatisfying<a class="headerlink" href="#Well-this-has-been-unsatisfying" title="Permalink to this headline">¶</a></h2>
<p>Yup! Welcome to causal inference, where there is <em>never</em> any certainty, and we’re always just trying to do our best!</p>
<p>But hopefully this provides you with a framework for evaluating studies you come across, thinking through the possible problems they may have, and even thinking about next steps you can take to try and evaluating if those concerns are valid.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Unifying DS</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="class_schedule.html">CLASS SCHEDULE</a></li>
</ul>
<p class="caption"><span class="caption-text">QUESTIONS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="taxonomy_of_questions.html">Taxonomy of Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="moving_from_problems_to_questions.html">From Problems to Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="descriptive_questions.html">Discretion and Description</a></li>
<li class="toctree-l1"><a class="reference internal" href="limitations_of_ATE.html">Limitations of Experiments</a></li>
</ul>
<p class="caption"><span class="caption-text">METHODS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="interpreting_indicator_vars.html">Indicator Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="fixed_effects.html">Fixed Effects</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Nick Eubank.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.4.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/evaluating_real_studies.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-151397036-1']);
      _gaq.push(['_setDomainName', 'none']);
      _gaq.push(['_setAllowLinker', true]);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    
  </body>
</html>