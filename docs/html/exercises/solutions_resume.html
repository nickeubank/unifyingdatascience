<!DOCTYPE html> <html lang=en  data-content_root="../"> <meta charset=utf-8  /> <meta name=viewport  content="width=device-width, initial-scale=1.0" /><meta name=viewport  content="width=device-width, initial-scale=1" /> <meta name=viewport  content="width=device-width,initial-scale=1"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name="lang:clipboard.copy" content="Copy to clipboard"> <meta name="lang:clipboard.copied" content="Copied to clipboard"> <meta name="lang:search.language" content=en > <meta name="lang:search.pipeline.stopwords" content=True > <meta name="lang:search.pipeline.trimmer" content=True > <meta name="lang:search.result.none" content="No matching documents"> <meta name="lang:search.result.one" content="1 matching document"> <meta name="lang:search.result.other" content="# matching documents"> <meta name="lang:search.tokenizer" content="[\s\-]+"> <link href="https://fonts.gstatic.com/" rel=preconnect  crossorigin> <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel=stylesheet > <style> body, input { font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif } code, kbd, pre { font-family: "Roboto Mono", "Courier New", Courier, monospace } </style> <link rel=stylesheet  href="../_static/stylesheets/application.css"/> <link rel=stylesheet  href="../_static/stylesheets/application-palette.css"/> <link rel=stylesheet  href="../_static/stylesheets/application-fixes.css"/> <link rel=stylesheet  href="../_static/fonts/material-icons.css"/> <meta name=theme-color  content="#2196f3"> <script src="../_static/javascripts/modernizr.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-151397036-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'UA-151397036-1'); </script> <title>Resume Experiment Analysis &#8212; Unifying Data Science</title> <link rel=stylesheet  type="text/css" href="../_static/pygments.css?v=649a27d8" /> <link rel=stylesheet  type="text/css" href="../_static/material.css?v=79c92029" /> <link rel=stylesheet  type="text/css" href="../_static/nbsphinx-code-cells.css?v=b9dd2d90" /> <script src="../_static/documentation_options.js?v=5929fcd5"></script> <script src="../_static/doctools.js?v=888ff710"></script> <script src="../_static/sphinx_highlight.js?v=dc90522c"></script> <script crossorigin=anonymous  integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script> <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script> <script defer=defer  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <link rel=icon  href="../_static/mids_logo.svg"/> <link rel=index  title=Index  href="../genindex.html" /> <link rel=search  title=Search  href="../search.html" /> <body dir=ltr data-md-color-primary=blue-grey data-md-color-accent=blue> <svg class=md-svg > <defs data-children-count=0 > <svg xmlns="http://www.w3.org/2000/svg" width=416  height=448  viewBox="0 0 416 448" id=__github ><path fill=currentColor  d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle  data-md-toggle=drawer  type=checkbox  id=__drawer > <input class=md-toggle  data-md-toggle=search  type=checkbox  id=__search > <label class=md-overlay  data-md-component=overlay  for=__drawer ></label> <a href="#exercises/solutions_resume" tabindex=1  class=md-skip > Skip to content </a> <header class=md-header  data-md-component=header > <nav class="md-header-nav md-grid"> <div class="md-flex navheader"> <div class="md-flex__cell md-flex__cell--shrink"> <a href="../index.html" title="Unifying Data Science" class="md-header-nav__button md-logo"> &nbsp; </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer ></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title > <span class=md-header-nav__topic >Unifying Data Science</span> <span class=md-header-nav__topic > Resume Experiment Analysis </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search ></label> <div class=md-search  data-md-component=search  role=dialog > <label class=md-search__overlay  for=__search ></label> <div class=md-search__inner  role=search > <form class=md-search__form  action="../search.html" method=get  name=search > <input type=text  class=md-search__input  name=q  placeholder=""Search"" autocapitalize=off  autocomplete=off  spellcheck=false  data-md-component=query  data-md-state=active > <label class="md-icon md-search__icon" for=__search ></label> <button type=reset  class="md-icon md-search__icon" data-md-component=reset  tabindex=-1 > &#xE5CD; </button> </form> <div class=md-search__output > <div class=md-search__scrollwrap  data-md-scrollfix> <div class=md-search-result  data-md-component=result > <div class=md-search-result__meta > Type to start searching </div> <ol class=md-search-result__list ></ol> </div> </div> </div> </div> </div> </div> <script src="../_static/javascripts/version_dropdown.js"></script> <script> var json_loc = "../"versions.json"", target_loc = "../../", text = "Versions"; $( document ).ready( add_version_dropdown(json_loc, target_loc, text)); </script> </div> </nav> </header> <div class=md-container > <nav class=md-tabs  data-md-component=tabs > <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list > <li class=md-tabs__item ><a href="../index.html" class=md-tabs__link >Home</a> <li class=md-tabs__item ><a href="../class_schedule.html" class=md-tabs__link >Class Schedule</a> <li class=md-tabs__item ><a href="../topic_list.html" class=md-tabs__link >Topic List</a> <li class=md-tabs__item ><a href="https://www.nickeubank.com" class=md-tabs__link >About The Author</a> </ul> </div> </nav> <main class=md-main > <div class="md-main__inner md-grid" data-md-component=container > <div class="md-sidebar md-sidebar--primary" data-md-component=navigation > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--primary" data-md-level=0 > <label class="md-nav__title md-nav__title--site" for=__drawer > <a href="../index.html" title="Unifying Data Science" class="md-nav__button md-logo"> <img src="../_static/" alt=" logo" width=48  height=48 > </a> <a href="../index.html" title="Unifying Data Science">Unifying Data Science</a> </label> <ul class=md-nav__list > <li class=md-nav__item > <a href="../class_schedule.html" class=md-nav__link >CLASS SCHEDULE</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Causal Inference</span></span> <li class=md-nav__item > <a href="../limitations_of_ATE.html" class=md-nav__link >Limitations of ATE</a> <li class=md-nav__item > <a href="../internal_v_external_validity.html" class=md-nav__link >Internal v. External Validity</a> <li class=md-nav__item > <a href="../evaluating_real_studies.html" class=md-nav__link >Evaluating A Real Study</a> <li class=md-nav__item > <a href="../causal_inference_beyond_ab_testing.html" class=md-nav__link >Beyond AB Testing</a> <li class=md-nav__item > <a href="../matching_why.html" class=md-nav__link >Matching (Why)</a> <li class=md-nav__item > <a href="../matching_how.html" class=md-nav__link >Matching (How)</a> <li class=md-nav__item > <a href="../interpreting_indicator_vars.html" class=md-nav__link >Indicator Variables</a> <li class=md-nav__item > <a href="../fixed_effects.html" class=md-nav__link >Fixed Effects (FEs)</a> <li class=md-nav__item > <a href="../fixed_effects_and_causal_inference.html" class=md-nav__link >FEs & Causality</a> <li class=md-nav__item > <a href="../fixed_effects_v_hierarchical.html" class=md-nav__link >FEs & Hierarchical Models</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Data Science Project Design</span></span> <li class=md-nav__item > <a href="../backwards_design.html" class=md-nav__link >Backwards Design</a> <li class=md-nav__item > <a href="../taxonomy_of_questions.html" class=md-nav__link >Taxonomy of Questions</a> <li class=md-nav__item > <a href="../moving_from_problems_to_questions.html" class=md-nav__link >From Problems to Questions</a> <li class=md-nav__item > <a href="../descriptive_questions.html" class=md-nav__link >Discretion and Description</a> <li class=md-nav__item > <a href="../ethical_ml_recommendations.html" class=md-nav__link >Ethical Machine Learning</a> <li class=md-nav__item > <a href="../writing_to_stakeholders.html" class=md-nav__link >Writing for Lay Audiences</a> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--secondary"> <label class=md-nav__title  for=__toc >"Contents"</label> <ul class=md-nav__list  data-md-scrollfix=""> <li class=md-nav__item ><a href="#exercises-solutions-resume--page-root" class=md-nav__link >Resume Experiment Analysis</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Checking-for-Balance" class=md-nav__link >Checking for Balance</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-1" class=md-nav__link >Exercise 1</a> <li class=md-nav__item ><a href="#Exercise-2" class=md-nav__link >Exercise 2</a> <li class=md-nav__item ><a href="#Exercise-3" class=md-nav__link >Exercise 3</a> </ul> </nav> <li class=md-nav__item ><a href="#Estimating-Effect-of-Race" class=md-nav__link >Estimating Effect of Race</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-4" class=md-nav__link >Exercise 4</a> <li class=md-nav__item ><a href="#Exercise-5" class=md-nav__link >Exercise 5</a> <li class=md-nav__item ><a href="#Exercise-6" class=md-nav__link >Exercise 6</a> </ul> </nav> <li class=md-nav__item ><a href="#Estimating-Heterogeneous-Effects" class=md-nav__link >Estimating Heterogeneous Effects</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-7" class=md-nav__link >Exercise 7</a> <li class=md-nav__item ><a href="#Exercise-8" class=md-nav__link >Exercise 8</a> <li class=md-nav__item ><a href="#Exercise-9" class=md-nav__link >Exercise 9</a> <li class=md-nav__item ><a href="#Exercise-10" class=md-nav__link >Exercise 10</a> <li class=md-nav__item ><a href="#Exercise-11" class=md-nav__link >Exercise 11</a> <li class=md-nav__item ><a href="#Exercise-12" class=md-nav__link >Exercise 12</a> </ul> </nav> <li class=md-nav__item ><a href="#What-Did-We-Just-Measure?" class=md-nav__link >What Did We Just Measure?</a> </ul> </nav> </ul> </nav> </div> </div> </div> <div class=md-content > <article class="md-content__inner md-typeset" role=main > <section id=Resume-Experiment-Analysis > <h1 id=exercises-solutions-resume--page-root >Resume Experiment Analysis<a class=headerlink  href="#exercises-solutions-resume--page-root" title="Link to this heading">¶</a></h1> <p>How much harder is it to get a job in the United States if you are Black than if you are White? Or, expressed differently, what is the <em>effect</em> of race on the difficulty of getting a job in the US?</p> <p>In this exercise, we will be analyzing data from a real world experiment designed to help answer this question. Namely, we will be analyzing data from a randomized experiment in which 4,870 ficticious resumes were sent out to employers in response to job adverts in Boston and Chicago in 2001. The resumes differ in various attributes including the names of the applicants, and different resumes were randomly allocated to job openings.</p> <p>The “experiment” part of the experiment is that resumes were randomly assigned Black- or White-sounding names, and then watched to see whether employers called the “applicants” with Black-sounding names at the same rate as the applicants with the White-sounding names.</p> <p>(Which names constituted “Black-sounding names” and “White-sounding names” was determined by analyzing names on Massachusetts birth certificates to determine which names were most associated with Black and White children, and then surveys were used to validate that the names were perceived as being associated with individuals of one racial category or the other).</p> <p>You can get access to original article <a class="reference external" href="https://www.aeaweb.org/articles?id=10.1257/0002828042002561">here</a>.</p> <p><strong>Note to Duke students:</strong> if you are on the Duke campus network, you’ll be able to access almost any academic journal articles directly; if you are off campus and want access, you can just go to the <a class="reference external" href="https://library.duke.edu/">Duke Library</a> website and search for the article title. Once you find it, you’ll be asked to log in, after which you’ll have full access to the article. You will also find this pattern holds true at nearly any major University in the US.</p> <ul class=simple > <li><p>Download the data set <code class="docutils literal notranslate"><span class=pre >resume_experiment.dta</span></code> from <a class="reference external" href="https://github.com/nickeubank/MIDS_Data/tree/master/resume_experiment">github here</a>, or by doing to <code class="docutils literal notranslate"><span class=pre >www.github.com/nickeubank/MIDS_Data</span></code> and opening the <code class="docutils literal notranslate"><span class=pre >resume_experiment</span></code> folder.</p> <li><p>For <code class="docutils literal notranslate"><span class=pre >python</span></code> users, use <code class="docutils literal notranslate"><span class=pre >read_stata</span></code> in <code class="docutils literal notranslate"><span class=pre >pandas</span></code> to load the data set; For <code class="docutils literal notranslate"><span class=pre >R</span></code> users, use <code class="docutils literal notranslate"><span class=pre >read_dta</span></code> in <code class="docutils literal notranslate"><span class=pre >haven</span></code> to load the data set</p> <li><p><code class="docutils literal notranslate"><span class=pre >black</span></code> is the treatment variable in the data set (whether the resume has a Black-sounding name).</p> <li><p><code class="docutils literal notranslate"><span class=pre >call</span></code> is the dependent variable of interest (did the employer call the fictitious applicant for an interview)</p> </ul> <p>In addition, the data include a number of variables to describe the other features in each fictitious resume, including applicants education level (<code class="docutils literal notranslate"><span class=pre >education</span></code>), years of experience (<code class="docutils literal notranslate"><span class=pre >yearsexp</span></code>), gender (<code class="docutils literal notranslate"><span class=pre >female</span></code>), computer skills (<code class="docutils literal notranslate"><span class=pre >computerskills</span></code>), and number of previous jobs (<code class="docutils literal notranslate"><span class=pre >ofjobs</span></code>). Each resume has a random selection of these attributes, so on average the Black-named fictitious applicant resumes have the same qualifications as the White-named applicant resumes.</p> <section id=Checking-for-Balance > <h2 id=Checking-for-Balance >Checking for Balance<a class=headerlink  href="#Checking-for-Balance" title="Link to this heading">¶</a></h2> <p>The first step in analyzing any experiment is to check whether you have <em>balance</em> across your treatment arms—that is to say, do the people who were randomly assigned to the treatment group look like the people who were randomly assigned to the control group. Or in this case, do the resumes that ended up with Black-sounding names look like the resumes with White-sounding names.</p> <p>Checking for balance is critical for two reasons. First, it’s always possible that random assignment will create profoundly different groups—the <em>Large of Large Numbers</em> is only a “law” in the limit. So we want to make sure we have reasonably similar groups from the outset. And second, it’s also always possible that the randomization wasn’t actually implemented correctly—you would be amazed at the number of ways that “random assignment” can go wrong! So if you ever do find you’re getting unbalanced data, you should worry not only about whether the groups have baseline differences, but also whether the “random assignment” was actually random!</p> <section id=Exercise-1 > <h3 id=Exercise-1 >Exercise 1<a class=headerlink  href="#Exercise-1" title="Link to this heading">¶</a></h3> <p>Check for balance in terms of the average values of applicant gender (<code class="docutils literal notranslate"><span class=pre >female</span></code>), computer skills (<code class="docutils literal notranslate"><span class=pre >computerskills</span></code>), and years of experience (<code class="docutils literal notranslate"><span class=pre >yearsexp</span></code>) across the two arms of the experiment (i.e. by <code class="docutils literal notranslate"><span class=pre >black</span></code>). Calculate both the differences in means across treatment arms <em>and</em> test for statistical significance of these differences. Do gender and computer skills look balanced across race groups?</p> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[1]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >pandas</span> <span class=k >as</span> <span class=nn >pd</span>
<span class=kn >from</span> <span class=nn >scipy</span> <span class=kn >import</span> <span class=n >stats</span>
<span class=kn >import</span> <span class=nn >statsmodels.api</span> <span class=k >as</span> <span class=nn >sm</span>

<span class=n >resumes</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >read_stata</span><span class=p >(</span>
    <span class=s2 >"https://github.com/nickeubank/MIDS_Data/blob/master/resume_experiment/"</span>
    <span class=s2 >"resume_experiment.dta?raw=true"</span>
<span class=p >)</span>
<br/></pre></div> </div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[2]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >resumes</span><span class=o >.</span><span class=n >head</span><span class=p >()</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[2]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border=1  class=dataframe > <thead> <tr style="text-align: right;"> <th> <th>education <th>ofjobs <th>yearsexp <th>computerskills <th>call <th>female <th>black <tr> <th>0 <td>4 <td>2 <td>6 <td>1 <td>0.0 <td>1.0 <td>0.0 <tr> <th>1 <td>3 <td>3 <td>6 <td>1 <td>0.0 <td>1.0 <td>0.0 <tr> <th>2 <td>4 <td>1 <td>6 <td>1 <td>0.0 <td>1.0 <td>1.0 <tr> <th>3 <td>3 <td>4 <td>6 <td>1 <td>0.0 <td>1.0 <td>1.0 <tr> <th>4 <td>3 <td>3 <td>22 <td>1 <td>0.0 <td>1.0 <td>0.0 </table> </div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[3]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >covariates</span> <span class=o >=</span> <span class=p >[</span><span class=s2 >"female"</span><span class=p >,</span> <span class=s2 >"computerskills"</span><span class=p >,</span> <span class=s2 >"yearsexp"</span><span class=p >]</span>
<span class=k >for</span> <span class=n >i</span> <span class=ow >in</span> <span class=n >covariates</span><span class=p >:</span>
    <span class=n >black</span> <span class=o >=</span> <span class=n >resumes</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >resumes</span><span class=o >.</span><span class=n >black</span> <span class=o >==</span> <span class=mi >1</span><span class=p >,</span> <span class=n >i</span><span class=p >]</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span>
    <span class=n >white</span> <span class=o >=</span> <span class=n >resumes</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >resumes</span><span class=o >.</span><span class=n >black</span> <span class=o >==</span> <span class=mi >0</span><span class=p >,</span> <span class=n >i</span><span class=p >]</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span>
    <span class=n >pvalue</span> <span class=o >=</span> <span class=n >stats</span><span class=o >.</span><span class=n >ttest_ind</span><span class=p >(</span>
        <span class=n >resumes</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >resumes</span><span class=o >.</span><span class=n >black</span> <span class=o >==</span> <span class=mi >1</span><span class=p >,</span> <span class=n >i</span><span class=p >]</span><span class=o >.</span><span class=n >values</span><span class=p >,</span>
        <span class=n >resumes</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >resumes</span><span class=o >.</span><span class=n >black</span> <span class=o >==</span> <span class=mi >0</span><span class=p >,</span> <span class=n >i</span><span class=p >]</span><span class=o >.</span><span class=n >values</span><span class=p >,</span>
    <span class=p >)</span><span class=o >.</span><span class=n >pvalue</span>
    <span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"For </span><span class=si >{</span><span class=n >i</span><span class=si >}</span><span class=s2 >, the mean for Black applicants is </span><span class=si >{</span><span class=n >black</span><span class=si >:</span><span class=s2 >.2f</span><span class=si >}</span><span class=s2 >,"</span><span class=p >)</span>
    <span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"            the mean for White applicants is </span><span class=si >{</span><span class=n >white</span><span class=si >:</span><span class=s2 >.2f</span><span class=si >}</span><span class=s2 >,"</span><span class=p >)</span>
    <span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"and the p-value for this difference is </span><span class=si >{</span><span class=n >pvalue</span><span class=si >:</span><span class=s2 >.2f</span><span class=si >}</span><span class=s2 >"</span><span class=p >)</span>
    <span class=nb >print</span><span class=p >(</span><span class=s2 >"</span><span class=se >\n</span><span class=s2 >"</span><span class=p >)</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
For female, the mean for Black applicants is 0.77,
            the mean for White applicants is 0.76,
and the p-value for this difference is 0.38


For computerskills, the mean for Black applicants is 0.83,
            the mean for White applicants is 0.81,
and the p-value for this difference is 0.03


For yearsexp, the mean for Black applicants is 7.83,
            the mean for White applicants is 7.86,
and the p-value for this difference is 0.85


</pre></div></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[4]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Yes, gender and experience are roughly balanced across race groups.</span>
<span class=c1 ># Black shows a statisticallly significantly higher level of computer</span>
<span class=c1 ># computer skills than White, but the magnitude isn't too worrying.</span>
<span class=c1 ># Provided other things seem balanced, this is hopefully spurious.</span>
<span class=c1 ># Later we will add computer skills as a control to see if it makes a difference.</span>
</pre></div> </div> </div> </section> <section id=Exercise-2 > <h3 id=Exercise-2 >Exercise 2<a class=headerlink  href="#Exercise-2" title="Link to this heading">¶</a></h3> <p>Do a similar tabulation for education (<code class="docutils literal notranslate"><span class=pre >education</span></code>). Education is a categorical variable coded as follows:</p> <ul class=simple > <li><p>0: Education not reported</p> <li><p>1: High school dropout</p> <li><p>2: High school graduate</p> <li><p>3: Some college</p> <li><p>4: College graduate or higher</p> </ul> <p>Because these are categorical, you shouldn’t just calculate and compare means—you should compare share or count of observations with each value (e.g., a chi-squared contingency table). You may also find the <code class="docutils literal notranslate"><span class=pre >pd.crosstab</span></code> function useful.</p> <p>Does education look balanced across racial groups?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[5]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Quick and dirty:</span>
<span class=n >ctab</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >crosstab</span><span class=p >(</span><span class=n >resumes</span><span class=p >[</span><span class=s2 >"education"</span><span class=p >],</span> <span class=n >resumes</span><span class=p >[</span><span class=s2 >"black"</span><span class=p >])</span>
<span class=n >ctab</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[5]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border=1  class=dataframe > <thead> <tr style="text-align: right;"> <th>black <th>0.0 <th>1.0 <tr> <th>education <th> <th> <tr> <th>0 <td>18 <td>28 <tr> <th>1 <td>18 <td>22 <tr> <th>2 <td>142 <td>132 <tr> <th>3 <td>513 <td>493 <tr> <th>4 <td>1744 <td>1760 </table> </div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[6]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >scipy.stats</span>

<span class=n >chi2</span><span class=p >,</span> <span class=n >p</span><span class=p >,</span> <span class=n >dof</span><span class=p >,</span> <span class=n >expected</span> <span class=o >=</span> <span class=n >scipy</span><span class=o >.</span><span class=n >stats</span><span class=o >.</span><span class=n >chi2_contingency</span><span class=p >(</span><span class=n >ctab</span><span class=o >.</span><span class=n >values</span><span class=p >)</span>
<span class=n >p</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[6]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
0.4917640058792273
</pre></div></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[7]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># So not statistically different. Pretty darn similar!</span>
</pre></div> </div> </div> </section> <section id=Exercise-3 > <h3 id=Exercise-3 >Exercise 3<a class=headerlink  href="#Exercise-3" title="Link to this heading">¶</a></h3> <p>What do you make of the overall results on resume characteristics? Why do we care about whether these variables look similar across the race groups? And if they didn’t look similar, would that be a threat to internal or external validity?</p> <div class="highlight-none notranslate"><div class=highlight ><pre><span></span>..
</pre></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[8]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Checking on the balance across groups on a number of key variables ensures that the resumes sent</span>
<span class=c1 ># out are the same or almost the same, which allows us to confidently isolate the independent</span>
<span class=c1 ># variable, the "Black-ness" or "White-ness" of the name.</span>
<br/></pre></div> </div> </div> </section> </section> <section id=Estimating-Effect-of-Race > <h2 id=Estimating-Effect-of-Race >Estimating Effect of Race<a class=headerlink  href="#Estimating-Effect-of-Race" title="Link to this heading">¶</a></h2> <section id=Exercise-4 > <h3 id=Exercise-4 >Exercise 4<a class=headerlink  href="#Exercise-4" title="Link to this heading">¶</a></h3> <p>The variable of interest in the data set is the variable <code class="docutils literal notranslate"><span class=pre >call</span></code>, which indicates a call back for an interview. Perform a two-sample t-test comparing applicants with black sounding names and white sounding names.</p> <p>Interpret your results—in both percentage terms <em>and</em> in percentage points, what is the effect of having a Black-sounding name (as opposed to a White-sounding name) on your resume?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[9]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >black</span> <span class=o >=</span> <span class=n >resumes</span><span class=p >[</span><span class=n >resumes</span><span class=o >.</span><span class=n >black</span> <span class=o >==</span> <span class=mi >1</span><span class=p >][</span><span class=s2 >"call"</span><span class=p >]</span>
<span class=n >white</span> <span class=o >=</span> <span class=n >resumes</span><span class=p >[</span><span class=n >resumes</span><span class=o >.</span><span class=n >black</span> <span class=o >==</span> <span class=mi >0</span><span class=p >][</span><span class=s2 >"call"</span><span class=p >]</span>
<span class=n >t2</span><span class=p >,</span> <span class=n >p2</span> <span class=o >=</span> <span class=n >stats</span><span class=o >.</span><span class=n >ttest_ind</span><span class=p >(</span><span class=n >black</span><span class=p >,</span> <span class=n >white</span><span class=p >)</span>

<span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"The mean callback rates are:"</span><span class=p >)</span>
<span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"</span><span class=si >{</span><span class=n >black</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span><span class=si >:</span><span class=s2 >.1%</span><span class=si >}</span><span class=s2 > for Black applicants, and"</span><span class=p >)</span>
<span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"</span><span class=si >{</span><span class=n >white</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span><span class=si >:</span><span class=s2 >.1%</span><span class=si >}</span><span class=s2 > for White applicants."</span><span class=p >)</span>
<span class=nb >print</span><span class=p >(</span>
    <span class=sa >f</span><span class=s2 >"Thats a difference of </span><span class=si >{</span><span class=p >(</span><span class=n >white</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span><span class=w > </span><span class=o >-</span><span class=w > </span><span class=n >black</span><span class=o >.</span><span class=n >mean</span><span class=p >())</span><span class=w > </span><span class=o >*</span><span class=w > </span><span class=mi >100</span><span class=si >:</span><span class=s2 > .1f</span><span class=si >}</span><span class=s2 > percentage points, "</span>
    <span class=sa >f</span><span class=s2 >"a difference of </span><span class=si >{</span><span class=p >(</span><span class=n >white</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span><span class=w > </span><span class=o >-</span><span class=w > </span><span class=n >black</span><span class=o >.</span><span class=n >mean</span><span class=p >())</span><span class=w > </span><span class=o >/</span><span class=w > </span><span class=p >(</span><span class=n >resumes</span><span class=o >.</span><span class=n >call</span><span class=o >.</span><span class=n >mean</span><span class=p >())</span><span class=w > </span><span class=si >:</span><span class=s2 >.1%</span><span class=si >}</span><span class=s2 > difference."</span>
<span class=p >)</span>
<span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"This difference has a (naive) p-value of </span><span class=si >{</span><span class=n >p2</span><span class=si >:</span><span class=s2 >.3f</span><span class=si >}</span><span class=s2 >"</span><span class=p >)</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
The mean callback rates are:
6.4% for Black applicants, and
9.7% for White applicants.
Thats a difference of  3.2 percentage points, a difference of 39.8% difference.
This difference has a (naive) p-value of 0.000
</pre></div></div> </div> </section> <section id=Exercise-5 > <h3 id=Exercise-5 >Exercise 5<a class=headerlink  href="#Exercise-5" title="Link to this heading">¶</a></h3> <p>Now, use a linear probability model (regression!) to estimate the differential likelihood of being called back by applicant race (i.e. the racial discrimination by employers).</p> <p>Since we have a limited dependent variable, be sure to use <a class="reference external" href="https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLSResults.get_robustcov_results.html">heteroskedastic robust standard errors.</a> Personally, I prefer the <code class="docutils literal notranslate"><span class=pre >HC3</span></code> implementation, as it tends to do better with smaller samples than other implementations.</p> <p>Interpret these results—what is the <em>effect</em> of having a Black-sounding name (as opposed to a White-sounding name) on your resume in terms of the likelihood you’ll be called back?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[10]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >statsmodels.formula.api</span> <span class=k >as</span> <span class=nn >smf</span>

<span class=n >model</span> <span class=o >=</span> <span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span><span class=s2 >"call ~ black"</span><span class=p >,</span> <span class=n >resumes</span><span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span>
<span class=n >model</span><span class=o >.</span><span class=n >get_robustcov_results</span><span class=p >(</span><span class=n >cov_type</span><span class=o >=</span><span class=s2 >"HC3"</span><span class=p >)</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[10]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>OLS Regression Results</caption> <tr> <th>Dep. Variable: <td>call <th> R-squared: <td> 0.003 <tr> <th>Model: <td>OLS <th> Adj. R-squared: <td> 0.003 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 16.92 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>3.96e-05 <tr> <th>Time: <td>14:16:45 <th> Log-Likelihood: <td> -562.24 <tr> <th>No. Observations: <td> 4870 <th> AIC: <td> 1128. <tr> <th>Df Residuals: <td> 4868 <th> BIC: <td> 1141. <tr> <th>Df Model: <td> 1 <th> <td> <tr> <th>Covariance Type: <td>HC3 <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 0.0965 <td> 0.006 <td> 16.121 <td> 0.000 <td> 0.085 <td> 0.108 <tr> <th>black <td> -0.0320 <td> 0.008 <td> -4.114 <td> 0.000 <td> -0.047 <td> -0.017 </table> <table> <tr> <th>Omnibus: <td>2969.205 <th> Durbin-Watson: <td> 1.440 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>18927.068 <tr> <th>Skew: <td> 3.068 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td>10.458 <th> Cond. No. <td> 2.62 </table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)</div> </div> </section> <section id=Exercise-6 > <h3 id=Exercise-6 >Exercise 6<a class=headerlink  href="#Exercise-6" title="Link to this heading">¶</a></h3> <p>Now let’s see if we can improve our estimates by adding in other variables as controls. Add in <code class="docutils literal notranslate"><span class=pre >education</span></code>, <code class="docutils literal notranslate"><span class=pre >yearsexp</span></code>, <code class="docutils literal notranslate"><span class=pre >female</span></code>, and <code class="docutils literal notranslate"><span class=pre >computerskills</span></code>—be sure to treat education as a categorical variable!</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[11]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >statsmodels.formula.api</span> <span class=k >as</span> <span class=nn >smf</span>

<span class=n >model</span> <span class=o >=</span> <span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span>
    <span class=s2 >"call ~ black + C(education) + yearsexp + computerskills + female"</span><span class=p >,</span> <span class=n >resumes</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span>
<span class=n >model</span><span class=o >.</span><span class=n >get_robustcov_results</span><span class=p >(</span><span class=n >cov_type</span><span class=o >=</span><span class=s2 >"HC3"</span><span class=p >)</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[11]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>OLS Regression Results</caption> <tr> <th>Dep. Variable: <td>call <th> R-squared: <td> 0.008 <tr> <th>Model: <td>OLS <th> Adj. R-squared: <td> 0.006 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 4.350 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>3.04e-05 <tr> <th>Time: <td>14:16:45 <th> Log-Likelihood: <td> -551.02 <tr> <th>No. Observations: <td> 4870 <th> AIC: <td> 1120. <tr> <th>Df Residuals: <td> 4861 <th> BIC: <td> 1178. <tr> <th>Df Model: <td> 8 <th> <td> <tr> <th>Covariance Type: <td>HC3 <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 0.0821 <td> 0.040 <td> 2.053 <td> 0.040 <td> 0.004 <td> 0.160 <tr> <th>C(education)[T.1] <td> -0.0017 <td> 0.057 <td> -0.030 <td> 0.976 <td> -0.113 <td> 0.110 <tr> <th>C(education)[T.2] <td>-8.953e-05 <td> 0.042 <td> -0.002 <td> 0.998 <td> -0.082 <td> 0.082 <tr> <th>C(education)[T.3] <td> -0.0025 <td> 0.039 <td> -0.065 <td> 0.948 <td> -0.079 <td> 0.074 <tr> <th>C(education)[T.4] <td> -0.0047 <td> 0.038 <td> -0.124 <td> 0.901 <td> -0.080 <td> 0.070 <tr> <th>black <td> -0.0316 <td> 0.008 <td> -4.076 <td> 0.000 <td> -0.047 <td> -0.016 <tr> <th>yearsexp <td> 0.0032 <td> 0.001 <td> 3.665 <td> 0.000 <td> 0.001 <td> 0.005 <tr> <th>computerskills <td> -0.0186 <td> 0.011 <td> -1.616 <td> 0.106 <td> -0.041 <td> 0.004 <tr> <th>female <td> 0.0112 <td> 0.010 <td> 1.165 <td> 0.244 <td> -0.008 <td> 0.030 </table> <table> <tr> <th>Omnibus: <td>2950.646 <th> Durbin-Watson: <td> 1.448 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>18631.250 <tr> <th>Skew: <td> 3.047 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td>10.395 <th> Cond. No. <td> 225. </table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)</div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[12]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Basically no change in estimate or statistical power. Though given</span>
<span class=c1 ># the sample size and balance, that isn't super surprising.</span>
</pre></div> </div> </div> </section> </section> <section id=Estimating-Heterogeneous-Effects > <h2 id=Estimating-Heterogeneous-Effects >Estimating Heterogeneous Effects<a class=headerlink  href="#Estimating-Heterogeneous-Effects" title="Link to this heading">¶</a></h2> <section id=Exercise-7 > <h3 id=Exercise-7 >Exercise 7<a class=headerlink  href="#Exercise-7" title="Link to this heading">¶</a></h3> <p>What we’ve been estimating up until this point are the <em>average</em> effects. Now let’s look for evidence of <em>heterogeneous treatment effects</em>—effects that are different for different types of people in our data.</p> <p>Is there more or less racial discrimination among applicants who do <em>not</em> have a college degree? What is the difference in both percentage terms and in percentage points? Is the difference statistically significant?</p> <p>Please still include <code class="docutils literal notranslate"><span class=pre >education</span></code>, <code class="docutils literal notranslate"><span class=pre >yearsexp</span></code>, <code class="docutils literal notranslate"><span class=pre >female</span></code>, and <code class="docutils literal notranslate"><span class=pre >computerskills</span></code> as controls.</p> <p><em>(Hint: use an interaction term)</em></p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[13]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># One could also drop people whose education is 0 here.</span>
<span class=c1 ># But my guess is that if you don't report education on a resume,</span>
<span class=c1 ># it is assumed that your education is not very good</span>
<span class=c1 ># by the hiring parties</span>

<span class=n >resumes</span><span class=p >[</span><span class=s2 >"non_college_grads"</span><span class=p >]</span> <span class=o >=</span> <span class=n >resumes</span><span class=o >.</span><span class=n >education</span> <span class=o >!=</span> <span class=mi >4</span>
<span class=n >model</span> <span class=o >=</span> <span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span>
    <span class=s2 >"call ~ black*non_college_grads + yearsexp + computerskills + female"</span><span class=p >,</span> <span class=n >resumes</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span>
<span class=n >results</span> <span class=o >=</span> <span class=n >model</span><span class=o >.</span><span class=n >get_robustcov_results</span><span class=p >(</span><span class=n >cov_type</span><span class=o >=</span><span class=s2 >"HC3"</span><span class=p >)</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
<span class=n >results</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[13]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>OLS Regression Results</caption> <tr> <th>Dep. Variable: <td>call <th> R-squared: <td> 0.008 <tr> <th>Model: <td>OLS <th> Adj. R-squared: <td> 0.007 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 5.874 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>4.06e-06 <tr> <th>Time: <td>14:16:46 <th> Log-Likelihood: <td> -550.77 <tr> <th>No. Observations: <td> 4870 <th> AIC: <td> 1116. <tr> <th>Df Residuals: <td> 4863 <th> BIC: <td> 1161. <tr> <th>Df Model: <td> 6 <th> <td> <tr> <th>Covariance Type: <td>HC3 <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 0.0759 <td> 0.014 <td> 5.318 <td> 0.000 <td> 0.048 <td> 0.104 <tr> <th>non_college_grads[T.True] <td> 0.0090 <td> 0.014 <td> 0.652 <td> 0.514 <td> -0.018 <td> 0.036 <tr> <th>black <td> -0.0281 <td> 0.009 <td> -3.090 <td> 0.002 <td> -0.046 <td> -0.010 <tr> <th>black:non_college_grads[T.True] <td> -0.0123 <td> 0.017 <td> -0.705 <td> 0.481 <td> -0.047 <td> 0.022 <tr> <th>yearsexp <td> 0.0032 <td> 0.001 <td> 3.673 <td> 0.000 <td> 0.001 <td> 0.005 <tr> <th>computerskills <td> -0.0188 <td> 0.011 <td> -1.660 <td> 0.097 <td> -0.041 <td> 0.003 <tr> <th>female <td> 0.0110 <td> 0.010 <td> 1.147 <td> 0.251 <td> -0.008 <td> 0.030 </table> <table> <tr> <th>Omnibus: <td>2950.206 <th> Durbin-Watson: <td> 1.448 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>18624.275 <tr> <th>Skew: <td> 3.047 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td>10.393 <th> Cond. No. <td> 50.5 </table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)</div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[14]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># So discrimination is greater for less educated applicants,</span>
<span class=c1 ># and the magnitude of the difference looks relatively large:</span>

<span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"Discrimination against noncollege grads is </span><span class=si >{</span><span class=o >-</span><span class=mf >0.0123</span><span class=w > </span><span class=o >/</span><span class=w > </span><span class=o >-</span><span class=mf >0.0281</span><span class=si >:</span><span class=s2 >.1%</span><span class=si >}</span><span class=s2 > greater"</span><span class=p >)</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
Discrimination against noncollege grads is 43.8% greater
</pre></div></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[15]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># But with that said, the difference is far from statistically significant,</span>
<span class=c1 ># so it should be taken with a few grains of salt, but also not ignored.</span>

<span class=c1 ># One thing to bear in mind is that this is a situation where our standard errors are relatively large</span>
<span class=c1 ># with respect to the statistical quantities of interest, suggesting that this is just a little bit underpowered</span>
<span class=c1 ># for analyzing our subpopulations, not a situation where we can't reject the null hypothesis of no effect</span>
<span class=c1 ># because we had a very precisely estimated estimate of zero effect.</span>
<br/></pre></div> </div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[16]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Split sample calculations</span>
<span class=n >college_grads</span> <span class=o >=</span> <span class=n >resumes</span><span class=p >[</span><span class=n >resumes</span><span class=o >.</span><span class=n >education</span> <span class=o >==</span> <span class=mi >4</span><span class=p >]</span>
<span class=n >model</span> <span class=o >=</span> <span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span>
    <span class=s2 >"call ~ black + yearsexp + computerskills + female"</span><span class=p >,</span> <span class=n >college_grads</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span>
<span class=n >model</span><span class=o >.</span><span class=n >get_robustcov_results</span><span class=p >(</span><span class=n >cov_type</span><span class=o >=</span><span class=s2 >"HC3"</span><span class=p >)</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[16]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>OLS Regression Results</caption> <tr> <th>Dep. Variable: <td>call <th> R-squared: <td> 0.005 <tr> <th>Model: <td>OLS <th> Adj. R-squared: <td> 0.004 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 4.245 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>0.00198 <tr> <th>Time: <td>14:16:46 <th> Log-Likelihood: <td> -372.64 <tr> <th>No. Observations: <td> 3504 <th> AIC: <td> 755.3 <tr> <th>Df Residuals: <td> 3499 <th> BIC: <td> 786.1 <tr> <th>Df Model: <td> 4 <th> <td> <tr> <th>Covariance Type: <td>HC3 <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 0.0736 <td> 0.016 <td> 4.704 <td> 0.000 <td> 0.043 <td> 0.104 <tr> <th>black <td> -0.0286 <td> 0.009 <td> -3.145 <td> 0.002 <td> -0.046 <td> -0.011 <tr> <th>yearsexp <td> 0.0019 <td> 0.001 <td> 1.899 <td> 0.058 <td>-6.02e-05 <td> 0.004 <tr> <th>computerskills <td> -0.0108 <td> 0.013 <td> -0.864 <td> 0.388 <td> -0.035 <td> 0.014 <tr> <th>female <td> 0.0197 <td> 0.010 <td> 1.972 <td> 0.049 <td> 0.000 <td> 0.039 </table> <table> <tr> <th>Omnibus: <td>2165.854 <th> Durbin-Watson: <td> 1.522 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>14157.448 <tr> <th>Skew: <td> 3.096 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td>10.657 <th> Cond. No. <td> 35.7 </table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)</div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[17]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >non_college_grads</span> <span class=o >=</span> <span class=n >resumes</span><span class=p >[</span><span class=n >resumes</span><span class=o >.</span><span class=n >education</span> <span class=o >!=</span> <span class=mi >4</span><span class=p >]</span>
<span class=n >model</span> <span class=o >=</span> <span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span>
    <span class=s2 >"call ~ black + yearsexp + computerskills + female"</span><span class=p >,</span> <span class=n >non_college_grads</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span>
<span class=n >model</span><span class=o >.</span><span class=n >get_robustcov_results</span><span class=p >(</span><span class=n >cov_type</span><span class=o >=</span><span class=s2 >"HC3"</span><span class=p >)</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[17]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>OLS Regression Results</caption> <tr> <th>Dep. Variable: <td>call <th> R-squared: <td> 0.026 <tr> <th>Model: <td>OLS <th> Adj. R-squared: <td> 0.023 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 6.837 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>1.90e-05 <tr> <th>Time: <td>14:16:46 <th> Log-Likelihood: <td> -170.01 <tr> <th>No. Observations: <td> 1366 <th> AIC: <td> 350.0 <tr> <th>Df Residuals: <td> 1361 <th> BIC: <td> 376.1 <tr> <th>Df Model: <td> 4 <th> <td> <tr> <th>Covariance Type: <td>HC3 <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 0.1315 <td> 0.035 <td> 3.806 <td> 0.000 <td> 0.064 <td> 0.199 <tr> <th>black <td> -0.0408 <td> 0.015 <td> -2.750 <td> 0.006 <td> -0.070 <td> -0.012 <tr> <th>yearsexp <td> 0.0062 <td> 0.002 <td> 3.757 <td> 0.000 <td> 0.003 <td> 0.009 <tr> <th>computerskills <td> -0.0412 <td> 0.026 <td> -1.592 <td> 0.112 <td> -0.092 <td> 0.010 <tr> <th>female <td> -0.0460 <td> 0.031 <td> -1.490 <td> 0.137 <td> -0.107 <td> 0.015 </table> <table> <tr> <th>Omnibus: <td>795.855 <th> Durbin-Watson: <td> 1.621 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>4394.951 <tr> <th>Skew: <td> 2.880 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td> 9.636 <th> Cond. No. <td> 46.2 </table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)</div> </div> </section> <section id=Exercise-8 > <h3 id=Exercise-8 >Exercise 8<a class=headerlink  href="#Exercise-8" title="Link to this heading">¶</a></h3> <p>Now let’s compare men and women—is the penalty for having a Black-sounding name greater for Black men or Black women?</p> <p>Again, please still include <code class="docutils literal notranslate"><span class=pre >education</span></code>, <code class="docutils literal notranslate"><span class=pre >yearsexp</span></code>, <code class="docutils literal notranslate"><span class=pre >female</span></code>, and <code class="docutils literal notranslate"><span class=pre >computerskills</span></code> as controls.</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[18]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># As interaction</span>
<span class=n >model</span> <span class=o >=</span> <span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span>
    <span class=s2 >"call ~ black*female + yearsexp + computerskills + C(education)"</span><span class=p >,</span> <span class=n >resumes</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span>
<span class=n >model</span><span class=o >.</span><span class=n >get_robustcov_results</span><span class=p >(</span><span class=n >cov_type</span><span class=o >=</span><span class=s2 >"HC3"</span><span class=p >)</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[18]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>OLS Regression Results</caption> <tr> <th>Dep. Variable: <td>call <th> R-squared: <td> 0.008 <tr> <th>Model: <td>OLS <th> Adj. R-squared: <td> 0.006 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 3.866 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>6.76e-05 <tr> <th>Time: <td>14:16:46 <th> Log-Likelihood: <td> -551.00 <tr> <th>No. Observations: <td> 4870 <th> AIC: <td> 1122. <tr> <th>Df Residuals: <td> 4860 <th> BIC: <td> 1187. <tr> <th>Df Model: <td> 9 <th> <td> <tr> <th>Covariance Type: <td>HC3 <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 0.0807 <td> 0.040 <td> 1.996 <td> 0.046 <td> 0.001 <td> 0.160 <tr> <th>C(education)[T.1] <td> -0.0021 <td> 0.057 <td> -0.037 <td> 0.971 <td> -0.114 <td> 0.110 <tr> <th>C(education)[T.2] <td> -0.0001 <td> 0.042 <td> -0.003 <td> 0.998 <td> -0.082 <td> 0.082 <tr> <th>C(education)[T.3] <td> -0.0026 <td> 0.039 <td> -0.066 <td> 0.947 <td> -0.079 <td> 0.074 <tr> <th>C(education)[T.4] <td> -0.0048 <td> 0.038 <td> -0.125 <td> 0.900 <td> -0.080 <td> 0.070 <tr> <th>black <td> -0.0287 <td> 0.016 <td> -1.840 <td> 0.066 <td> -0.059 <td> 0.002 <tr> <th>female <td> 0.0131 <td> 0.014 <td> 0.919 <td> 0.358 <td> -0.015 <td> 0.041 <tr> <th>black:female <td> -0.0038 <td> 0.018 <td> -0.213 <td> 0.831 <td> -0.039 <td> 0.031 <tr> <th>yearsexp <td> 0.0032 <td> 0.001 <td> 3.668 <td> 0.000 <td> 0.001 <td> 0.005 <tr> <th>computerskills <td> -0.0186 <td> 0.011 <td> -1.618 <td> 0.106 <td> -0.041 <td> 0.004 </table> <table> <tr> <th>Omnibus: <td>2950.616 <th> Durbin-Watson: <td> 1.448 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>18630.964 <tr> <th>Skew: <td> 3.047 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td>10.395 <th> Cond. No. <td> 226. </table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)</div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[19]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># A little bit more discrimination for women maybe, but not only is it</span>
<span class=c1 ># extremely insignificant statistically, but the point estimate is also very small</span>
<span class=c1 ># (unlike above) -- ~ fifteen percent?</span>
<br/></pre></div> </div> </div> </section> <section id=Exercise-9 > <h3 id=Exercise-9 >Exercise 9<a class=headerlink  href="#Exercise-9" title="Link to this heading">¶</a></h3> <p>Calculate and/or lookup the following online:</p> <ul class=simple > <li><p>What is the share of applicants in our dataset with college degrees?</p> <li><p>What share of Black adult Americans have college degrees (i.e. have completed a bachelors degree)?</p> </ul> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[20]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># In our data:</span>
<span class=nb >print</span><span class=p >(</span>
    <span class=sa >f</span><span class=s2 >"</span><span class=si >{</span><span class=w > </span><span class=p >(</span><span class=n >resumes</span><span class=p >[</span><span class=s1 >'education'</span><span class=p >]</span><span class=w > </span><span class=o >==</span><span class=w > </span><span class=mi >4</span><span class=p >)</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span><span class=si >:</span><span class=s2 >.1%</span><span class=si >}</span><span class=s2 > of applicants have a college degree in the experimental data"</span>
<span class=p >)</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
72.0% of applicants have a college degree in the experimental data
</pre></div></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[21]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># In the US, about 16% of Black adults have a college degree</span>
<br/></pre></div> </div> </div> </section> <section id=Exercise-10 > <h3 id=Exercise-10 >Exercise 10<a class=headerlink  href="#Exercise-10" title="Link to this heading">¶</a></h3> <p>Bearing in mind your answers to Exercise 7 and to Exercise 9, how do you think the Average Treatment Effect you estimated in Exercise 6 might generalize to the experience of the average Black American (i.e., how do you think the ATE for the average Black American would compare to the ATE estimated from this experiment)?</p> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[22]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># With the obvious caveat that the statistical significance of the difference is low,</span>
<span class=c1 ># but where we also acknowledge that is probably because our test is underpowered,</span>
<span class=c1 ># given that discrimination seems higher for less educated job applicants</span>
<span class=c1 ># and the resume experiment over-represented people with college degrees,</span>
<span class=c1 ># real workplace discrimination is likely higher than suggested by the</span>
<span class=c1 ># ATE estimated in Exercise 6.</span>
<br/></pre></div> </div> </div> </section> <section id=Exercise-11 > <h3 id=Exercise-11 >Exercise 11<a class=headerlink  href="#Exercise-11" title="Link to this heading">¶</a></h3> <p>What does your answer to Exercise 10 imply about the study’s <em>internal</em> validity?</p> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[23]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Nothing! It's unrelated to internal validity.</span>
</pre></div> </div> </div> </section> <section id=Exercise-12 > <h3 id=Exercise-12 >Exercise 12<a class=headerlink  href="#Exercise-12" title="Link to this heading">¶</a></h3> <p>What does your answer to Exercise 10 imply about the study’s <em>external</em> validity?</p> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[24]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># It implies that the study may not have external validity</span>
<span class=c1 ># with respect to the broader US population.</span>
</pre></div> </div> </div> </section> </section> <section id="What-Did-We-Just-Measure?"> <h2 id="What-Did-We-Just-Measure?">What Did We Just Measure?<a class=headerlink  href="#What-Did-We-Just-Measure?" title="Link to this heading">¶</a></h2> <p>It’s worth pausing for a moment to think about exactly what we’ve measured in this experiment. Was it the effect of race on hiring? Or the difference in the experience of the average White job applicant from the average Black job applicant?</p> <p>Well… no. What we have measured in this experiment is <strong>just</strong> the effect of having a Black-sounding name (as opposed to a White-sounding name) on your resume on the likelihood of getting a followup call from someone hiring in Boston or Chicago given identical resumes. In that sense, what we’ve measured is a small <em>piece</em> of the difference in the experience of Black and White Americans when seeking employment. As anyone looking for a job knows, getting a call-back is obviously a crucial step in getting a job, so this difference—even if it’s just one part of the overall difference—is remarkable.</p> </section> </section> </article> </div> </div> </main> </div> <footer class=md-footer > <div class=md-footer-nav > <nav class="md-footer-nav__inner md-grid"> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright > <div class=md-footer-copyright__highlight > &#169; Copyright 2022, Nick Eubank. </div> Created using <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.2.6. and <a href="https://github.com/bashtage/sphinx-material/">Material for Sphinx</a> </div> </div> </div> </footer> <script src="../_static/javascripts/application.js"></script> <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>