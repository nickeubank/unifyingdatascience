
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>A/B Testing the Udacity Website &#8212; Unifying Data Science</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "document", "processHtmlClass": "math|output_area"}}</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="A/B-Testing-the-Udacity-Website">
<h1>A/B Testing the Udacity Website<a class="headerlink" href="#A/B-Testing-the-Udacity-Website" title="Permalink to this headline">¶</a></h1>
<p>In these exercises, we’ll be analyzing data on user behavior from an experiment run by Udacity, the online education company. More specifically, we’ll be looking at a test Udacity ran to improve the onboarding process on their site.</p>
<p>Udacity’s test is an example of an “A/B” test, in which some portion of users visiting a website (or using an app) are randomly selected to see a new version of the site. An analyst can then compare the behavior of users who see a new website design to users seeing their normal website to estimate the effect of rolling out the proposed changes to all users. While this kind of experiment has it’s own name in industry (A/B testing), to be clear it’s just a randomized experiment, and so everything
we’ve learned about potential outcomes and randomized experiments apply here.</p>
<p>(Udacity has generously provides the data from this test under an Apache open-source license, and you can find their <a class="reference external" href="https://www.kaggle.com/tammyrotem/ab-tests-with-python/notebook">original writeup here</a>. If you’re interested in learning more on A/B testing in particular, it seems only fair while we use their data to flag they have a full course on the subject <a class="reference external" href="https://www.udacity.com/course/ab-testing--ud257">here</a>.)</p>
<section id="Udacity’s-Test">
<h2>Udacity’s Test<a class="headerlink" href="#Udacity’s-Test" title="Permalink to this headline">¶</a></h2>
<p>The test <a class="reference external" href="https://www.kaggle.com/tammyrotem/ab-tests-with-python/notebook">is described by Udacity as follows</a>:</p>
<p>At the time of this experiment, Udacity courses currently have two options on the course overview page: “start free trial”, and “access course materials”.</p>
<p><strong>Current Conditions Before Change</strong></p>
<ul class="simple">
<li><p>If the student clicks “start free trial”, they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first.</p></li>
<li><p>If the student clicks “access course materials”, they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.</p></li>
</ul>
<p><strong>Description of Experimented Change</strong></p>
<ul class="simple">
<li><p>In the experiment, Udacity tested a change where if the student clicked “start free trial”, they were asked how much time they had available to devote to the course.</p></li>
<li><p>If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free.</p></li>
<li><p>At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead. This <a class="reference external" href="images/udacity_checkyoureready.png">screenshot</a> shows what the experiment looks like.</p></li>
</ul>
<p><strong>Udacity’s Hope is that…</strong>:</p>
<blockquote>
<div><p>this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn’t have enough time – without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches’ capacity to support students who are likely to complete the course.</p>
</div></blockquote>
</section>
<section id="Import-the-Data">
<h2>Import the Data<a class="headerlink" href="#Import-the-Data" title="Permalink to this headline">¶</a></h2>
<section id="Exercise-1">
<h3>Exercise 1<a class="headerlink" href="#Exercise-1" title="Permalink to this headline">¶</a></h3>
<p>Begin by importing Udacity’s data on user behavior by going to <a class="reference external" href="http://www.github/nickeubank/MIDS_Data/">http://www.github/nickeubank/MIDS_Data/</a> and using the <code class="docutils literal notranslate"><span class="pre">udacity_AB_testing</span></code>folder, or by clicking <a class="reference external" href="https://github.com/nickeubank/MIDS_Data/tree/master/udacity_AB_testing">here.</a> Note that there are TWO datasets for this test – one for the control data (users who saw the original design), and one for treatment data (users who saw the experimental design). Udacity decided to show their test site to 1/2 of visitors, so there are
roughly the same number of users appearing in each dataset (though this is not a requirement of AB tests).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># First, load pandas and an extension that</span>
<span class="c1"># applies Black formatting to all cells.</span>

<span class="o">%</span><span class="k">load_ext</span> lab_black
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">control</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;https://media.githubusercontent.com/media/nickeubank/&quot;</span>
    <span class="s2">&quot;MIDS_Data/master/udacity_AB_testing/control_data.csv&quot;</span>
<span class="p">)</span>
<span class="n">treat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;https://media.githubusercontent.com/media/nickeubank/&quot;</span>
    <span class="s2">&quot;MIDS_Data/master/udacity_AB_testing/experiment_data.csv&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Exercise-2">
<h3>Exercise 2<a class="headerlink" href="#Exercise-2" title="Permalink to this headline">¶</a></h3>
<p>Explore the data. Can you identifying the unit of observation of the data (e.g. what is represented by each row)?</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Each row is a single day of behavior for each treatment arm.</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Pick-your-measures">
<h2>Pick your measures<a class="headerlink" href="#Pick-your-measures" title="Permalink to this headline">¶</a></h2>
<section id="Exercise-3">
<h3>Exercise 3<a class="headerlink" href="#Exercise-3" title="Permalink to this headline">¶</a></h3>
<p>The easiest way to analyze this data is to stack it into a single dataset where each observation is a day-treatment-arm (so you should end up with two rows per day, one for those who are in the treated groups, and one for those who were in the control group). Note that currently nothing in the data identifies whether a given observation is a treatment group observation or a control group observation, so you’ll want to make sure to add a “treatment” indicator variable.</p>
<p>The variables in the data are:</p>
<ul class="simple">
<li><p>Pageviews: number of unique users visiting homepage</p></li>
<li><p>Clicks: number of those users clicking “Start Free Trial”</p></li>
<li><p>Enrollments: Number of people enrolling in trial</p></li>
<li><p>Payments: Number of people who eventually pay for the service</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">control</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">treat</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">users</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">control</span><span class="p">,</span> <span class="n">treat</span><span class="p">])</span>
<span class="n">users</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Pageviews</th>
      <th>Clicks</th>
      <th>Enrollments</th>
      <th>Payments</th>
      <th>treatment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Sat, Oct 11</td>
      <td>7723</td>
      <td>687</td>
      <td>134.0</td>
      <td>70.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Sun, Oct 12</td>
      <td>9102</td>
      <td>779</td>
      <td>147.0</td>
      <td>70.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Mon, Oct 13</td>
      <td>10511</td>
      <td>909</td>
      <td>167.0</td>
      <td>95.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Tue, Oct 14</td>
      <td>9871</td>
      <td>836</td>
      <td>156.0</td>
      <td>105.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Wed, Oct 15</td>
      <td>10014</td>
      <td>837</td>
      <td>163.0</td>
      <td>64.0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">users</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Pageviews</th>
      <th>Clicks</th>
      <th>Enrollments</th>
      <th>Payments</th>
      <th>treatment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>32</th>
      <td>Wed, Nov 12</td>
      <td>10042</td>
      <td>802</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Thu, Nov 13</td>
      <td>9721</td>
      <td>829</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Fri, Nov 14</td>
      <td>9304</td>
      <td>770</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Sat, Nov 15</td>
      <td>8668</td>
      <td>724</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Sun, Nov 16</td>
      <td>8988</td>
      <td>710</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Make sure it worked well!</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">users</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">control</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">treat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Exercise-4">
<h3>Exercise 4<a class="headerlink" href="#Exercise-4" title="Permalink to this headline">¶</a></h3>
<p>Given the outcomes of interest to Udacity, what outcomes do you want to measure? (In the language of the Potential Outcomes Framework, what are your <span class="math notranslate nohighlight">\(Y\)</span> variables?). Add these to your data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Udacity wants a decline in the number of people</span>
<span class="c1"># who enroll in a trial but don&#39;t</span>
<span class="c1"># end up continuing (paying) at the end of the trial.</span>
<span class="c1"># So first we want the number of enrollments that end in</span>
<span class="c1"># non-payment per person who sees trial page.</span>

<span class="c1"># Note that because &quot;clicks&quot; is pre-treatment</span>
<span class="c1"># and we have the same number of people in both</span>
<span class="c1"># treatment arms, on average we have the</span>
<span class="c1"># same number of clicks in both groups</span>
<span class="c1"># so you don&#39;t technically have to normalize.</span>

<span class="c1"># It&#39;s also ok to just look at the share of Enrollments</span>
<span class="c1"># that end up as payments.</span>

<span class="n">users</span><span class="p">[</span><span class="s2">&quot;enroll_but_nopayment_per_click&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">users</span><span class="p">[</span><span class="s2">&quot;Enrollments&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">users</span><span class="p">[</span><span class="s2">&quot;Payments&quot;</span><span class="p">]</span>
<span class="p">)</span> <span class="o">/</span> <span class="n">users</span><span class="p">[</span><span class="s2">&quot;Clicks&quot;</span><span class="p">]</span>

<span class="c1"># Second, they don&#39;t want to see a decline in payments, so we also want to measure</span>
<span class="c1"># the conversion rate from clicks to payments. Ideally, this won&#39;t change.</span>

<span class="c1"># Again, dividing by clicks is optional.</span>

<span class="n">users</span><span class="p">[</span><span class="s2">&quot;payments_per_click&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">users</span><span class="p">[</span><span class="s2">&quot;Payments&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">users</span><span class="p">[</span><span class="s2">&quot;Clicks&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Validating-The-Data">
<h2>Validating The Data<a class="headerlink" href="#Validating-The-Data" title="Permalink to this headline">¶</a></h2>
<section id="Exercise-5">
<h3>Exercise 5<a class="headerlink" href="#Exercise-5" title="Permalink to this headline">¶</a></h3>
<p>Whenever you are working with experimental data, the first thing you want to do is verify that users actually were randomly sorted into the two arms of the experiment. In this data, half of users were supposed to be shown the old version of the site and half were supposed to see the new version.</p>
<p><code class="docutils literal notranslate"><span class="pre">Pageviews</span></code> tells you how many unique users visited the welcome site we are experimenting on. <code class="docutils literal notranslate"><span class="pre">Pageviews</span></code> is what is sometimes called an “invariant” variable, meaning that it shouldn’t vary across treatment arms – after all, people have to visit the site before they get a chance to see the treatment, so there’s no way that being assigned to treatment or control should affect the number of pageviews assigned to each group.</p>
<p>“Invariant” variables are also an example of what are known as a “pre-treatment” variable, because pageviews are determined before users are manipulated in any way. That makes it analogous to gender or age in experiments where you have demographic data – a person’s age and gender are determined before they experience any manipulations, so the value of any pre-treatment attributes should be the same across the two arms of our experiment. This is what is called “checking for balance.” If
pre-treatment attributes aren’t balanced, then we know our attempt to randomly assign people to different groups failed.</p>
<p>To test the quality of the randomization, calculate the average number of pageviews for the treated group and for the control group. Do they look similar?</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">users</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Pageviews&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
9315.135135135135
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">users</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Pageviews&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
9339.0
</pre></div></div>
</div>
</section>
<section id="Exercise-6">
<h3>Exercise 6<a class="headerlink" href="#Exercise-6" title="Permalink to this headline">¶</a></h3>
<p>“Similar” is a tricky concept – obviously, we expect <em>some</em> differences across groups since users were <em>randomly</em> divided across treatment arms. The question is whether the differences between groups are larger than we’d expect to emerge given our random assignment process. To evaluate this, let’s use a <code class="docutils literal notranslate"><span class="pre">ttest</span></code> to test the statistical significance of the differences we see.</p>
<p>If you’re using R, you can just use the <code class="docutils literal notranslate"><span class="pre">t.test</span></code> function.</p>
<p>If you’re using Python, you can use the <code class="docutils literal notranslate"><span class="pre">ttest</span></code> function from scipy, which you can import as <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">scipy.stats</span> <span class="pre">import</span> <span class="pre">ttest_ind</span></code>.</p>
<p><strong>Note</strong>: Remember that scipy functions don’t accept <code class="docutils literal notranslate"><span class="pre">pandas</span></code> objects, so you have to pass the numpy vectors underlying your data with the <code class="docutils literal notranslate"><span class="pre">.values</span></code> operator (e.g. <code class="docutils literal notranslate"><span class="pre">df.my_column.values</span></code>).</p>
<p>Does the difference in <code class="docutils literal notranslate"><span class="pre">pageviews</span></code> look statistically significant?</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">ttest_ind</span>

<span class="n">ttest_ind</span><span class="p">(</span>
    <span class="n">users</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Pageviews&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">users</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Pageviews&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ttest_indResult(statistic=-0.1417118298287496, pvalue=0.8877034068650902)
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># p-value of 0.8877 -- nope! Not statistically different at all.</span>
</pre></div>
</div>
</div>
</section>
<section id="Exercise-7">
<h3>Exercise 7<a class="headerlink" href="#Exercise-7" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Pageviews</span></code> is not the only pre-treatment variable in this data. What other measure is pre-treatment? Review the description of the experiment if you’re not sure.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Clicks. The experiment only changes what happens AFTER people click on &quot;free trial&quot;, so clicks are &quot;pre-treatment&quot;,</span>
</pre></div>
</div>
</div>
</section>
<section id="Exercise-8">
<h3>Exercise 8<a class="headerlink" href="#Exercise-8" title="Permalink to this headline">¶</a></h3>
<p>Check if the other pre-treatment variable is also balanced.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ttest_ind</span><span class="p">(</span>
    <span class="n">users</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Clicks&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">users</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Clicks&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ttest_indResult(statistic=-0.09270642968639531, pvalue=0.9263942642482703)
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Yup, good balance! Difference has a p-value of only 0.93!</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Estimating-the-Effect-of-Experiment">
<h2>Estimating the Effect of Experiment<a class="headerlink" href="#Estimating-the-Effect-of-Experiment" title="Permalink to this headline">¶</a></h2>
<section id="Exercise-9">
<h3>Exercise 9<a class="headerlink" href="#Exercise-9" title="Permalink to this headline">¶</a></h3>
<p>Now that we’ve established we have good balance (meaning we think randomization was likely successful), we can evaluate the effects of the experiment. Test whether the two metrics you picked have different average values in the control group and treatment group. Because we’ve randomized, this is a consistent estimate of the Average Treatment Effect of Udacity’s website change.</p>
<p>Did Udacity achieve their goal?</p>
<p><strong>Note:</strong> You may discover some issues with your data. Can you figure out what’s going on, and adjust?</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Because trials last 2 weeks, you don&#39;t get payment</span>
<span class="c1"># stats from the last two weeks of data.</span>
<span class="c1"># So we drop them.</span>

<span class="n">users</span> <span class="o">=</span> <span class="n">users</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">notnull</span><span class="p">(</span><span class="n">users</span><span class="o">.</span><span class="n">Enrollments</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;enroll_but_nopayment_per_click&quot;</span><span class="p">,</span> <span class="s2">&quot;payments_per_click&quot;</span><span class="p">]:</span>
    <span class="n">wo_change</span> <span class="o">=</span> <span class="n">users</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">w_change</span> <span class="o">=</span> <span class="n">users</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">pvalue</span> <span class="o">=</span> <span class="n">ttest_ind</span><span class="p">(</span>
        <span class="n">users</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
        <span class="n">users</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;treatment&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">pvalue</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;change from orig to experiment in </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> is &quot;</span>
        <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="p">(</span><span class="n">w_change</span> <span class="o">-</span> <span class="n">wo_change</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage points&quot;</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;a change of </span><span class="si">{</span><span class="p">((</span><span class="n">w_change</span> <span class="o">-</span> <span class="n">wo_change</span><span class="p">)</span> <span class="o">/</span> <span class="n">wo_change</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;p-value of difference is </span><span class="si">{</span><span class="n">pvalue</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
change from orig to experiment in enroll_but_nopayment_per_click is  -1.6 percentage points
a change of -15.56%
p-value of difference is 0.132


change from orig to experiment in payments_per_click is  -0.5 percentage points
a change of -4.14%
p-value of difference is 0.593


</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># So we do see a decrease in share of people who click trial,</span>
<span class="c1"># enroll but then don&#39;t pay, and it&#39;s borderline significant</span>
<span class="c1"># (has p-value &lt; 0.1 if we had used a 1-tailed tests).</span>
<span class="c1"># But we don&#39;t see a significant decline in share of people who</span>
<span class="c1"># click who end up enrolling after trial,</span>
<span class="c1"># so the change was basically successful in only filtering out</span>
<span class="c1"># people who weren&#39;t really interested.</span>
</pre></div>
</div>
</div>
</section>
<section id="Exercise-10">
<h3>Exercise 10<a class="headerlink" href="#Exercise-10" title="Permalink to this headline">¶</a></h3>
<p>One of the magic things about experiments is that all you have to do is compare averages to get an average treatment effect. However, you <em>can</em> do other things to try and increase the statistical power of your experiments, like add controls in a linear regression model.</p>
<p>As you likely know, a bivariate regression is exactly equivalent to a t-test, so let’s start by re-estimating the effect of treatment on payments-per-click using a linear regression. Can you replicate the results from your t-test? They shouldn’t just be close – they should be numerically equivalent (i.e. exactly the same to the limits of floating point number precision).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s2">&quot;payments_per_click ~ treatment&quot;</span><span class="p">,</span> <span class="n">users</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>payments_per_click</td> <th>  R-squared:         </th> <td>   0.007</td>
</tr>
<tr>
  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>  -0.016</td>
</tr>
<tr>
  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>  0.2903</td>
</tr>
<tr>
  <th>Date:</th>              <td>Wed, 03 Feb 2021</td>  <th>  Prob (F-statistic):</th>  <td> 0.593</td>
</tr>
<tr>
  <th>Time:</th>                  <td>14:27:31</td>      <th>  Log-Likelihood:    </th> <td>  95.810</td>
</tr>
<tr>
  <th>No. Observations:</th>       <td>    46</td>       <th>  AIC:               </th> <td>  -187.6</td>
</tr>
<tr>
  <th>Df Residuals:</th>           <td>    44</td>       <th>  BIC:               </th> <td>  -184.0</td>
</tr>
<tr>
  <th>Df Model:</th>               <td>     1</td>       <th>                     </th>     <td> </td>
</tr>
<tr>
  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>
</tr>
<tr>
  <th>Intercept</th> <td>    0.1183</td> <td>    0.006</td> <td>   18.403</td> <td> 0.000</td> <td>    0.105</td> <td>    0.131</td>
</tr>
<tr>
  <th>treatment</th> <td>   -0.0049</td> <td>    0.009</td> <td>   -0.539</td> <td> 0.593</td> <td>   -0.023</td> <td>    0.013</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.968</td> <th>  Durbin-Watson:     </th> <td>   1.092</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.616</td> <th>  Jarque-Bera (JB):  </th> <td>   0.985</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.316</td> <th>  Prob(JB):          </th> <td>   0.611</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.662</td> <th>  Cond. No.          </th> <td>    2.62</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div>
</div>
</section>
<section id="Exercise-11">
<h3>Exercise 11<a class="headerlink" href="#Exercise-11" title="Permalink to this headline">¶</a></h3>
<p>Now add indicator variables for the day of each observation. Do the standard errors on your <code class="docutils literal notranslate"><span class="pre">treatment</span></code> variable change? If so, in what direction?</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s2">&quot;payments_per_click ~ treatment + C(Date)&quot;</span><span class="p">,</span> <span class="n">users</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>payments_per_click</td> <th>  R-squared:         </th> <td>   0.743</td>
</tr>
<tr>
  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.475</td>
</tr>
<tr>
  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   2.770</td>
</tr>
<tr>
  <th>Date:</th>              <td>Wed, 03 Feb 2021</td>  <th>  Prob (F-statistic):</th>  <td>0.00991</td>
</tr>
<tr>
  <th>Time:</th>                  <td>14:27:31</td>      <th>  Log-Likelihood:    </th> <td>  126.94</td>
</tr>
<tr>
  <th>No. Observations:</th>       <td>    46</td>       <th>  AIC:               </th> <td>  -205.9</td>
</tr>
<tr>
  <th>Df Residuals:</th>           <td>    22</td>       <th>  BIC:               </th> <td>  -162.0</td>
</tr>
<tr>
  <th>Df Model:</th>               <td>    23</td>       <th>                     </th>     <td> </td>
</tr>
<tr>
  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>
</tr>
</table>
<table class="simpletable">
<tr>
             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>
</tr>
<tr>
  <th>Intercept</th>              <td>    0.0815</td> <td>    0.016</td> <td>    5.090</td> <td> 0.000</td> <td>    0.048</td> <td>    0.115</td>
</tr>
<tr>
  <th>C(Date)[T.Fri, Oct 24]</th> <td>    0.0791</td> <td>    0.022</td> <td>    3.569</td> <td> 0.002</td> <td>    0.033</td> <td>    0.125</td>
</tr>
<tr>
  <th>C(Date)[T.Fri, Oct 31]</th> <td>    0.0777</td> <td>    0.022</td> <td>    3.507</td> <td> 0.002</td> <td>    0.032</td> <td>    0.124</td>
</tr>
<tr>
  <th>C(Date)[T.Mon, Oct 13]</th> <td>    0.0179</td> <td>    0.022</td> <td>    0.809</td> <td> 0.427</td> <td>   -0.028</td> <td>    0.064</td>
</tr>
<tr>
  <th>C(Date)[T.Mon, Oct 20]</th> <td>    0.0343</td> <td>    0.022</td> <td>    1.548</td> <td> 0.136</td> <td>   -0.012</td> <td>    0.080</td>
</tr>
<tr>
  <th>C(Date)[T.Mon, Oct 27]</th> <td>    0.0799</td> <td>    0.022</td> <td>    3.604</td> <td> 0.002</td> <td>    0.034</td> <td>    0.126</td>
</tr>
<tr>
  <th>C(Date)[T.Sat, Nov 1]</th>  <td>    0.0612</td> <td>    0.022</td> <td>    2.763</td> <td> 0.011</td> <td>    0.015</td> <td>    0.107</td>
</tr>
<tr>
  <th>C(Date)[T.Sat, Oct 11]</th> <td>   -0.0033</td> <td>    0.022</td> <td>   -0.148</td> <td> 0.884</td> <td>   -0.049</td> <td>    0.043</td>
</tr>
<tr>
  <th>C(Date)[T.Sat, Oct 18]</th> <td>    0.0239</td> <td>    0.022</td> <td>    1.080</td> <td> 0.292</td> <td>   -0.022</td> <td>    0.070</td>
</tr>
<tr>
  <th>C(Date)[T.Sat, Oct 25]</th> <td>    0.0742</td> <td>    0.022</td> <td>    3.347</td> <td> 0.003</td> <td>    0.028</td> <td>    0.120</td>
</tr>
<tr>
  <th>C(Date)[T.Sun, Nov 2]</th>  <td>    0.0405</td> <td>    0.022</td> <td>    1.826</td> <td> 0.081</td> <td>   -0.005</td> <td>    0.086</td>
</tr>
<tr>
  <th>C(Date)[T.Sun, Oct 12]</th> <td>    0.0239</td> <td>    0.022</td> <td>    1.078</td> <td> 0.293</td> <td>   -0.022</td> <td>    0.070</td>
</tr>
<tr>
  <th>C(Date)[T.Sun, Oct 19]</th> <td>    0.0196</td> <td>    0.022</td> <td>    0.887</td> <td> 0.385</td> <td>   -0.026</td> <td>    0.066</td>
</tr>
<tr>
  <th>C(Date)[T.Sun, Oct 26]</th> <td>    0.0673</td> <td>    0.022</td> <td>    3.038</td> <td> 0.006</td> <td>    0.021</td> <td>    0.113</td>
</tr>
<tr>
  <th>C(Date)[T.Thu, Oct 16]</th> <td>    0.0095</td> <td>    0.022</td> <td>    0.430</td> <td> 0.672</td> <td>   -0.036</td> <td>    0.055</td>
</tr>
<tr>
  <th>C(Date)[T.Thu, Oct 23]</th> <td>    0.0161</td> <td>    0.022</td> <td>    0.725</td> <td> 0.476</td> <td>   -0.030</td> <td>    0.062</td>
</tr>
<tr>
  <th>C(Date)[T.Thu, Oct 30]</th> <td>    0.0181</td> <td>    0.022</td> <td>    0.817</td> <td> 0.423</td> <td>   -0.028</td> <td>    0.064</td>
</tr>
<tr>
  <th>C(Date)[T.Tue, Oct 14]</th> <td>    0.0394</td> <td>    0.022</td> <td>    1.779</td> <td> 0.089</td> <td>   -0.007</td> <td>    0.085</td>
</tr>
<tr>
  <th>C(Date)[T.Tue, Oct 21]</th> <td>    0.0226</td> <td>    0.022</td> <td>    1.022</td> <td> 0.318</td> <td>   -0.023</td> <td>    0.069</td>
</tr>
<tr>
  <th>C(Date)[T.Tue, Oct 28]</th> <td>    0.0643</td> <td>    0.022</td> <td>    2.904</td> <td> 0.008</td> <td>    0.018</td> <td>    0.110</td>
</tr>
<tr>
  <th>C(Date)[T.Wed, Oct 15]</th> <td>    0.0157</td> <td>    0.022</td> <td>    0.709</td> <td> 0.486</td> <td>   -0.030</td> <td>    0.062</td>
</tr>
<tr>
  <th>C(Date)[T.Wed, Oct 22]</th> <td>    0.0196</td> <td>    0.022</td> <td>    0.884</td> <td> 0.386</td> <td>   -0.026</td> <td>    0.066</td>
</tr>
<tr>
  <th>C(Date)[T.Wed, Oct 29]</th> <td>    0.0452</td> <td>    0.022</td> <td>    2.040</td> <td> 0.054</td> <td>   -0.001</td> <td>    0.091</td>
</tr>
<tr>
  <th>treatment</th>              <td>   -0.0049</td> <td>    0.007</td> <td>   -0.750</td> <td> 0.461</td> <td>   -0.018</td> <td>    0.009</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 4.114</td> <th>  Durbin-Watson:     </th> <td>   1.713</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.128</td> <th>  Jarque-Bera (JB):  </th> <td>   1.796</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.000</td> <th>  Prob(JB):          </th> <td>   0.407</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.032</td> <th>  Cond. No.          </th> <td>    27.3</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div>
</div>
<p>You should have found that your standard errors decreased by about 20% – this is why, although just comparing means <em>works</em>, if you have additional variables you should add them as covariates in your analysis. Moreover, in other settings you may find this effect is even larger – the date indicators we added to our data are perfectly balanced between treatment and control, so we aren’t adding a lot of data to the model by adding them as variables. As we’ll see in later exercises, adding variables
like “gender” or “age” (which will never be perfectly balanced across treatment and control) will help even more.</p>
</section>
<section id="Exercise-12">
<h3>Exercise 12<a class="headerlink" href="#Exercise-12" title="Permalink to this headline">¶</a></h3>
<p>Given your results, what would you tell Udacity about their trial?</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># It seems like everything is going in the expected direction. However</span>
<span class="c1"># before rolling out something that affects something as important</span>
<span class="c1"># as on-boarding, I would run a longer trial to get a little greater</span>
<span class="c1"># statistical significance...</span>
</pre></div>
</div>
</div>
</section>
<section id="Exercise-13">
<h3>Exercise 13<a class="headerlink" href="#Exercise-13" title="Permalink to this headline">¶</a></h3>
<p>As a last exercise, instead of adding indicators for each date, add indicators for <em>day of the week</em> (e.g. Monday, Tuesday, etc.).</p>
<p>(This is just for data manipulation practice!)</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">users</span><span class="p">[</span><span class="s2">&quot;day_of_week&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">users</span><span class="o">.</span><span class="n">Date</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s2">&quot;payments_per_click ~ treatment + C(day_of_week)&quot;</span><span class="p">,</span> <span class="n">users</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>payments_per_click</td> <th>  R-squared:         </th> <td>   0.138</td>
</tr>
<tr>
  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>  -0.021</td>
</tr>
<tr>
  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>  0.8687</td>
</tr>
<tr>
  <th>Date:</th>              <td>Wed, 03 Feb 2021</td>  <th>  Prob (F-statistic):</th>  <td> 0.540</td>
</tr>
<tr>
  <th>Time:</th>                  <td>14:27:31</td>      <th>  Log-Likelihood:    </th> <td>  99.073</td>
</tr>
<tr>
  <th>No. Observations:</th>       <td>    46</td>       <th>  AIC:               </th> <td>  -182.1</td>
</tr>
<tr>
  <th>Df Residuals:</th>           <td>    38</td>       <th>  BIC:               </th> <td>  -167.5</td>
</tr>
<tr>
  <th>Df Model:</th>               <td>     7</td>       <th>                     </th>     <td> </td>
</tr>
<tr>
  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>
</tr>
</table>
<table class="simpletable">
<tr>
            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>
</tr>
<tr>
  <th>Intercept</th>             <td>    0.1337</td> <td>    0.013</td> <td>    9.971</td> <td> 0.000</td> <td>    0.107</td> <td>    0.161</td>
</tr>
<tr>
  <th>C(day_of_week)[T.Mon]</th> <td>   -0.0082</td> <td>    0.018</td> <td>   -0.461</td> <td> 0.647</td> <td>   -0.044</td> <td>    0.028</td>
</tr>
<tr>
  <th>C(day_of_week)[T.Sat]</th> <td>   -0.0133</td> <td>    0.017</td> <td>   -0.794</td> <td> 0.432</td> <td>   -0.047</td> <td>    0.021</td>
</tr>
<tr>
  <th>C(day_of_week)[T.Sun]</th> <td>   -0.0144</td> <td>    0.017</td> <td>   -0.865</td> <td> 0.393</td> <td>   -0.048</td> <td>    0.019</td>
</tr>
<tr>
  <th>C(day_of_week)[T.Thu]</th> <td>   -0.0377</td> <td>    0.018</td> <td>   -2.113</td> <td> 0.041</td> <td>   -0.074</td> <td>   -0.002</td>
</tr>
<tr>
  <th>C(day_of_week)[T.Tue]</th> <td>   -0.0101</td> <td>    0.018</td> <td>   -0.568</td> <td> 0.574</td> <td>   -0.046</td> <td>    0.026</td>
</tr>
<tr>
  <th>C(day_of_week)[T.Wed]</th> <td>   -0.0254</td> <td>    0.018</td> <td>   -1.425</td> <td> 0.162</td> <td>   -0.062</td> <td>    0.011</td>
</tr>
<tr>
  <th>treatment</th>             <td>   -0.0049</td> <td>    0.009</td> <td>   -0.538</td> <td> 0.594</td> <td>   -0.023</td> <td>    0.014</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.703</td> <th>  Durbin-Watson:     </th> <td>   0.986</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.704</td> <th>  Jarque-Bera (JB):  </th> <td>   0.237</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.155</td> <th>  Prob(JB):          </th> <td>   0.888</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.168</td> <th>  Cond. No.          </th> <td>    9.27</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div>
</div>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Unifying DS</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../class_schedule.html">CLASS SCHEDULE</a></li>
</ul>
<p class="caption"><span class="caption-text">Data Science Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../taxonomy_of_questions.html">Taxonomy of Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../moving_from_problems_to_questions.html">From Problems to Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../descriptive_questions.html">Discretion and Description</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ethical_ml_recommendations.html">Ethical Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../writing_to_stakeholders.html">Writing for Lay Audiences</a></li>
</ul>
<p class="caption"><span class="caption-text">Causal Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../limitations_of_ATE.html">Limitations of ATE</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal_v_external_validity.html">Internal v. External Validity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../evaluating_real_studies.html">Evaluating A Real Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matching_why.html">Matching (Why)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matching_how.html">Matching (How)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../interpreting_indicator_vars.html">Indicator Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fixed_effects.html">Fixed Effects (FEs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fixed_effects_and_causal_inference.html">FEs &amp; Causality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fixed_effects_v_hierarchical.html">FEs &amp; Hierarchical Models</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Nick Eubank.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.0.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/exercises/solutions_abtesting.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-151397036-1']);
      _gaq.push(['_setDomainName', 'none']);
      _gaq.push(['_setAllowLinker', true]);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    
  </body>
</html>