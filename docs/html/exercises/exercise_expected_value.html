<!DOCTYPE html> <html lang=en  data-content_root="../"> <meta charset=utf-8  /> <meta name=viewport  content="width=device-width, initial-scale=1.0" /><meta name=viewport  content="width=device-width, initial-scale=1" /> <meta name=viewport  content="width=device-width,initial-scale=1"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name="lang:clipboard.copy" content="Copy to clipboard"> <meta name="lang:clipboard.copied" content="Copied to clipboard"> <meta name="lang:search.language" content=en > <meta name="lang:search.pipeline.stopwords" content=True > <meta name="lang:search.pipeline.trimmer" content=True > <meta name="lang:search.result.none" content="No matching documents"> <meta name="lang:search.result.one" content="1 matching document"> <meta name="lang:search.result.other" content="# matching documents"> <meta name="lang:search.tokenizer" content="[\s\-]+"> <link href="https://fonts.gstatic.com/" rel=preconnect  crossorigin> <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel=stylesheet > <style> body, input { font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif } code, kbd, pre { font-family: "Roboto Mono", "Courier New", Courier, monospace } </style> <link rel=stylesheet  href="../_static/stylesheets/application.css"/> <link rel=stylesheet  href="../_static/stylesheets/application-palette.css"/> <link rel=stylesheet  href="../_static/stylesheets/application-fixes.css"/> <link rel=stylesheet  href="../_static/fonts/material-icons.css"/> <meta name=theme-color  content="#2196f3"> <script src="../_static/javascripts/modernizr.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-151397036-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'UA-151397036-1'); </script> <title>Decision Making from AB Testing &#8212; Unifying Data Science</title> <link rel=stylesheet  type="text/css" href="../_static/pygments.css?v=649a27d8" /> <link rel=stylesheet  type="text/css" href="../_static/material.css?v=79c92029" /> <link rel=stylesheet  type="text/css" href="../_static/nbsphinx-code-cells.css?v=14571329" /> <script src="../_static/documentation_options.js?v=5929fcd5"></script> <script src="../_static/doctools.js?v=888ff710"></script> <script src="../_static/sphinx_highlight.js?v=dc90522c"></script> <script crossorigin=anonymous  integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script> <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script> <script defer=defer  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <link rel=icon  href="../_static/mids_logo.svg"/> <link rel=index  title=Index  href="../genindex.html" /> <link rel=search  title=Search  href="../search.html" /> <body dir=ltr data-md-color-primary=blue-grey data-md-color-accent=blue> <svg class=md-svg > <defs data-children-count=0 > <svg xmlns="http://www.w3.org/2000/svg" width=416  height=448  viewBox="0 0 416 448" id=__github ><path fill=currentColor  d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle  data-md-toggle=drawer  type=checkbox  id=__drawer > <input class=md-toggle  data-md-toggle=search  type=checkbox  id=__search > <label class=md-overlay  data-md-component=overlay  for=__drawer ></label> <a href="#exercises/exercise_expected_value" tabindex=1  class=md-skip > Skip to content </a> <header class=md-header  data-md-component=header > <nav class="md-header-nav md-grid"> <div class="md-flex navheader"> <div class="md-flex__cell md-flex__cell--shrink"> <a href="../index.html" title="Unifying Data Science" class="md-header-nav__button md-logo"> &nbsp; </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer ></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title > <span class=md-header-nav__topic >Unifying Data Science</span> <span class=md-header-nav__topic > Decision Making from AB Testing </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search ></label> <div class=md-search  data-md-component=search  role=dialog > <label class=md-search__overlay  for=__search ></label> <div class=md-search__inner  role=search > <form class=md-search__form  action="../search.html" method=get  name=search > <input type=text  class=md-search__input  name=q  placeholder=""Search"" autocapitalize=off  autocomplete=off  spellcheck=false  data-md-component=query  data-md-state=active > <label class="md-icon md-search__icon" for=__search ></label> <button type=reset  class="md-icon md-search__icon" data-md-component=reset  tabindex=-1 > &#xE5CD; </button> </form> <div class=md-search__output > <div class=md-search__scrollwrap  data-md-scrollfix> <div class=md-search-result  data-md-component=result > <div class=md-search-result__meta > Type to start searching </div> <ol class=md-search-result__list ></ol> </div> </div> </div> </div> </div> </div> <script src="../_static/javascripts/version_dropdown.js"></script> <script> var json_loc = "../"versions.json"", target_loc = "../../", text = "Versions"; $( document ).ready( add_version_dropdown(json_loc, target_loc, text)); </script> </div> </nav> </header> <div class=md-container > <nav class=md-tabs  data-md-component=tabs > <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list > <li class=md-tabs__item ><a href="../index.html" class=md-tabs__link >Home</a> <li class=md-tabs__item ><a href="../class_schedule.html" class=md-tabs__link >Class Schedule</a> <li class=md-tabs__item ><a href="../topic_list.html" class=md-tabs__link >Topic List</a> <li class=md-tabs__item ><a href="https://www.nickeubank.com" class=md-tabs__link >About The Author</a> </ul> </div> </nav> <main class=md-main > <div class="md-main__inner md-grid" data-md-component=container > <div class="md-sidebar md-sidebar--primary" data-md-component=navigation > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--primary" data-md-level=0 > <label class="md-nav__title md-nav__title--site" for=__drawer > <a href="../index.html" title="Unifying Data Science" class="md-nav__button md-logo"> <img src="../_static/" alt=" logo" width=48  height=48 > </a> <a href="../index.html" title="Unifying Data Science">Unifying Data Science</a> </label> <ul class=md-nav__list > <li class=md-nav__item > <a href="../class_schedule.html" class=md-nav__link >CLASS SCHEDULE</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Causal Inference</span></span> <li class=md-nav__item > <a href="../limitations_of_ATE.html" class=md-nav__link >Limitations of ATE</a> <li class=md-nav__item > <a href="../internal_v_external_validity.html" class=md-nav__link >Internal v. External Validity</a> <li class=md-nav__item > <a href="../evaluating_real_studies.html" class=md-nav__link >Evaluating A Real Study</a> <li class=md-nav__item > <a href="../causal_inference_beyond_ab_testing.html" class=md-nav__link >Beyond AB Testing</a> <li class=md-nav__item > <a href="../matching_why.html" class=md-nav__link >Matching (Why)</a> <li class=md-nav__item > <a href="../matching_how.html" class=md-nav__link >Matching (How)</a> <li class=md-nav__item > <a href="../interpreting_indicator_vars.html" class=md-nav__link >Indicator Variables</a> <li class=md-nav__item > <a href="../fixed_effects.html" class=md-nav__link >Fixed Effects (FEs)</a> <li class=md-nav__item > <a href="../fixed_effects_and_causal_inference.html" class=md-nav__link >FEs & Causality</a> <li class=md-nav__item > <a href="../fixed_effects_v_hierarchical.html" class=md-nav__link >FEs & Hierarchical Models</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Data Science Project Design</span></span> <li class=md-nav__item > <a href="../backwards_design.html" class=md-nav__link >Backwards Design</a> <li class=md-nav__item > <a href="../taxonomy_of_questions.html" class=md-nav__link >Taxonomy of Questions</a> <li class=md-nav__item > <a href="../moving_from_problems_to_questions.html" class=md-nav__link >From Problems to Questions</a> <li class=md-nav__item > <a href="../descriptive_questions.html" class=md-nav__link >Discretion and Description</a> <li class=md-nav__item > <a href="../ethical_ml_recommendations.html" class=md-nav__link >Ethical Machine Learning</a> <li class=md-nav__item > <a href="../writing_to_stakeholders.html" class=md-nav__link >Writing for Lay Audiences</a> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--secondary"> <label class=md-nav__title  for=__toc >"Contents"</label> <ul class=md-nav__list  data-md-scrollfix=""> <li class=md-nav__item ><a href="#exercises-exercise-expected-value--page-root" class=md-nav__link >Decision Making from AB Testing</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-Context" class=md-nav__link >Exercise Context</a> <li class=md-nav__item ><a href="#Exercises" class=md-nav__link >Exercises</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-1" class=md-nav__link >Exercise 1</a> <li class=md-nav__item ><a href="#Exercise-2" class=md-nav__link >Exercise 2</a> <li class=md-nav__item ><a href="#Exercise-3" class=md-nav__link >Exercise 3</a> <li class=md-nav__item ><a href="#Exercise-4" class=md-nav__link >Exercise 4</a> </ul> </nav> <li class=md-nav__item ><a href="#Bootstrapping" class=md-nav__link >Bootstrapping</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#id1" class=md-nav__link >Exercise 4</a> <li class=md-nav__item ><a href="#Exercise-7" class=md-nav__link >Exercise 7</a> </ul> </nav> <li class=md-nav__item ><a href="#Interpreting-Our-Estimates" class=md-nav__link >Interpreting Our Estimates</a> <li class=md-nav__item ><a href="#Outcome-Simulation" class=md-nav__link >Outcome Simulation</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-8" class=md-nav__link >Exercise 8</a> <li class=md-nav__item ><a href="#You-Did-It!" class=md-nav__link >You Did It!</a> <li class=md-nav__item ><a href="#Exercise-9" class=md-nav__link >Exercise 9</a> <li class=md-nav__item ><a href="#Exercise-10" class=md-nav__link >Exercise 10</a> <li class=md-nav__item ><a href="#Exercise-11" class=md-nav__link >Exercise 11</a> <li class=md-nav__item ><a href="#Exercise-12" class=md-nav__link >Exercise 12</a> </ul> </nav> <li class=md-nav__item ><a href="#The-Math" class=md-nav__link >The Math</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Bayes-Rule-and-Frequentist-Statistics" class=md-nav__link >Bayes Rule and Frequentist Statistics</a> <li class=md-nav__item ><a href="#OK,-why-do-I-care?" class=md-nav__link >OK, why do I care?</a> <li class=md-nav__item ><a href="#Reason-1:-It-is-critically-important-that-you-understand-what-p-values-and-other-Frequentist-statistics-are,-and-what-they-are-not." class=md-nav__link >Reason 1: It is <em>critically</em> important that you understand what p-values and other Frequentist statistics are, and what they are not.</a> <li class=md-nav__item ><a href="#Reason-2:-There-is-a-special-case-where-P(ATE|-X)-=-P(X|-ATE)" class=md-nav__link >Reason 2: There <em>is</em> a special case where <span class="math notranslate nohighlight">\(P(ATE| X) = P(X| ATE)\)</span></a> </ul> </nav> </ul> </nav> </ul> </nav> </div> </div> </div> <div class=md-content > <article class="md-content__inner md-typeset" role=main > <section id=Decision-Making-from-AB-Testing > <h1 id=exercises-exercise-expected-value--page-root >Decision Making from AB Testing<a class=headerlink  href="#exercises-exercise-expected-value--page-root" title="Link to this heading">¶</a></h1> <p>Most presentations of A/B testing tend to emphasize a binary approach to decision making: we run an AB test, then evaluate whether we can reject the null hypothesis of no effect. If we reject the null hypothesis of no effect, then we deploy the change; if not, we maintain the status quo.</p> <p>We have also seen some approaches that bring a little much needed nuance to this approach: in our <a class="reference external" href="https://www.amazon.com/Trustworthy-Online-Controlled-Experiments-Practical/dp/1108724264">Trustworthy Online Controlled Experiments</a>, the authors have emphasized that we should evaluate <em>both</em></p> <ul class=simple > <li><p>Can we reject the null hypothesis of no effect (to establish our results are statistically significant), and</p> <li><p>Whether the estimated effect is of <em>practical significance</em>, by which they mean “does the effect size look large enough that it would be profitable to deploy.”</p> </ul> <p>And finally, you’ve probably seen cases that do the thing you should probably be doing (at least within this regime):</p> <ul class=simple > <li><p>Rather than evaluating statistical significance with respect to a null hypothesis of no effect, evaluate statistical significance with respect to a null hypothesis of “the effect is less than the size needed for deployment to be profitable (i.e., less than or equal to the threshold for practical significance).”</p> </ul> <p>In these exercises, we will examine an approach to analyzing the results of an A/B test that is a little less black and white, and I think provides a more holistic, easy to understand, and sophisticated way of interpreting A/B test results. It comes with a couple caveats, but I’d argue none that don’t apply to the approaches described above.</p> <p>In short, under this approach we use all available information to characterize the distribution of our estimated effect. We can do this either by approach our analysis from a maximum likelihood perspective or using bootstrapping. Then we will use a kind of Monte Carlo / simulation based approach to model the likelihood of different outcomes, not just in terms of the likelihood of different estimates of the treatment effect, but also the likelihood different economic outcomes (which are a function of the treatment effect).</p> <p>To make this approach concrete, we will start by doing some exercises in which this approach is demonstrated. After that, we will circle back to discuss the pros and cons of this approach in detail.</p> <section id=Exercise-Context > <h2 id=Exercise-Context >Exercise Context<a class=headerlink  href="#Exercise-Context" title="Link to this heading">¶</a></h2> <p>In these exercises, we will be working with a tweaked version of data from <a class="reference external" href="https://www.kaggle.com/datasets/chebotinaa/fast-food-marketing-campaign-ab-test">IBM Watson Analytics from a marketing A/B test conducted in the state of Washington.</a></p> <p>The context in which this data was generated is:</p> <blockquote> <div><p>A fast-food chain plans to add a new item to its menu. However, they are still undecided whether to run a new marketing campaign for promoting the new product. In order to determine whether the promotion will increase sales, a promotion has been deployed at a random sample of stores to promote the new item. Weekly sales of the new item are recorded for the first four weeks.</p> </div></blockquote> <p>The data consists of the following variables:</p> <ul class=simple > <li><p><code class="docutils literal notranslate"><span class=pre >MarketID</span></code>: unique identifier for market</p> <li><p><code class="docutils literal notranslate"><span class=pre >MarketSize</span></code>: size of market area by sales</p> <li><p><code class="docutils literal notranslate"><span class=pre >LocationID</span></code>: unique identifier for store location</p> <li><p><code class="docutils literal notranslate"><span class=pre >AgeOfStore</span></code>: age of store in years</p> <li><p><code class="docutils literal notranslate"><span class=pre >Promotion</span></code>: did the location receive the promotion (was it treated).</p> <li><p><code class="docutils literal notranslate"><span class=pre >week</span></code>: one of four weeks when the promotions were run</p> <li><p><code class="docutils literal notranslate"><span class=pre >SalesInThousands</span></code>: sales amount for a specific <code class="docutils literal notranslate"><span class=pre >LocationID</span></code>, <code class="docutils literal notranslate"><span class=pre >Promotion</span></code>, and <code class="docutils literal notranslate"><span class=pre >week</span></code></p> </ul> <p>(And yes, despite my general distaste for them, this is a pretty darn clean dataset. You’re welcome. :) )</p> </section> <section id=Exercises > <h2 id=Exercises >Exercises<a class=headerlink  href="#Exercises" title="Link to this heading">¶</a></h2> <section id=Exercise-1 > <h3 id=Exercise-1 >Exercise 1<a class=headerlink  href="#Exercise-1" title="Link to this heading">¶</a></h3> <p>Load the dataset — <code class="docutils literal notranslate"><span class=pre >WA_Marketing_Campaign.csv</span></code> from <a class="reference external" href="https://github.com/nickeubank/MIDS_Data/tree/master/fast_food_ab_test">this repository.</a> Please use this copy as I’ve made a couple small modifications to the data for this exercise.</p> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[1]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >pandas</span> <span class=k >as</span> <span class=nn >pd</span>
<span class=kn >import</span> <span class=nn >numpy</span> <span class=k >as</span> <span class=nn >np</span>

<span class=n >pd</span><span class=o >.</span><span class=n >set_option</span><span class=p >(</span><span class=s2 >"mode.copy_on_write"</span><span class=p >,</span> <span class=kc >True</span><span class=p >)</span>

<span class=n >weekly_sales</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >read_csv</span><span class=p >(</span>
    <span class=s2 >"https://github.com/nickeubank/MIDS_Data/raw/"</span>
    <span class=s2 >"master/fast_food_ab_test/WA_Marketing_Campaign.csv"</span>
<span class=p >)</span>
</pre></div> </div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[2]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >weekly_sales</span><span class=p >[</span><span class=s2 >"Promotion"</span><span class=p >]</span><span class=o >.</span><span class=n >value_counts</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[2]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
Promotion
0    188
1    172
Name: count, dtype: int64
</pre></div></div> </div> </section> <section id=Exercise-2 > <h3 id=Exercise-2 >Exercise 2<a class=headerlink  href="#Exercise-2" title="Link to this heading">¶</a></h3> <p>To simplify the analysis, let’s sum up sales from across all four weeks for each store so we only have one observation per store. That way we won’t need to worry about the panel structure of the data.</p> <p>(In a dataset where multiple observations come from the same entity at different points in time, a proper analysis requires accounting for the fact that the different observations for each entity are not independent of one another. We’ll talk about that in a later class.)</p> <p>You should end up with 90 observations (one per <code class="docutils literal notranslate"><span class=pre >LocationID</span></code>).</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[3]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >weekly_sales</span><span class=p >[</span><span class=s2 >"total_sales"</span><span class=p >]</span> <span class=o >=</span> <span class=n >weekly_sales</span><span class=o >.</span><span class=n >groupby</span><span class=p >(</span><span class=s2 >"LocationID"</span><span class=p >)[</span>
    <span class=s2 >"SalesInThousands"</span>
<span class=p >]</span><span class=o >.</span><span class=n >transform</span><span class=p >(</span><span class=n >np</span><span class=o >.</span><span class=n >sum</span><span class=p >)</span>

<span class=n >sales</span> <span class=o >=</span> <span class=n >weekly_sales</span><span class=o >.</span><span class=n >drop</span><span class=p >(</span><span class=n >columns</span><span class=o >=</span><span class=p >[</span><span class=s2 >"week"</span><span class=p >,</span> <span class=s2 >"SalesInThousands"</span><span class=p >])</span><span class=o >.</span><span class=n >drop_duplicates</span><span class=p >()</span>
<span class=k >assert</span> <span class=ow >not</span> <span class=n >sales</span><span class=o >.</span><span class=n >LocationID</span><span class=o >.</span><span class=n >duplicated</span><span class=p >()</span><span class=o >.</span><span class=n >any</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area stderr docutils container"> <div class=highlight ><pre>
/var/folders/fs/h_8_rwsn5hvg9mhp0txgc_s9v6191b/T/ipykernel_72247/3645032325.py:3: FutureWarning: The provided callable &lt;function sum at 0x113562f20&gt; is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string "sum" instead.
  ].transform(np.sum)
</pre></div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[4]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"</span><span class=si >{</span><span class=nb >len</span><span class=p >(</span><span class=n >sales</span><span class=p >)</span><span class=si >}</span><span class=s2 > observations left."</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
90 observations left.
</pre></div></div> </div> </section> <section id=Exercise-3 > <h3 id=Exercise-3 >Exercise 3<a class=headerlink  href="#Exercise-3" title="Link to this heading">¶</a></h3> <p>Now, using a simple linear regression in <code class="docutils literal notranslate"><span class=pre >statsmodels</span></code>, estimate the simple difference in means between stores with and without the promotion.</p> <p>(We’re skipping a lot of “learn about your data” and “validate your randomization by checking balance” steps — this is bad practice, but again I want us to stay focused on the analysis and interpretation for this exercise, so you can just trust it’s ok.)</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[5]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >statsmodels.formula.api</span> <span class=k >as</span> <span class=nn >smf</span>

<span class=n >fit_model</span> <span class=o >=</span> <span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span><span class=s2 >"total_sales ~ Promotion"</span><span class=p >,</span> <span class=n >sales</span><span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span>
<span class=n >fit_model</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[5]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>OLS Regression Results</caption> <tr> <th>Dep. Variable: <td>total_sales <th> R-squared: <td> 0.007 <tr> <th>Model: <td>OLS <th> Adj. R-squared: <td> -0.004 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 0.6386 <tr> <th>Date: <td>Wed, 20 Mar 2024 <th> Prob (F-statistic): <td> 0.426 <tr> <th>Time: <td>21:37:25 <th> Log-Likelihood: <td> -502.19 <tr> <th>No. Observations: <td> 90 <th> AIC: <td> 1008. <tr> <th>Df Residuals: <td> 88 <th> BIC: <td> 1013. <tr> <th>Df Model: <td> 1 <th> <td> <tr> <th>Covariance Type: <td>nonrobust <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 221.4579 <td> 9.461 <td> 23.408 <td> 0.000 <td> 202.656 <td> 240.259 <tr> <th>Promotion <td> 10.9382 <td> 13.687 <td> 0.799 <td> 0.426 <td> -16.262 <td> 38.139 </table> <table> <tr> <th>Omnibus: <td>10.731 <th> Durbin-Watson: <td> 0.164 <tr> <th>Prob(Omnibus): <td> 0.005 <th> Jarque-Bera (JB): <td> 12.033 <tr> <th>Skew: <td> 0.891 <th> Prob(JB): <td> 0.00244 <tr> <th>Kurtosis: <td> 2.825 <th> Cond. No. <td> 2.57 </table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div> </div> </section> <section id=Exercise-4 > <h3 id=Exercise-4 >Exercise 4<a class=headerlink  href="#Exercise-4" title="Link to this heading">¶</a></h3> <p>We obviously have some good controls in this dataset, so add in categorical controls for <code class="docutils literal notranslate"><span class=pre >MarketID</span></code> and <code class="docutils literal notranslate"><span class=pre >log(AgeOfStore)</span></code>.</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[6]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >fit_model</span> <span class=o >=</span> <span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span>
    <span class=s2 >"total_sales ~ Promotion + C(MarketID) + np.log(AgeOfStore)"</span><span class=p >,</span>
    <span class=n >sales</span><span class=p >,</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span>
<span class=n >fit_model</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[6]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>OLS Regression Results</caption> <tr> <th>Dep. Variable: <td>total_sales <th> R-squared: <td> 0.977 <tr> <th>Model: <td>OLS <th> Adj. R-squared: <td> 0.974 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 298.3 <tr> <th>Date: <td>Wed, 20 Mar 2024 <th> Prob (F-statistic): <td>6.30e-59 <tr> <th>Time: <td>21:37:25 <th> Log-Likelihood: <td> -333.20 <tr> <th>No. Observations: <td> 90 <th> AIC: <td> 690.4 <tr> <th>Df Residuals: <td> 78 <th> BIC: <td> 720.4 <tr> <th>Df Model: <td> 11 <th> <td> <tr> <th>Covariance Type: <td>nonrobust <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 143.3495 <td> 4.939 <td> 29.024 <td> 0.000 <td> 133.517 <td> 153.182 <tr> <th>C(MarketID)[T.2] <td> 103.6022 <td> 5.803 <td> 17.854 <td> 0.000 <td> 92.050 <td> 115.155 <tr> <th>C(MarketID)[T.3] <td> 197.9546 <td> 4.675 <td> 42.345 <td> 0.000 <td> 188.648 <td> 207.262 <tr> <th>C(MarketID)[T.4] <td> 73.4474 <td> 6.025 <td> 12.191 <td> 0.000 <td> 61.453 <td> 85.441 <tr> <th>C(MarketID)[T.5] <td> 62.1848 <td> 5.525 <td> 11.254 <td> 0.000 <td> 51.185 <td> 73.185 <tr> <th>C(MarketID)[T.6] <td> 3.9928 <td> 5.133 <td> 0.778 <td> 0.439 <td> -6.225 <td> 14.211 <tr> <th>C(MarketID)[T.7] <td> 37.4080 <td> 4.942 <td> 7.569 <td> 0.000 <td> 27.569 <td> 47.247 <tr> <th>C(MarketID)[T.8] <td> 50.4497 <td> 5.011 <td> 10.069 <td> 0.000 <td> 40.474 <td> 60.425 <tr> <th>C(MarketID)[T.9] <td> 66.3807 <td> 5.322 <td> 12.473 <td> 0.000 <td> 55.786 <td> 76.976 <tr> <th>C(MarketID)[T.10] <td> 79.7188 <td> 5.150 <td> 15.478 <td> 0.000 <td> 69.465 <td> 89.972 <tr> <th>Promotion <td> 19.4720 <td> 2.353 <td> 8.276 <td> 0.000 <td> 14.788 <td> 24.156 <tr> <th>np.log(AgeOfStore) <td> -1.2697 <td> 1.302 <td> -0.975 <td> 0.333 <td> -3.863 <td> 1.323 </table> <table> <tr> <th>Omnibus: <td>10.090 <th> Durbin-Watson: <td> 2.215 <tr> <th>Prob(Omnibus): <td> 0.006 <th> Jarque-Bera (JB): <td> 10.333 <tr> <th>Skew: <td> 0.685 <th> Prob(JB): <td> 0.00570 <tr> <th>Kurtosis: <td> 3.937 <th> Cond. No. <td> 26.0 </table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div> </div> </section> </section> <section id=Bootstrapping > <h2 id=Bootstrapping >Bootstrapping<a class=headerlink  href="#Bootstrapping" title="Link to this heading">¶</a></h2> <p>When we run a linear regression — like the one above — standard errors are calculated under the assumption that certain assumptions about our data are true. Generally speaking, those are that our regression errors are normally distributed and homoskedastic.</p> <p>These analytically-derived standard errors are not the only way one can calculate standard errors, however. A different approach — and one whose validity does not rest on any distributional assumptions: bootstrapping.</p> <p>Within Frequentist statistics, the meaning of standard errors is “how would our estimates vary if we conducted our study all over again, drawing a new set of observations from the same population each time?”</p> <p>Bootstrapping takes this idea seriously. Essentially bootstrapping is the process of simulating drawing new observations from the larger population and observing how our estimate varies across different draws of data. In doing so, bootstrapping only relies on the idea that our data was randomly drawn from a larger population, not any distributional assumptions. In most cases, that makes it much more robust.</p> <p>OK, but obviously we can’t go re-run this marketing experiment again, so how do we get more data? It turns out that sampling from our actual data <em>with replacement</em> to get new datasets of the same size as our original dataset is a statistically valid way to simulate re-running the experiment.</p> <section id=id1 > <h3 id=id1 >Exercise 4<a class=headerlink  href="#id1" title="Link to this heading">¶</a></h3> <p>To create a bootstrapped estimate of the difference in means between treatment and control, create a loop that runs 10,000 times, and at each step:</p> <ol class="arabic simple"> <li><p>Creates a new dataset by sampling — with replacement — from our original dataset. This new dataset should be the same size as our original dataset.</p> <li><p>Runs the regression we specified above (total sales over four weeks regressed on <code class="docutils literal notranslate"><span class=pre >Promotion</span></code>, <code class="docutils literal notranslate"><span class=pre >MarketID</span></code>, and <code class="docutils literal notranslate"><span class=pre >log(AgeOfStore)</span></code>).</p> <li><p>Extracts the coefficient on <code class="docutils literal notranslate"><span class=pre >Promotion</span></code> from said regression and stores it in a new series or numpy array.</p> </ol> <p>As usual with loops, don’t try and write the final loop all at once — put together one pass, then put it in a loop that runs a few times, then finally a loop that runs all 100,000 times.</p> <p>(Note: the reason we collapsed our data to one-observation-per-LocationID is that if we’d still had multiple weeks per store, we’d have to re-sample our data a little differently. In particular, we’d have to randomly draw from a list of stores, then pull all the observations per store to simulate “drawing” new <em>stores</em> with replacement, rather than drawing observations with replacement.)</p> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[7]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >STEPS</span> <span class=o >=</span> <span class=mi >10_000</span>
<span class=n >estimates</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >Series</span><span class=p >(</span><span class=n >index</span><span class=o >=</span><span class=nb >range</span><span class=p >(</span><span class=n >STEPS</span><span class=p >))</span>
<span class=k >for</span> <span class=n >i</span> <span class=ow >in</span> <span class=nb >range</span><span class=p >(</span><span class=n >STEPS</span><span class=p >):</span>
    <span class=n >new_data</span> <span class=o >=</span> <span class=n >sales</span><span class=o >.</span><span class=n >sample</span><span class=p >(</span><span class=nb >len</span><span class=p >(</span><span class=n >sales</span><span class=p >),</span> <span class=n >replace</span><span class=o >=</span><span class=kc >True</span><span class=p >)</span>
    <span class=n >model</span> <span class=o >=</span> <span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span>
        <span class=s2 >"total_sales ~ Promotion + C(MarketID) + np.log(AgeOfStore)"</span><span class=p >,</span> <span class=n >new_data</span>
    <span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span>
    <span class=n >estimates</span><span class=o >.</span><span class=n >iloc</span><span class=p >[</span><span class=n >i</span><span class=p >]</span> <span class=o >=</span> <span class=n >model</span><span class=o >.</span><span class=n >params</span><span class=p >[</span><span class=s2 >"Promotion"</span><span class=p >]</span>
</pre></div> </div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[8]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"Average estimate is </span><span class=si >{</span><span class=n >estimates</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span><span class=si >:</span><span class=s2 >.3f</span><span class=si >}</span><span class=s2 >"</span><span class=p >)</span>
<span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"Standard deviation is </span><span class=si >{</span><span class=n >estimates</span><span class=o >.</span><span class=n >std</span><span class=p >()</span><span class=si >:</span><span class=s2 >.3f</span><span class=si >}</span><span class=s2 >"</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
Average estimate is 19.459
Standard deviation is 2.288
</pre></div></div> </div> </section> <section id=Exercise-7 > <h3 id=Exercise-7 >Exercise 7<a class=headerlink  href="#Exercise-7" title="Link to this heading">¶</a></h3> <p>What is the average value of your bootstrapped estimate? What is the standard deviation? Finally, plot a histogram of your estimates.</p> <p>If it’s helpful, recall that pandas Series have a <code class="docutils literal notranslate"><span class=pre >.hist()</span></code> method for this purpose.</p> <p>How do they compare with your regression estimates?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[9]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >estimates</span><span class=o >.</span><span class=n >hist</span><span class=p >(</span><span class=n >bins</span><span class=o >=</span><span class=mi >20</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[9]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
&lt;Axes: &gt;
</pre></div></div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <img alt="../_images/exercises_exercise_expected_value_16_1.png" src="../_images/exercises_exercise_expected_value_16_1.png"/> </div> </div> </section> </section> <section id=Interpreting-Our-Estimates > <h2 id=Interpreting-Our-Estimates >Interpreting Our Estimates<a class=headerlink  href="#Interpreting-Our-Estimates" title="Link to this heading">¶</a></h2> <p>As you will have likely noticed, in this case the bootstrapped estimates of the difference in means between stores with the promotion and without have a very similar mean and standard deviation to the estimates in our linear regression (the standard deviation of the bootstrapped estimates correspond to the standard errors in the regression). That is because, in this case, our regression errors were relatively normally distributed and homoskedastic, meaning that the standard errors calculated analytically by <code class="docutils literal notranslate"><span class=pre >statsmodels</span></code> are actually quite accurate. Indeed, you can also see that our bootstrapped estimates of the difference in means is relatively normally distributed, another consequence of the regression errors being relatively normally distributed. But as we’ll see soon, in addition to getting experience with bootstrapping, this approach facilitates something else we want to do.</p> <p>Before we move on, though, I want to pause for a moment to reflect on how these estimates can be interpreted.</p> <p>The histogram you plotted above is, technically, an empirical distribution of our estimate of the difference in means between our control stores and those with the promotion. And if we assume that the various assumptions required for a difference in means in an experiment to be a valid estimate of an Average Treatment Effect, then this is also the <strong>empirical distribution of our estimate of the Average Treatment Effect.</strong></p> <p>But there’s an additional way of thinking about this distribution: in a world where we know nothing about the promotion we’re studying except the results of the statistical analysis, this is also our best guess for the probability distribution of the <em>true</em> Average Treatment Effect.</p> <p>And indeed, given the regression errors for this data are relatively normally distributed, the same could also be said of the results we got from <code class="docutils literal notranslate"><span class=pre >statsmodels</span></code> — as you may recall, a linear regression is numerically equivalent to the Maximum Likelihood Estimator for normally distributed data, meaning we could also say that our best guess for the probability distribution of the value of the Average Treatment Effect is that it is roughly normally distributed with a mean of our original regression coefficient (-19) and a standard deviation of 2.3.</p> <p>Before I make the statisticians upset, I need to emphasize that the caveat above — that this is only true <strong>in a world where we know nothing about the likely effect of the promotion except the results of the statistical analysis</strong> — is a big one. In the language of Bayesian statistics, saying we know nothing except the results of this analysis is analogous to saying we have “uninformative priors.” And that’s not a small thing — for example, the company that launched this campaign presumably at least <em>suspects</em> the promotion will improve sales. And based on its experience with past promotions, it is also probably pretty confident of the <em>approximate</em> magnitude of the biggest effect it may detect. For example, they probably know it won’t 10x sales. And if we were doing a proper Bayesian analysis, we would take that kind of information into account by introducing what are called “weakly informative priors.” (For a more detailed discussion with equations, hang on till the end of this exercise.)</p> <p>Nevertheless, I think there is merit in understanding this way of interpreting these results. Yes, a fully Bayesian empirical analysis would likely generate somewhat different results, but unless you are using informative priors (asserting you have a moderate sense of the likely effect of the promotion), the results you get will be relatively similar to what we are getting here. And I think there is merit in understanding this point as the place where these two approaches to statistics coincide, as it were.</p> <p>And in doing so, I hope this will also provide you with a way to think about our estimates in a richer manner — even if we know it’s not exactly right because we know this analysis isn’t the <em>only</em> thing we know about the world — than the binary, black and white world of A/B testing.</p> </section> <section id=Outcome-Simulation > <h2 id=Outcome-Simulation >Outcome Simulation<a class=headerlink  href="#Outcome-Simulation" title="Link to this heading">¶</a></h2> <p>Interpreting the result above as the probability distribution of the <em>true</em> Average Treatment Effect is only interesting if we find a way to do something with it. So let’s have some fun using Monte Carlos simulation techniques.</p> <p>Suppose we chose to deploy our promotion — what is likely to happen? We know that the most likely outcome is that the promotion will improve sales by our estimated ATE, but what are the range of possible outcomes? Even if we expect the promotion will <em>probably</em> make money, maybe what you’re really worried about is loss-avoidance, in which case what you want to know is actually “what are the odds we <em>lose</em> money?” And how can we integrate information about the cost economics of the promotion into how we answer those questions? Let’s find out!</p> <section id=Exercise-8 > <h3 id=Exercise-8 >Exercise 8<a class=headerlink  href="#Exercise-8" title="Link to this heading">¶</a></h3> <p>Let’s start with a simple example. Suppose that our promotion has a fixed cost per store per month. More specifically, suppose that it costs 17,000 dollars per store per month to run the promotion. What is the probability that, if the fast food company deployed the promotion, it would actually <em>lose</em> money?</p> <p>To answer this question, simply figure out how to compute the company’s per-store profit as a function of the ATE of the promotion.</p> <p>Then, for each estimate of the ATE we bootstrapped, calculate the profit if that estimate turned out to be the true ATE.</p> <p>Then calculate the share of bootstrapped “worlds” in which the per-store profits from the promotion were negative.</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[10]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"Prob of losing money with the promotion is </span><span class=si >{</span><span class=p >((</span><span class=n >estimates</span><span class=w > </span><span class=o >-</span><span class=w > </span><span class=mi >17</span><span class=p >)</span><span class=w > </span><span class=o >&lt;</span><span class=w > </span><span class=mi >0</span><span class=p >)</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span><span class=si >:</span><span class=s2 >.1%</span><span class=si >}</span><span class=s2 >"</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
Prob of losing money with the promotion is 14.1%
</pre></div></div> </div> </section> <section id="You-Did-It!"> <h3 id="You-Did-It!">You Did It!<a class=headerlink  href="#You-Did-It!" title="Link to this heading">¶</a></h3> <p>Congratulations! You just did your first “scenario modelling!” And now you can probably see one of the reasons I chose to bootstrap our standard errors — it naturally generated this array of simulated draws of the “true” Average Treatment Effect we can use for modelling!</p> <p>That isn’t to say bootstrapping is strictly necessary to do this type of analysis — because our data was relatively normally distributed, we could have done our scenario planning by using the <code class="docutils literal notranslate"><span class=pre >numpy.random.normal()</span></code> function to simulate draws from the normal distribution implied by our normal <code class="docutils literal notranslate"><span class=pre >statsmodels</span></code> results. But why add that step?</p> </section> <section id=Exercise-9 > <h3 id=Exercise-9 >Exercise 9<a class=headerlink  href="#Exercise-9" title="Link to this heading">¶</a></h3> <p>OK, that wasn’t a particularly complicated scenario. Let’s suppose, instead, that the promotion costs $17,000 more per store per month, <em>and</em> 50 dollars per 1,000 in sales.</p> <p>Now what’s the probability you make LESS money with the promotion than without?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[11]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >net_profit</span> <span class=o >=</span> <span class=p >(</span><span class=n >estimates</span> <span class=o >-</span> <span class=mi >17</span><span class=p >)</span> <span class=o >-</span> <span class=p >(</span><span class=mf >0.05</span> <span class=o >*</span> <span class=n >estimates</span><span class=p >)</span>

<span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"Prob of making less with the promotion is now </span><span class=si >{</span><span class=p >(</span><span class=n >net_profit</span><span class=w > </span><span class=o >&lt;</span><span class=w > </span><span class=mi >0</span><span class=p >)</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span><span class=si >:</span><span class=s2 >.1%</span><span class=si >}</span><span class=s2 >"</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
Prob of making less with the promotion is now 24.1%
</pre></div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[12]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >net_profit</span><span class=o >.</span><span class=n >hist</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[12]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
&lt;Axes: &gt;
</pre></div></div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <img alt="../_images/exercises_exercise_expected_value_22_1.png" src="../_images/exercises_exercise_expected_value_22_1.png"/> </div> </div> </section> <section id=Exercise-10 > <h3 id=Exercise-10 >Exercise 10<a class=headerlink  href="#Exercise-10" title="Link to this heading">¶</a></h3> <p>Now suppose that the cost of the promotion is:</p> <ul class=simple > <li><p>16,000 dollars per store per month, plus</p> <li><p>50 dollars per 1,000 in increased sales <em>for the first 17,000</em> in increased sales, and</p> <li><p>25 dollars per 1,000 after that.</p> </ul> <p>What are the odds you’ll lose money?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[13]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >profits</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >DataFrame</span><span class=p >({</span><span class=s2 >"ate"</span><span class=p >:</span> <span class=n >estimates</span><span class=p >})</span>

<span class=n >profits</span><span class=p >[</span><span class=s2 >"first_17"</span><span class=p >]</span> <span class=o >=</span> <span class=mi >17</span>
<span class=n >profits</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >profits</span><span class=o >.</span><span class=n >ate</span> <span class=o >&lt;</span> <span class=mi >17</span><span class=p >,</span> <span class=s2 >"first_17"</span><span class=p >]</span> <span class=o >=</span> <span class=n >profits</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >profits</span><span class=o >.</span><span class=n >ate</span> <span class=o >&lt;</span> <span class=mi >17</span><span class=p >,</span> <span class=s2 >"ate"</span><span class=p >]</span>

<span class=n >profits</span><span class=p >[</span><span class=s2 >"over_17"</span><span class=p >]</span> <span class=o >=</span> <span class=mi >0</span>
<span class=n >profits</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >profits</span><span class=o >.</span><span class=n >ate</span> <span class=o >&gt;</span> <span class=mi >17</span><span class=p >,</span> <span class=s2 >"over_17"</span><span class=p >]</span> <span class=o >=</span> <span class=n >profits</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >profits</span><span class=o >.</span><span class=n >ate</span> <span class=o >&gt;</span> <span class=mi >17</span><span class=p >,</span> <span class=s2 >"ate"</span><span class=p >]</span> <span class=o >-</span> <span class=mi >17</span>


<span class=n >profits</span><span class=p >[</span><span class=s2 >"profit"</span><span class=p >]</span> <span class=o >=</span> <span class=p >(</span>
    <span class=p >(</span><span class=n >profits</span><span class=o >.</span><span class=n >ate</span> <span class=o >-</span> <span class=mi >16</span><span class=p >)</span> <span class=o >-</span> <span class=p >(</span><span class=n >profits</span><span class=p >[</span><span class=s2 >"first_17"</span><span class=p >]</span> <span class=o >*</span> <span class=mf >0.05</span><span class=p >)</span> <span class=o >-</span> <span class=p >(</span><span class=n >profits</span><span class=p >[</span><span class=s2 >"over_17"</span><span class=p >]</span> <span class=o >*</span> <span class=mf >0.025</span><span class=p >)</span>
<span class=p >)</span>

<span class=nb >print</span><span class=p >(</span><span class=sa >f</span><span class=s2 >"The odds we'll lose money is </span><span class=si >{</span><span class=p >(</span><span class=n >profits</span><span class=p >[</span><span class=s1 >'profit'</span><span class=p >]</span><span class=w > </span><span class=o >&lt;</span><span class=w > </span><span class=mi >0</span><span class=p >)</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span><span class=si >:</span><span class=s2 >.1%</span><span class=si >}</span><span class=s2 >"</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
The odds we'll lose money is 12.6%
</pre></div></div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area stderr docutils container"> <div class=highlight ><pre>
/var/folders/fs/h_8_rwsn5hvg9mhp0txgc_s9v6191b/T/ipykernel_72247/2223901279.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[16.89569719 15.6637186  16.11056695 ... 16.25179418 15.3315546
 16.8096373 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.
  profits.loc[profits.ate &lt; 17, "first_17"] = profits.loc[profits.ate &lt; 17, "ate"]
/var/folders/fs/h_8_rwsn5hvg9mhp0txgc_s9v6191b/T/ipykernel_72247/2223901279.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.96907815 6.00871939 5.42634738 ... 2.97284399 3.57814255 4.42874029]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.
  profits.loc[profits.ate &gt; 17, "over_17"] = profits.loc[profits.ate &gt; 17, "ate"] - 17
</pre></div></div> </div> </section> <section id=Exercise-11 > <h3 id=Exercise-11 >Exercise 11<a class=headerlink  href="#Exercise-11" title="Link to this heading">¶</a></h3> <p>Your boss doesn’t just want that top-line number, she also wants to know the Expected Monetary Value of the promotion. What would that be?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[14]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >profits</span><span class=p >[</span><span class=s2 >"profit"</span><span class=p >]</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[14]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
2.5515868688548027
</pre></div></div> </div> </section> <section id=Exercise-12 > <h3 id=Exercise-12 >Exercise 12<a class=headerlink  href="#Exercise-12" title="Link to this heading">¶</a></h3> <p>Finally, she wants to see a full probability distribution of outcomes — what does that look like?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[15]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >profits</span><span class=p >[</span><span class=s2 >"profit"</span><span class=p >]</span><span class=o >.</span><span class=n >hist</span><span class=p >(</span><span class=n >bins</span><span class=o >=</span><span class=mi >20</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[15]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
&lt;Axes: &gt;
</pre></div></div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <img alt="../_images/exercises_exercise_expected_value_28_1.png" src="../_images/exercises_exercise_expected_value_28_1.png"/> </div> </div> </section> </section> <section id=The-Math > <h2 id=The-Math >The Math<a class=headerlink  href="#The-Math" title="Link to this heading">¶</a></h2> <p>As I promised above, let’s take a moment to review why we can think of this distribution as being equal to the probability distribution of our true ATE <em>if and only if</em> we are willing to assume we know nothing other than the results of this study.</p> <section id=Bayes-Rule-and-Frequentist-Statistics > <h3 id=Bayes-Rule-and-Frequentist-Statistics >Bayes Rule and Frequentist Statistics<a class=headerlink  href="#Bayes-Rule-and-Frequentist-Statistics" title="Link to this heading">¶</a></h3> <p>As discussed previously, one of the challenges with the standard, Frequentist approach to A/B testing is that the statistics we get from these analyses (like p-values) rarely correspond to the substantive quantities we care about most.</p> <p>In statistical notation, our estimate of the distribution of our estimate of the Average Treatment Effect can be written: <span class="math notranslate nohighlight">\(P(X|ATE)\)</span> where <span class="math notranslate nohighlight">\(X\)</span> is the data generated by our A/B test conditional on the <span class="math notranslate nohighlight">\(ATE\)</span>.</p> <p>We sometimes fool ourselves into thinking that this quantity corresponds precisely to what we care about: the probability distribution of the true ATE given our estimate <span class="math notranslate nohighlight">\(P(ATE|X)\)</span>.</p> <p>But as you can see, <span class="math notranslate nohighlight">\(P(X|ATE) \neq P(ATE|X)\)</span>.</p> <p>Thankfully, though, Bayes Rule does provide us with a way of determining how these quantities relate to each other. Bayes rule is often written as:</p> <div class="math notranslate nohighlight"> \[P(A | B) = \frac{P(A \cap B)}{P(B)}\]</div> <p>We can rewrite <span class="math notranslate nohighlight">\(P(A \cap B)\)</span> as <span class="math notranslate nohighlight">\(P(B | A) * P(A)\)</span>, let <span class="math notranslate nohighlight">\(A\)</span> be <span class="math notranslate nohighlight">\(ATE\)</span> and <span class="math notranslate nohighlight">\(B\)</span> be our data <span class="math notranslate nohighlight">\(X\)</span> to help us understand our problem better:</p> <div class="math notranslate nohighlight"> \[P(ATE | X) = \frac{P(X|ATE) * P(ATE)}{P(X)}\]</div> <p>Here, we can see that quantity we are interested in (the probability distribution of <span class="math notranslate nohighlight">\(ATE\)</span>) on the left-hand side of the equation. We can also see that the first term on the right-hand side of the equation (<span class="math notranslate nohighlight">\(P(X|ATE)\)</span>) is the distribution we got from bootstrapping (or regular regression packages, conditional on some distributional assumptions). This leaves us with only two terms we need to understand: <span class="math notranslate nohighlight">\(P(ATE)\)</span> and <span class="math notranslate nohighlight">\(P(X)\)</span>.</p> <p>We call <span class="math notranslate nohighlight">\(P(ATE)\)</span> our unconditional <em>prior</em> belief about <span class="math notranslate nohighlight">\(ATE\)</span> — unconditional because we aren’t conditioning on <span class="math notranslate nohighlight">\(X\)</span> (the results of our analysis). This, in other words, what values of <span class="math notranslate nohighlight">\(ATE\)</span> were plausible before your analysis began.</p> <p>And <span class="math notranslate nohighlight">\(P(X)\)</span>? This term is actually kinda annoying and not that interesting, so we generally ignore it. Because we know that the left-hand side of our equation is a probability distribution, we know that the right-hand side has to integrate out to 1 (with respect to all possible values of <span class="math notranslate nohighlight">\(A\)</span>, which in this case is just whether the conditional probability distribution of <span class="math notranslate nohighlight">\(ATE\)</span>). So rather than trying to compute <span class="math notranslate nohighlight">\(P(X)\)</span> directly, we usually figure out what it <em>must be</em> indirectly by figuring out what normalization gives us a valid probability distribution.</p> <p>As a result, we often just say that the left-hand side of the equation is <em>proportional</em> to the right-hand side, and write this using the <span class="math notranslate nohighlight">\(\propto\)</span> symbol:</p> <div class="math notranslate nohighlight"> \[P(ATE | X) \propto P(X|ATE) * P(ATE )\]</div> </section> <section id="OK,-why-do-I-care?"> <h3 id="OK,-why-do-I-care?">OK, why do I care?<a class=headerlink  href="#OK,-why-do-I-care?" title="Link to this heading">¶</a></h3> <p>OK, that was a lot of math. Why do I care about all this?</p> <p>Two reasons:</p> </section> <section id="Reason-1:-It-is-critically-important-that-you-understand-what-p-values-and-other-Frequentist-statistics-are,-and-what-they-are-not."> <h3 id="Reason-1:-It-is-critically-important-that-you-understand-what-p-values-and-other-Frequentist-statistics-are,-and-what-they-are-not.">Reason 1: It is <em>critically</em> important that you understand what p-values and other Frequentist statistics are, and what they are not.<a class=headerlink  href="#Reason-1:-It-is-critically-important-that-you-understand-what-p-values-and-other-Frequentist-statistics-are,-and-what-they-are-not." title="Link to this heading">¶</a></h3> <p>P-values, as we discussed previously, are the probability of observing our data given the null hypothesis is true — i.e, <span class="math notranslate nohighlight">\(P(X|Null)\)</span>. It is <em>not</em> the probability that the null is true given the data (<span class="math notranslate nohighlight">\(P(Null|X)\)</span>).</p> <p>If you get a p-value of 0.05 from an AB test showing that <em>increasing</em> latency increases user retention on a website, you should not assume that “Oh, well this only had a 5% probability of happening by chance! Latency must be increasing retention!” Rather, you should say “um, I have a pretty strong sense (a prior, <span class="math notranslate nohighlight">\(P(Null)\)</span>) that increasing latency does <em>not</em> increase retention. So I’m gonna be much more skeptical of that result than an AB test that shows a <em>decrease</em> in latency increases user retention with a p-value of 0.05.</p> </section> <section id="Reason-2:-There-is-a-special-case-where-P(ATE|-X)-=-P(X|-ATE)"> <h3 id="Reason-2:-There-is-a-special-case-where-P(ATE|-X)-=-P(X|-ATE)">Reason 2: There <em>is</em> a special case where <span class="math notranslate nohighlight">\(P(ATE| X) = P(X| ATE)\)</span><a class=headerlink  href="#Reason-2:-There-is-a-special-case-where-P(ATE|-X)-=-P(X|-ATE)" title="Link to this heading">¶</a></h3> <p>Suppose you know <em>nothing</em> about the treatment you seek to test. All possible outcomes, in your mind, are <em>equally</em> likely. This is the case of what is called an <em>uninformative prior</em>, and it essentially means <span class="math notranslate nohighlight">\(P(ATE)\)</span> is a constant for all possible outcomes.</p> <p>If <span class="math notranslate nohighlight">\(P(ATE)\)</span> is a constant, then <span class="math notranslate nohighlight">\(P(ATE| X) \propto P(X| ATE) * c\)</span> for some constant <span class="math notranslate nohighlight">\(c\)</span>. This implies <span class="math notranslate nohighlight">\(P(ATE| X) \propto P(X| ATE)\)</span> (since constants drop out when doing proportionate comparisons).</p> <p>Now, I want to emphasize that assuming that all outcomes of <span class="math notranslate nohighlight">\(P(ATE)\)</span> are equally likely is a <em>very</em> weird thing to assume. After all, you’re doing an A/B test because you have some suspicion that your treatment will have an effect, right?</p> <p>But I think it’s helpful to consider this case as a way of understanding the relationship between Frequentist statistics like p-values and the quantities we often actually care about (like the probability that the Null hypothesis of no effect is true): namely, if we are willing to assume that the world started with the study we are conducting and ends with the study we are conducting, and that we know nothing except what is in our dataset, then these two <em>substantively and theoretically distinct</em> quantities will be the same.</p> </section> </section> </section> </article> </div> </div> </main> </div> <footer class=md-footer > <div class=md-footer-nav > <nav class="md-footer-nav__inner md-grid"> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright > <div class=md-footer-copyright__highlight > &#169; Copyright 2022, Nick Eubank. </div> Created using <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.2.6. and <a href="https://github.com/bashtage/sphinx-material/">Material for Sphinx</a> </div> </div> </div> </footer> <script src="../_static/javascripts/application.js"></script> <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>