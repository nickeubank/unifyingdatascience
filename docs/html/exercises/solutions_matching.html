<!DOCTYPE html> <html lang=en > <meta charset=utf-8  /> <meta name=viewport  content="width=device-width, initial-scale=1.0" /><meta name=generator  content="Docutils 0.17.1: http://docutils.sourceforge.net/" /> <meta name=viewport  content="width=device-width,initial-scale=1"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name="lang:clipboard.copy" content="Copy to clipboard"> <meta name="lang:clipboard.copied" content="Copied to clipboard"> <meta name="lang:search.language" content=en > <meta name="lang:search.pipeline.stopwords" content=True > <meta name="lang:search.pipeline.trimmer" content=True > <meta name="lang:search.result.none" content="No matching documents"> <meta name="lang:search.result.one" content="1 matching document"> <meta name="lang:search.result.other" content="# matching documents"> <meta name="lang:search.tokenizer" content="[\s\-]+"> <link href="https://fonts.gstatic.com/" rel=preconnect  crossorigin> <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel=stylesheet > <style> body, input { font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif } code, kbd, pre { font-family: "Roboto Mono", "Courier New", Courier, monospace } </style> <link rel=stylesheet  href="../_static/stylesheets/application.css"/> <link rel=stylesheet  href="../_static/stylesheets/application-palette.css"/> <link rel=stylesheet  href="../_static/stylesheets/application-fixes.css"/> <link rel=stylesheet  href="../_static/fonts/material-icons.css"/> <meta name=theme-color  content="#2196f3"> <script src="../_static/javascripts/modernizr.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-151397036-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'UA-151397036-1'); </script> <title>Matching Exercise &#8212; Unifying Data Science</title> <link rel=stylesheet  type="text/css" href="../_static/pygments.css" /> <link rel=stylesheet  type="text/css" href="../_static/material.css" /> <link rel=stylesheet  type="text/css" href="../_static/nbsphinx-code-cells.css" /> <script data-url_root="../" id=documentation_options  src="../_static/documentation_options.js"></script> <script src="../_static/jquery.js"></script> <script src="../_static/underscore.js"></script> <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script> <script src="../_static/doctools.js"></script> <script crossorigin=anonymous  integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script> <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script> <script defer=defer  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <link rel="shortcut icon" href="../_static/mids_logo.svg"/> <link rel=index  title=Index  href="../genindex.html" /> <link rel=search  title=Search  href="../search.html" /> <body dir=ltr data-md-color-primary=blue-grey data-md-color-accent=blue> <svg class=md-svg > <defs data-children-count=0 > <svg xmlns="http://www.w3.org/2000/svg" width=416  height=448  viewBox="0 0 416 448" id=__github ><path fill=currentColor  d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle  data-md-toggle=drawer  type=checkbox  id=__drawer > <input class=md-toggle  data-md-toggle=search  type=checkbox  id=__search > <label class=md-overlay  data-md-component=overlay  for=__drawer ></label> <a href="#exercises/solutions_matching" tabindex=1  class=md-skip > Skip to content </a> <header class=md-header  data-md-component=header > <nav class="md-header-nav md-grid"> <div class="md-flex navheader"> <div class="md-flex__cell md-flex__cell--shrink"> <a href="../index.html" title="Unifying Data Science" class="md-header-nav__button md-logo"> <img src="../_static/mids_logo.svg" height=26  alt="Unifying Data Science logo"> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer ></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title > <span class=md-header-nav__topic >Unifying Data Science</span> <span class=md-header-nav__topic > Matching Exercise </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search ></label> <div class=md-search  data-md-component=search  role=dialog > <label class=md-search__overlay  for=__search ></label> <div class=md-search__inner  role=search > <form class=md-search__form  action="../search.html" method=get  name=search > <input type=text  class=md-search__input  name=q  placeholder=""Search"" autocapitalize=off  autocomplete=off  spellcheck=false  data-md-component=query  data-md-state=active > <label class="md-icon md-search__icon" for=__search ></label> <button type=reset  class="md-icon md-search__icon" data-md-component=reset  tabindex=-1 > &#xE5CD; </button> </form> <div class=md-search__output > <div class=md-search__scrollwrap  data-md-scrollfix> <div class=md-search-result  data-md-component=result > <div class=md-search-result__meta > Type to start searching </div> <ol class=md-search-result__list ></ol> </div> </div> </div> </div> </div> </div> <script src="../_static/javascripts/version_dropdown.js"></script> <script> var json_loc = "../"versions.json"", target_loc = "../../", text = "Versions"; $( document ).ready( add_version_dropdown(json_loc, target_loc, text)); </script> </div> </nav> </header> <div class=md-container > <nav class=md-tabs  data-md-component=tabs > <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list > <li class=md-tabs__item ><a href="../index.html" class=md-tabs__link >Home</a> <li class=md-tabs__item ><a href="../class_schedule.html" class=md-tabs__link >Class Schedule</a> <li class=md-tabs__item ><a href="../topic_list.html" class=md-tabs__link >Topic List</a> <li class=md-tabs__item ><a href="https://www.nickeubank.com" class=md-tabs__link >About The Author</a> </ul> </div> </nav> <main class=md-main > <div class="md-main__inner md-grid" data-md-component=container > <div class="md-sidebar md-sidebar--primary" data-md-component=navigation > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--primary" data-md-level=0 > <label class="md-nav__title md-nav__title--site" for=__drawer > <a href="../index.html" title="Unifying Data Science" class="md-nav__button md-logo"> <img src="../_static/mids_logo.svg" alt=" logo" width=48  height=48 > </a> <a href="../index.html" title="Unifying Data Science">Unifying Data Science</a> </label> <ul class=md-nav__list > <li class=md-nav__item > <a href="../class_schedule.html" class=md-nav__link >CLASS SCHEDULE</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Causal Inference</span></span> <li class=md-nav__item > <a href="../limitations_of_ATE.html" class=md-nav__link >Limitations of ATE</a> <li class=md-nav__item > <a href="../internal_v_external_validity.html" class=md-nav__link >Internal v. External Validity</a> <li class=md-nav__item > <a href="../evaluating_real_studies.html" class=md-nav__link >Evaluating A Real Study</a> <li class=md-nav__item > <a href="../causal_inference_beyond_ab_testing.html" class=md-nav__link >Beyond AB Testing</a> <li class=md-nav__item > <a href="../matching_why.html" class=md-nav__link >Matching (Why)</a> <li class=md-nav__item > <a href="../matching_how.html" class=md-nav__link >Matching (How)</a> <li class=md-nav__item > <a href="../interpreting_indicator_vars.html" class=md-nav__link >Indicator Variables</a> <li class=md-nav__item > <a href="../fixed_effects.html" class=md-nav__link >Fixed Effects (FEs)</a> <li class=md-nav__item > <a href="../fixed_effects_and_causal_inference.html" class=md-nav__link >FEs & Causality</a> <li class=md-nav__item > <a href="../fixed_effects_v_hierarchical.html" class=md-nav__link >FEs & Hierarchical Models</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Data Science Project Design</span></span> <li class=md-nav__item > <a href="../backwards_design.html" class=md-nav__link >Backwards Design</a> <li class=md-nav__item > <a href="../taxonomy_of_questions.html" class=md-nav__link >Taxonomy of Questions</a> <li class=md-nav__item > <a href="../moving_from_problems_to_questions.html" class=md-nav__link >From Problems to Questions</a> <li class=md-nav__item > <a href="../descriptive_questions.html" class=md-nav__link >Discretion and Description</a> <li class=md-nav__item > <a href="../ethical_ml_recommendations.html" class=md-nav__link >Ethical Machine Learning</a> <li class=md-nav__item > <a href="../writing_to_stakeholders.html" class=md-nav__link >Writing for Lay Audiences</a> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--secondary"> <label class=md-nav__title  for=__toc >"Contents"</label> <ul class=md-nav__list  data-md-scrollfix=""> <li class=md-nav__item ><a href="#exercises-solutions-matching--page-root" class=md-nav__link >Matching Exercise</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Matching-Packages:-Python-v.-R" class=md-nav__link >Matching Packages: Python v. R</a> <li class=md-nav__item ><a href="#Installing-dame-flame." class=md-nav__link >Installing dame-flame.</a> <li class=md-nav__item ><a href="#Data-Setup" class=md-nav__link >Data Setup</a> <li class=md-nav__item ><a href="#Getting-To-Know-Your-Data" class=md-nav__link >Getting To Know Your Data</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-1" class=md-nav__link >Exercise 1</a> <li class=md-nav__item ><a href="#Exercise-2" class=md-nav__link >Exercise 2</a> <li class=md-nav__item ><a href="#Exercise-3" class=md-nav__link >Exercise 3</a> </ul> </nav> <li class=md-nav__item ><a href="#Matching!" class=md-nav__link >Matching!</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-4" class=md-nav__link >Exercise 4</a> <li class=md-nav__item ><a href="#Exercise-5" class=md-nav__link >Exercise 5</a> </ul> </nav> <li class=md-nav__item ><a href="#Let&#39;s-Do-Matching-with-DAME" class=md-nav__link >Let’s Do Matching with DAME</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-6" class=md-nav__link >Exercise 6</a> <li class=md-nav__item ><a href="#Exercise-7" class=md-nav__link >Exercise 7</a> </ul> </nav> <li class=md-nav__item ><a href="#Interpreting-DAME-output" class=md-nav__link >Interpreting DAME output</a> <li class=md-nav__item ><a href="#Exercise-8" class=md-nav__link >Exercise 8</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-9" class=md-nav__link >Exercise 9</a> <li class=md-nav__item ><a href="#Exercise-10" class=md-nav__link >Exercise 10</a> </ul> </nav> <li class=md-nav__item ><a href="#Getting-Back-a-Dataset" class=md-nav__link >Getting Back a Dataset</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-11" class=md-nav__link >Exercise 11</a> </ul> </nav> <li class=md-nav__item ><a href="#Check-Your-Matches-and-Analyze" class=md-nav__link >Check Your Matches and Analyze</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#Exercise-12" class=md-nav__link >Exercise 12</a> <li class=md-nav__item ><a href="#Exercise-13" class=md-nav__link >Exercise 13</a> <li class=md-nav__item ><a href="#Exercise-14" class=md-nav__link >Exercise 14</a> <li class=md-nav__item ><a href="#Exercise-15" class=md-nav__link >Exercise 15</a> <li class=md-nav__item ><a href="#Exercise-16" class=md-nav__link >Exercise 16</a> </ul> </nav> <li class=md-nav__item ><a href="#Other-Forms-of-Matching" class=md-nav__link >Other Forms of Matching</a> <li class=md-nav__item ><a href="#Absolutely-positively-need-the-solutions?" class=md-nav__link >Absolutely positively need the solutions?</a> </ul> </nav> </ul> </nav> </div> </div> </div> <div class=md-content > <article class="md-content__inner md-typeset" role=main > <section id=Matching-Exercise > <h1 id=exercises-solutions-matching--page-root >Matching Exercise<a class=headerlink  href="#exercises-solutions-matching--page-root" title="Permalink to this heading">¶</a></h1> <p>In this exercise, we’ll be evaluating how getting a college degree impacts earnings in the US using matching.</p> <section id="Matching-Packages:-Python-v.-R"> <h2 id="Matching-Packages:-Python-v.-R">Matching Packages: Python v. R<a class=headerlink  href="#Matching-Packages:-Python-v.-R" title="Permalink to this heading">¶</a></h2> <p>Just as the best tools for machine learning tend to be in Python since they’re developed by CS people (who prefer Python), most of the best tools for causal inference are implemented in R since innovation in causal inference tends to be lead by social scientists using R. As a result, the most well developed matching package is called <a class="reference external" href="https://kosukeimai.github.io/MatchIt/index.html">MatchIt</a>, and is only available in R (though you can always call it from Python using <code class="docutils literal notranslate"><span class=pre >rpy2</span></code>).</p> <p>In the last couple years, though, a group of computer scientists and statisticians here at Duke have made some great advancements in matching (especially the computational side of things), and they recently released a set of matching packages in both R and Python that we’ll be using today. They have some great algorithms we’ll use today, but be aware these packages aren’t as mature, and aren’t general purpose packages yet. So if you ever get deep into matching, be aware you will probably still want to make at least partial use of the R package <a class="reference external" href="https://kosukeimai.github.io/MatchIt/index.html">MatchIt</a>, as well as some other R packages for new innovative techniques (like <a class="reference external" href="https://projects.iq.harvard.edu/frontier/home">Matching Frontier estimation</a>), or <a class="reference external" href="https://almost-matching-exactly.github.io/AHB-R-package/">Adaptive Hyper-Box Matching</a>.</p> </section> <section id=Installing-dame-flame. > <h2 id=Installing-dame-flame. >Installing dame-flame.<a class=headerlink  href="#Installing-dame-flame." title="Permalink to this heading">¶</a></h2> <p>For this lesson, begin by installing <code class="docutils literal notranslate"><span class=pre >dame-flame</span></code> with <code class="docutils literal notranslate"><span class=pre >pip</span> <span class=pre >install</span> <span class=pre >dame-flame</span></code> (it’s not on conda yet).</p> <p><a class="reference external" href="https://almost-matching-exactly.github.io/DAME-FLAME-Python-Package">DAME</a> is an algorithm that we can use for a version of course exact matching. The package only accepts a list of categorical variables, and then attempts to match pairs that match exactly on those variables. That means that if you want to match on, say, age, you have to break it up into categories (say, under 18, 18-29, 30-39, etc. etc.).</p> <p>Of course, one cannot always find exact matches on all variables, so what DAME does is:</p> <ol class="arabic simple"> <li><p>Find all observations that match on <em>all</em> matching variables.</p> <li><p>Figure out which matching variable is least useful in predicting the outcome of interest <span class="math notranslate nohighlight">\(Y\)</span> and drops that, then tries to match the remaining observations on the narrowed set of matching variables.</p> <li><p>This repeats until you run out of variables, all observations are matched, or you hit a stopping run (namely: quality of matches falls below a threshold).</p> </ol> <p>In addition, the lab has also created FLAME, which does the same thing, but employs some tricks to make it <em>massively</em> more computationally efficient, meaning it can be used on datasets with millions of observations (which most matching algorithms cannot). It’s a little less accurate, but an amazing contribution never the less.</p> </section> <section id=Data-Setup > <h2 id=Data-Setup >Data Setup<a class=headerlink  href="#Data-Setup" title="Permalink to this heading">¶</a></h2> <p>To save you some time and let you focus on matching, I’ve <em>pre-cleaned</em> about one month worth of of data from the US Current Population Survey data we used for our <a class="reference external" href="exercises/exercises_regression_incomeineq.ipynb">gender discrimination analysis</a>. You can download the data <a class="reference external" href="https://github.com/nickeubank/MIDS_Data/blob/master/Current_Population_Survey/cps_for_matching.dta?raw=true%22">from here</a>, or read it directly with:</p> <div class="highlight-python notranslate"><div class=highlight ><pre><span></span><span class=n >cps</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >read_stata</span><span class=p >(</span>
    <span class=s2 >"https://github.com/nickeubank/MIDS_Data/blob/master"</span>
    <span class=s2 >"/Current_Population_Survey/cps_for_matching.dta?raw=true"</span>
<span class=p >)</span>
</pre></div> </div> <p>Load the data and quickly familiarize yourself with its contents.</p> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[1]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Load critical packages</span>
<span class=kn >import</span> <span class=nn >pandas</span> <span class=k >as</span> <span class=nn >pd</span>
<span class=kn >import</span> <span class=nn >numpy</span> <span class=k >as</span> <span class=nn >np</span>
<span class=kn >import</span> <span class=nn >dame_flame</span>
</pre></div> </div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[2]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Load our Current Population Survey data</span>
<span class=c1 ># a regular  survey of US citizens</span>

<span class=n >cps</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >read_stata</span><span class=p >(</span>
    <span class=s2 >"https://github.com/nickeubank/MIDS_Data/blob/master"</span>
    <span class=s2 >"/Current_Population_Survey/cps_for_matching.dta?raw=true"</span>
<span class=p >)</span>
</pre></div> </div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[3]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Take a look at the data</span>
<span class=n >cps</span><span class=o >.</span><span class=n >head</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[3]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border=1  class=dataframe > <thead> <tr style="text-align: right;"> <th> <th>index <th>annual_earnings <th>female <th>simplified_race <th>has_college <th>age <th>county <th>class94 <tr> <th>0 <td>151404 <td>NaN <td>1 <td>3.0 <td>1 <td>30 <td>0-WV <td>Private, For Profit <tr> <th>1 <td>123453 <td>NaN <td>0 <td>0.0 <td>0 <td>21 <td>251-TX <td>Private, For Profit <tr> <th>2 <td>187982 <td>NaN <td>0 <td>0.0 <td>0 <td>40 <td>5-MA <td>Self-Employed, Unincorporated <tr> <th>3 <td>122356 <td>NaN <td>1 <td>0.0 <td>1 <td>27 <td>0-TN <td>Private, Nonprofit <tr> <th>4 <td>210750 <td>42900.0 <td>1 <td>0.0 <td>0 <td>52 <td>0-IA <td>Private, For Profit </table> </div></div> </div> </section> <section id=Getting-To-Know-Your-Data > <h2 id=Getting-To-Know-Your-Data >Getting To Know Your Data<a class=headerlink  href="#Getting-To-Know-Your-Data" title="Permalink to this heading">¶</a></h2> <p>Before you start matching, it is important to examine your data to ensure that matching is feasible (you have some overlap the the features of people in the treated and untreated groups), and also that there is a reason <em>to</em> match: either you’re unsure about some of the functional forms at play, or your have some imbalance between the two groups.</p> <section id=Exercise-1 > <h3 id=Exercise-1 >Exercise 1<a class=headerlink  href="#Exercise-1" title="Permalink to this heading">¶</a></h3> <p>Show the raw difference of <code class="docutils literal notranslate"><span class=pre >annual_earnings</span></code> between those with and without a college degree (<code class="docutils literal notranslate"><span class=pre >has_college</span></code>). Is the difference statistically significant?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[4]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >statsmodels.formula.api</span> <span class=k >as</span> <span class=nn >smf</span>

<span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span><span class=s2 >"annual_earnings ~ has_college"</span><span class=p >,</span> <span class=n >cps</span><span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[4]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>OLS Regression Results</caption> <tr> <th>Dep. Variable: <td>annual_earnings <th> R-squared: <td> 0.063 <tr> <th>Model: <td>OLS <th> Adj. R-squared: <td> 0.063 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 370.2 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>6.56e-80 <tr> <th>Time: <td>13:59:39 <th> Log-Likelihood: <td> -63018. <tr> <th>No. Observations: <td> 5515 <th> AIC: <td>1.260e+05 <tr> <th>Df Residuals: <td> 5513 <th> BIC: <td>1.261e+05 <tr> <th>Df Model: <td> 1 <th> <td> <tr> <th>Covariance Type: <td>nonrobust <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 3.887e+04 <td> 336.007 <td> 115.669 <td> 0.000 <td> 3.82e+04 <td> 3.95e+04 <tr> <th>has_college <td> 1.416e+04 <td> 735.820 <td> 19.242 <td> 0.000 <td> 1.27e+04 <td> 1.56e+04 </table> <table> <tr> <th>Omnibus: <td>2214.375 <th> Durbin-Watson: <td> 1.974 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>10578.287 <tr> <th>Skew: <td> 1.910 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td> 8.608 <th> Cond. No. <td> 2.59 </table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[5]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># About 14,000 a year, and it's very significant.</span>
</pre></div> </div> </div> </section> <section id=Exercise-2 > <h3 id=Exercise-2 >Exercise 2<a class=headerlink  href="#Exercise-2" title="Permalink to this heading">¶</a></h3> <p>Next we can check for balance. Check the share of people in different racial groups who have college degrees. Are those differences statistically significant?</p> <p>Race is coded as White Non-Hispanic (0), Black Non-Hispanic (1), Hispanic (2), Other (3).</p> <p>Does the distribution also look different across counties (I don’t need statistical significance for this)?</p> <p>Does the data seem balanced?</p> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[6]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># This question wording is, admittedly, a little iffy.</span>
<span class=c1 ># Basically, while we want frequency tables to do our chi2</span>
<span class=c1 ># test, I know _I_ can't look at a frequency table and have</span>
<span class=c1 ># any sense of whether the groups are actually balanced.</span>
<span class=c1 ># So I like to see shares with my eyes, then use freq table to test.</span>
</pre></div> </div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[7]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># One easy way to get differences in shares (and bi-variate significance)</span>
<span class=n >smf</span><span class=o >.</span><span class=n >ols</span><span class=p >(</span><span class=s2 >"has_college ~ C(simplified_race)"</span><span class=p >,</span> <span class=n >cps</span><span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[7]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>OLS Regression Results</caption> <tr> <th>Dep. Variable: <td>has_college <th> R-squared: <td> 0.032 <tr> <th>Model: <td>OLS <th> Adj. R-squared: <td> 0.032 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 122.1 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>7.74e-78 <tr> <th>Time: <td>13:59:39 <th> Log-Likelihood: <td> -7675.0 <tr> <th>No. Observations: <td> 11150 <th> AIC: <td>1.536e+04 <tr> <th>Df Residuals: <td> 11146 <th> BIC: <td>1.539e+04 <tr> <th>Df Model: <td> 3 <th> <td> <tr> <th>Covariance Type: <td>nonrobust <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 0.4382 <td> 0.006 <td> 79.420 <td> 0.000 <td> 0.427 <td> 0.449 <tr> <th>C(simplified_race)[T.1.0] <td> -0.1206 <td> 0.016 <td> -7.507 <td> 0.000 <td> -0.152 <td> -0.089 <tr> <th>C(simplified_race)[T.2.0] <td> -0.2398 <td> 0.014 <td> -17.682 <td> 0.000 <td> -0.266 <td> -0.213 <tr> <th>C(simplified_race)[T.3.0] <td> 0.0367 <td> 0.016 <td> 2.261 <td> 0.024 <td> 0.005 <td> 0.069 </table> <table> <tr> <th>Omnibus: <td>46681.807 <th> Durbin-Watson: <td> 1.965 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>1670.333 <tr> <th>Skew: <td> 0.377 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td> 1.261 <th> Cond. No. <td> 3.97 </table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[8]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Or just groupby:</span>

<span class=n >cps</span><span class=o >.</span><span class=n >groupby</span><span class=p >(</span><span class=s2 >"simplified_race"</span><span class=p >)[</span><span class=s2 >"has_college"</span><span class=p >]</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[8]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
simplified_race
0.0    0.438205
1.0    0.317647
2.0    0.198413
3.0    0.474900
Name: has_college, dtype: float64
</pre></div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[9]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Then for statistical significance:</span>
<span class=n >ctab</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >crosstab</span><span class=p >(</span><span class=n >cps</span><span class=p >[</span><span class=s2 >"simplified_race"</span><span class=p >],</span> <span class=n >cps</span><span class=p >[</span><span class=s2 >"has_college"</span><span class=p >])</span>
<span class=n >ctab</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[9]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border=1  class=dataframe > <thead> <tr style="text-align: right;"> <th>has_college <th>0 <th>1 <tr> <th>simplified_race <th> <th> <tr> <th>0.0 <td>4282 <td>3340 <tr> <th>1.0 <td>696 <td>324 <tr> <th>2.0 <td>1212 <td>300 <tr> <th>3.0 <td>523 <td>473 </table> </div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[10]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >scipy.stats</span>

<span class=n >chi2</span><span class=p >,</span> <span class=n >p</span><span class=p >,</span> <span class=n >dof</span><span class=p >,</span> <span class=n >expected</span> <span class=o >=</span> <span class=n >scipy</span><span class=o >.</span><span class=n >stats</span><span class=o >.</span><span class=n >chi2_contingency</span><span class=p >(</span><span class=n >ctab</span><span class=o >.</span><span class=n >values</span><span class=p >)</span>
<span class=n >p</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[10]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
1.2993875943569016e-76
</pre></div></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[11]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Insanely significant. :)</span>
</pre></div> </div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[12]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># And look at counties.</span>
<span class=n >cps</span><span class=o >.</span><span class=n >groupby</span><span class=p >(</span><span class=s2 >"county"</span><span class=p >)[[</span><span class=s2 >"has_college"</span><span class=p >]]</span><span class=o >.</span><span class=n >describe</span><span class=p >()</span><span class=o >.</span><span class=n >sort_values</span><span class=p >((</span><span class=s2 >"has_college"</span><span class=p >,</span> <span class=s2 >"mean"</span><span class=p >))</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[12]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } </style> <table border=1  class=dataframe > <thead> <tr> <th> <th colspan=8  halign=left >has_college <tr> <th> <th>count <th>mean <th>std <th>min <th>25% <th>50% <th>75% <th>max <tr> <th>county <th> <th> <th> <th> <th> <th> <th> <th> <tr> <th>71-MO <td>4.0 <td>0.000000 <td>0.000000 <td>0.0 <td>0.0 <td>0.0 <td>0.0 <td>0.0 <tr> <th>700-VA <td>3.0 <td>0.000000 <td>0.000000 <td>0.0 <td>0.0 <td>0.0 <td>0.0 <td>0.0 <tr> <th>69-NY <td>1.0 <td>0.000000 <td>NaN <td>0.0 <td>0.0 <td>0.0 <td>0.0 <td>0.0 <tr> <th>69-FL <td>4.0 <td>0.000000 <td>0.000000 <td>0.0 <td>0.0 <td>0.0 <td>0.0 <td>0.0 <tr> <th>17-MD <td>2.0 <td>0.000000 <td>0.000000 <td>0.0 <td>0.0 <td>0.0 <td>0.0 <td>0.0 <tr> <th>... <td>... <td>... <td>... <td>... <td>... <td>... <td>... <td>... <tr> <th>75-CA <td>17.0 <td>0.882353 <td>0.332106 <td>0.0 <td>1.0 <td>1.0 <td>1.0 <td>1.0 <tr> <th>21-NJ <td>4.0 <td>1.000000 <td>0.000000 <td>1.0 <td>1.0 <td>1.0 <td>1.0 <td>1.0 <tr> <th>19-NJ <td>2.0 <td>1.000000 <td>0.000000 <td>1.0 <td>1.0 <td>1.0 <td>1.0 <td>1.0 <tr> <th>81-IN <td>1.0 <td>1.000000 <td>NaN <td>1.0 <td>1.0 <td>1.0 <td>1.0 <td>1.0 <tr> <th>171-MN <td>1.0 <td>1.000000 <td>NaN <td>1.0 <td>1.0 <td>1.0 <td>1.0 <td>1.0 </table> <p>326 rows × 8 columns</p> </div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[13]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >cps</span><span class=o >.</span><span class=n >groupby</span><span class=p >(</span><span class=s2 >"county"</span><span class=p >)[[</span><span class=s2 >"has_college"</span><span class=p >]]</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span><span class=o >.</span><span class=n >describe</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[13]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border=1  class=dataframe > <thead> <tr style="text-align: right;"> <th> <th>has_college <tr> <th>count <td>326.000000 <tr> <th>mean <td>0.390058 <tr> <th>std <td>0.207616 <tr> <th>min <td>0.000000 <tr> <th>25% <td>0.262319 <tr> <th>50% <td>0.375000 <tr> <th>75% <td>0.500000 <tr> <th>max <td>1.000000 </table> </div></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[14]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Good in the middle, but many counties have no college grads, and a few only have college grads.</span>
</pre></div> </div> </div> </section> <section id=Exercise-3 > <h3 id=Exercise-3 >Exercise 3<a class=headerlink  href="#Exercise-3" title="Permalink to this heading">¶</a></h3> <p>One of the other advantages of matching is that even when you have balanced data, you don’t have to go through the process of testing out different functional forms to see what fits the data base.</p> <p>In our last exercise, we looked at the relationship between gender and earnings “controlling for age”, where we just put in age as a linear control. Plot a non-linear regression of annual_earnings on age (if you’re using <code class="docutils literal notranslate"><span class=pre >plotnine</span></code>, use <code class="docutils literal notranslate"><span class=pre >geom_smooth(method="lowess")</span></code> — if you’re using altair, use <code class="docutils literal notranslate"><span class=pre >transform_loess</span></code> (<a class="reference external" href="https://www.practicaldatascience.org/html/plotting_altair_part1.html#LOESS">tutorial examples here</a>)).</p> <p>Does the relationship look linear?</p> <p>Does this speak to why it’s nice to not have to think about functional forms with matching as much?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[15]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >altair</span> <span class=k >as</span> <span class=nn >alt</span>

<span class=n >alt</span><span class=o >.</span><span class=n >data_transformers</span><span class=o >.</span><span class=n >enable</span><span class=p >(</span><span class=s2 >"data_server"</span><span class=p >)</span>
<span class=n >alt</span><span class=o >.</span><span class=n >Chart</span><span class=p >(</span><span class=n >cps</span><span class=p >)</span><span class=o >.</span><span class=n >encode</span><span class=p >(</span><span class=n >x</span><span class=o >=</span><span class=s2 >"age"</span><span class=p >,</span> <span class=n >y</span><span class=o >=</span><span class=s2 >"annual_earnings"</span><span class=p >)</span><span class=o >.</span><span class=n >transform_loess</span><span class=p >(</span>
    <span class=n >on</span><span class=o >=</span><span class=s2 >"age"</span><span class=p >,</span> <span class=n >loess</span><span class=o >=</span><span class=s2 >"annual_earnings"</span>
<span class=p >)</span><span class=o >.</span><span class=n >mark_line</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[15]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div id=altair-viz-208ef48025cc4c23a1b6423721876d64 ></div> <script> var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG; (function(spec, embedOpt){ let outputDiv = document.currentScript.previousElementSibling; if (outputDiv.id !== "altair-viz-208ef48025cc4c23a1b6423721876d64") { outputDiv = document.getElementById("altair-viz-208ef48025cc4c23a1b6423721876d64"); } const paths = { "vega": "https://cdn.jsdelivr.net/npm//vega@5?noext", "vega-lib": "https://cdn.jsdelivr.net/npm//vega-lib?noext", "vega-lite": "https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext", "vega-embed": "https://cdn.jsdelivr.net/npm//vega-embed@6?noext", }; function maybeLoadScript(lib, version) { var key = `${lib.replace("-", "")}_version`; return (VEGA_DEBUG[key] == version) ? Promise.resolve(paths[lib]) : new Promise(function(resolve, reject) { var s = document.createElement('script'); document.getElementsByTagName("head")[0].appendChild(s); s.async = true; s.onload = () => { VEGA_DEBUG[key] = version; return resolve(paths[lib]); }; s.onerror = () => reject(`Error loading script: ${paths[lib]}`); s.src = paths[lib]; }); } function showError(err) { outputDiv.innerHTML = `<div class=error  style="color:red;">${err}</div>`; throw err; } function displayChart(vegaEmbed) { vegaEmbed(outputDiv, spec, embedOpt) .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`)); } if(typeof define === "function" && define.amd) { requirejs.config({paths}); require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`)); } else { maybeLoadScript("vega", "5") .then(() => maybeLoadScript("vega-lite", "4.17.0")) .then(() => maybeLoadScript("vega-embed", "6")) .catch(showError) .then(() => displayChart(vegaEmbed)); } })({"config": {"view": {"continuousWidth": 400, "continuousHeight": 300}}, "data": {"url": "http://localhost:52950/0ee7eece2d8f1f8781a1f2ffcc967b60.json"}, "mark": "line", "encoding": {"x": {"field": "age", "type": "quantitative"}, "y": {"field": "annual_earnings", "type": "quantitative"}}, "transform": [{"loess": "annual_earnings", "on": "age"}], "$schema": "https://vega.github.io/schema/vega-lite/v4.17.0.json"}, {"mode": "vega-lite"}); </script></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[16]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Not even remotely linear. Thank goodness we don't have to worry about that with matching!</span>
<span class=c1 ># Though it wouldn't be *that* hard to fit a quadratic.</span>
</pre></div> </div> </div> </section> </section> <section id="Matching!"> <h2 id="Matching!">Matching!<a class=headerlink  href="#Matching!" title="Permalink to this heading">¶</a></h2> <p>Because DAME is an implementation of exact matching, we have to discretize all of our continuous variables. Thankfully, in this case we only have <code class="docutils literal notranslate"><span class=pre >age</span></code>, so this shouldn’t be too hard!</p> <section id=Exercise-4 > <h3 id=Exercise-4 >Exercise 4<a class=headerlink  href="#Exercise-4" title="Permalink to this heading">¶</a></h3> <p>Create a new variable that discretizes age into a single value for each decade of age.</p> <p>Because CPS only has employment data on people 18 or over, though, include people who are 18 or 19 with the 20 year olds so that group isn’t too small, and if you see any other really small groups, please merge those too.</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[17]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >cps</span><span class=p >[</span><span class=s2 >"discretized_age"</span><span class=p >]</span> <span class=o >=</span> <span class=n >cps</span><span class=o >.</span><span class=n >age</span> <span class=o >//</span> <span class=mi >10</span>
<span class=n >cps</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >cps</span><span class=p >[</span><span class=s2 >"discretized_age"</span><span class=p >]</span> <span class=o >==</span> <span class=mi >1</span><span class=p >,</span> <span class=s2 >"discretized_age"</span><span class=p >]</span> <span class=o >=</span> <span class=mi >2</span>
<span class=n >cps</span><span class=p >[</span><span class=s2 >"discretized_age"</span><span class=p >]</span><span class=o >.</span><span class=n >value_counts</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[17]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
3    2760
4    2551
5    2397
2    1990
6    1236
7     173
8      43
Name: discretized_age, dtype: int64
</pre></div></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[18]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># 70 and 80 year olds are tiny groups.</span>
<span class=n >cps</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >cps</span><span class=p >[</span><span class=s2 >"discretized_age"</span><span class=p >]</span> <span class=o >==</span> <span class=mi >8</span><span class=p >,</span> <span class=s2 >"discretized_age"</span><span class=p >]</span> <span class=o >=</span> <span class=mi >7</span>
</pre></div> </div> </div> </section> <section id=Exercise-5 > <h3 id=Exercise-5 >Exercise 5<a class=headerlink  href="#Exercise-5" title="Permalink to this heading">¶</a></h3> <p>We also have to covert our string variables into numeric variables for DAME, so convert <code class="docutils literal notranslate"><span class=pre >county</span></code> and <code class="docutils literal notranslate"><span class=pre >class94</span></code> to a numeric vector of intergers.</p> <p>(Note: it’s not clear whether <code class="docutils literal notranslate"><span class=pre >class94</span></code> belongs: if it reflects people choosing fields based on passion, it belongs; if people choose certain jobs because of their degrees, its not something we’d actually want in our regression.</p> <p>Hint: if you use <code class="docutils literal notranslate"><span class=pre >pd.Categorical</span></code> to convert you var to a categorical, you can pull the underlying integer codes with <code class="docutils literal notranslate"><span class=pre >.codes</span></code>.</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[19]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >cps</span><span class=p >[</span><span class=s2 >"county"</span><span class=p >]</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >Categorical</span><span class=p >(</span><span class=n >cps</span><span class=p >[</span><span class=s2 >"county"</span><span class=p >])</span><span class=o >.</span><span class=n >codes</span>
<span class=n >cps</span><span class=p >[</span><span class=s2 >"county"</span><span class=p >]</span><span class=o >.</span><span class=n >value_counts</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[19]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
41     576
200    275
12     230
33     225
51     223
      ...
122      1
263      1
285      1
154      1
213      1
Name: county, Length: 326, dtype: int64
</pre></div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[20]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >cps</span><span class=p >[</span><span class=s2 >"class94"</span><span class=p >]</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >Categorical</span><span class=p >(</span><span class=n >cps</span><span class=p >[</span><span class=s2 >"class94"</span><span class=p >])</span><span class=o >.</span><span class=n >codes</span>
<span class=n >cps</span><span class=p >[</span><span class=s2 >"class94"</span><span class=p >]</span><span class=o >.</span><span class=n >value_counts</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[20]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
3    7809
1     740
4     706
2     615
6     552
5     387
0     337
7       4
Name: class94, dtype: int64
</pre></div></div> </div> </section> </section> <section id="Let's-Do-Matching-with-DAME"> <h2 id="Let's-Do-Matching-with-DAME">Let’s Do Matching with DAME<a class=headerlink  href="#Let's-Do-Matching-with-DAME" title="Permalink to this heading">¶</a></h2> <section id=Exercise-6 > <h3 id=Exercise-6 >Exercise 6<a class=headerlink  href="#Exercise-6" title="Permalink to this heading">¶</a></h3> <p>First, drop all the variables you <em>don’t</em> want in matching (e.g. your original <code class="docutils literal notranslate"><span class=pre >age</span></code> variable), and any observations for which <code class="docutils literal notranslate"><span class=pre >annual_earnings</span></code> is missing.</p> <p>You will probably also have to drop a column named <code class="docutils literal notranslate"><span class=pre >index</span></code>: DAME will try and match on ANY included variables, and so because there was a column called <code class="docutils literal notranslate"><span class=pre >index</span></code> in the data we imported, if we leave it in DAME will try (and obviously fail) to match on index.</p> <p>Also, it’s best to reset your index, as <code class="docutils literal notranslate"><span class=pre >dame_flame</span></code> using index labels (e.g., the values in <code class="docutils literal notranslate"><span class=pre >df.index</span></code>) to identify matches. So you want to be sure those are unique.</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[21]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >for_matching</span> <span class=o >=</span> <span class=n >cps</span><span class=o >.</span><span class=n >drop</span><span class=p >([</span><span class=s2 >"age"</span><span class=p >,</span> <span class=s2 >"index"</span><span class=p >],</span> <span class=n >axis</span><span class=o >=</span><span class=s2 >"columns"</span><span class=p >)</span>
<span class=n >for_matching</span> <span class=o >=</span> <span class=n >for_matching</span><span class=p >[</span><span class=n >for_matching</span><span class=o >.</span><span class=n >annual_earnings</span><span class=o >.</span><span class=n >notnull</span><span class=p >()]</span>
<span class=n >for_matching</span> <span class=o >=</span> <span class=n >for_matching</span><span class=o >.</span><span class=n >reset_index</span><span class=p >(</span><span class=n >drop</span><span class=o >=</span><span class=kc >True</span><span class=p >)</span>
<span class=n >for_matching</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[21]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border=1  class=dataframe > <thead> <tr style="text-align: right;"> <th> <th>annual_earnings <th>female <th>simplified_race <th>has_college <th>county <th>class94 <th>discretized_age <tr> <th>0 <td>42900.0 <td>1 <td>0.0 <td>0 <td>10 <td>3 <td>5 <tr> <th>1 <td>31200.0 <td>0 <td>2.0 <td>0 <td>31 <td>3 <td>3 <tr> <th>2 <td>20020.0 <td>0 <td>0.0 <td>1 <td>8 <td>3 <td>6 <tr> <th>3 <td>22859.2 <td>0 <td>0.0 <td>0 <td>44 <td>1 <td>4 <tr> <th>4 <td>73860.8 <td>0 <td>0.0 <td>1 <td>24 <td>3 <td>3 <tr> <th>... <td>... <td>... <td>... <td>... <td>... <td>... <td>... <tr> <th>5510 <td>33800.0 <td>1 <td>3.0 <td>0 <td>247 <td>3 <td>3 <tr> <th>5511 <td>23920.0 <td>0 <td>3.0 <td>0 <td>272 <td>3 <td>5 <tr> <th>5512 <td>31200.0 <td>0 <td>2.0 <td>0 <td>246 <td>3 <td>2 <tr> <th>5513 <td>37440.0 <td>0 <td>0.0 <td>0 <td>99 <td>3 <td>2 <tr> <th>5514 <td>26000.0 <td>0 <td>1.0 <td>0 <td>23 <td>2 <td>5 </table> <p>5515 rows × 7 columns</p> </div></div> </div> </section> <section id=Exercise-7 > <h3 id=Exercise-7 >Exercise 7<a class=headerlink  href="#Exercise-7" title="Permalink to this heading">¶</a></h3> <p>The syntax of <code class="docutils literal notranslate"><span class=pre >dame_flame</span></code> is similar to the syntax of <code class="docutils literal notranslate"><span class=pre >sklearn</span></code>. If you start with a dataset called <code class="docutils literal notranslate"><span class=pre >my_data</span></code> with a <code class="docutils literal notranslate"><span class=pre >treat</span></code> variable with treatment assignment and an <code class="docutils literal notranslate"><span class=pre >outcome</span></code> variable for my outcome of interest (<span class="math notranslate nohighlight">\(Y\)</span>), the syntax to do basic matching would be:</p> <div class="highlight-python notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >dame_flame</span>
<span class=n >model</span> <span class=o >=</span> <span class=n >dame_flame</span><span class=o >.</span><span class=n >matching</span><span class=o >.</span><span class=n >DAME</span><span class=p >(</span><span class=n >repeats</span><span class=o >=</span><span class=kc >False</span><span class=p >,</span> <span class=n >verbose</span><span class=o >=</span><span class=mi >3</span><span class=p >,</span> <span class=n >want_pe</span><span class=o >=</span><span class=kc >True</span><span class=p >)</span>
<span class=n >model</span><span class=o >.</span><span class=n >fit</span><span class=p >(</span>
    <span class=n >my_data</span><span class=p >,</span>
    <span class=n >treatment_column_name</span><span class=o >=</span><span class=s2 >"treat"</span><span class=p >,</span>
    <span class=n >outcome_column_name</span><span class=o >=</span><span class=s2 >"outcome"</span><span class=p >,</span>
<span class=p >)</span>
<span class=n >result</span> <span class=o >=</span> <span class=n >model</span><span class=o >.</span><span class=n >predict</span><span class=p >(</span><span class=n >my_data</span><span class=p >)</span>
</pre></div> </div> <p>Where the arguments:</p> <ul class=simple > <li><p><code class="docutils literal notranslate"><span class=pre >repeats=False</span></code> says that I only want each observation to get matched once. We’ll talk about what happens if we use <code class="docutils literal notranslate"><span class=pre >repeats=True</span></code> below.</p> <li><p><code class="docutils literal notranslate"><span class=pre >verbose=3</span></code> tells dame to report everything it’s doing as it goes.</p> <li><p><code class="docutils literal notranslate"><span class=pre >want_pe</span></code> says “please include the predictive error in your printout at each step”. This is a measure of match quality.</p> </ul> <p>So run DAME on your data!</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[22]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >model</span> <span class=o >=</span> <span class=n >dame_flame</span><span class=o >.</span><span class=n >matching</span><span class=o >.</span><span class=n >DAME</span><span class=p >(</span><span class=n >repeats</span><span class=o >=</span><span class=kc >False</span><span class=p >,</span> <span class=n >verbose</span><span class=o >=</span><span class=mi >3</span><span class=p >,</span> <span class=n >want_pe</span><span class=o >=</span><span class=kc >True</span><span class=p >)</span>
<span class=n >model</span><span class=o >.</span><span class=n >fit</span><span class=p >(</span>
    <span class=n >for_matching</span><span class=p >,</span>
    <span class=n >treatment_column_name</span><span class=o >=</span><span class=s2 >"has_college"</span><span class=p >,</span>
    <span class=n >outcome_column_name</span><span class=o >=</span><span class=s2 >"annual_earnings"</span><span class=p >,</span>
<span class=p >)</span>
<span class=n >result</span> <span class=o >=</span> <span class=n >model</span><span class=o >.</span><span class=n >predict</span><span class=p >(</span><span class=n >for_matching</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
Completed iteration 0 of matching
        Number of matched groups formed in total:  370
        Unmatched treated units:  644 out of a total of  1150 treated units
        Unmatched control units:  3187 out of a total of  4365 control units
        Number of matches made this iteration:  1684
        Number of matches made so far:  1684
        Covariates dropped so far:  set()
        Predictive error of covariate set used to match:  1199312680.0957854
Completed iteration 1 of matching
        Number of matched groups formed in total:  494
        Unmatched treated units:  25 out of a total of  1150 treated units
        Unmatched control units:  180 out of a total of  4365 control units
        Number of matches made this iteration:  3626
        Number of matches made so far:  5310
        Covariates dropped so far:  frozenset({'county'})
        Predictive error of covariate set used to match:  1199421883.1095908
Completed iteration 2 of matching
        Number of matched groups formed in total:  494
        Unmatched treated units:  25 out of a total of  1150 treated units
        Unmatched control units:  180 out of a total of  4365 control units
        Number of matches made this iteration:  0
        Number of matches made so far:  5310
        Covariates dropped so far:  frozenset({'simplified_race'})
        Predictive error of covariate set used to match:  1204727749.8949614
Completed iteration 3 of matching
        Number of matched groups formed in total:  505
        Unmatched treated units:  8 out of a total of  1150 treated units
        Unmatched control units:  129 out of a total of  4365 control units
        Number of matches made this iteration:  68
        Number of matches made so far:  5378
        Covariates dropped so far:  frozenset({'county', 'simplified_race'})
        Predictive error of covariate set used to match:  1204742613.479154
Completed iteration 4 of matching
        Number of matched groups formed in total:  505
        Unmatched treated units:  8 out of a total of  1150 treated units
        Unmatched control units:  129 out of a total of  4365 control units
        Number of matches made this iteration:  0
        Number of matches made so far:  5378
        Covariates dropped so far:  frozenset({'class94'})
        Predictive error of covariate set used to match:  1205072671.3262901
Completed iteration 5 of matching
        Number of matched groups formed in total:  508
        Unmatched treated units:  5 out of a total of  1150 treated units
        Unmatched control units:  120 out of a total of  4365 control units
        Number of matches made this iteration:  12
        Number of matches made so far:  5390
        Covariates dropped so far:  frozenset({'class94', 'county'})
        Predictive error of covariate set used to match:  1205171280.4727237
Completed iteration 6 of matching
        Number of matched groups formed in total:  509
        Unmatched treated units:  4 out of a total of  1150 treated units
        Unmatched control units:  119 out of a total of  4365 control units
        Number of matches made this iteration:  2
        Number of matches made so far:  5392
        Covariates dropped so far:  frozenset({'class94', 'simplified_race'})
        Predictive error of covariate set used to match:  1210524158.7436352
Completed iteration 7 of matching
        Number of matched groups formed in total:  511
        Unmatched treated units:  0 out of a total of  1150 treated units
        Unmatched control units:  110 out of a total of  4365 control units
        Number of matches made this iteration:  13
        Number of matches made so far:  5405
        Covariates dropped so far:  frozenset({'class94', 'county', 'simplified_race'})
        Predictive error of covariate set used to match:  1210539313.933855
5405 units matched. We finished with no more treated units to match
</pre></div></div> </div> </section> </section> <section id=Interpreting-DAME-output > <h2 id=Interpreting-DAME-output >Interpreting DAME output<a class=headerlink  href="#Interpreting-DAME-output" title="Permalink to this heading">¶</a></h2> <p>The output you get from doing this <em>should</em> be reports from about 8 iterations of matching. In each iteration, you’ll see a description of the number of matches made in the iteration, the number of treatment units still unmatched, and the number of control units unmatched.</p> <p>In the first iteration, the algorithm tries to match observations that match on <em>all</em> the variables in your data. That’s why in the first iteration, you see the set of variables being dropped is an empty set – it <em>hasn’t</em> dropped any variables:</p> <div class="highlight-none notranslate"><div class=highlight ><pre><span></span>Completed iteration 0 of matching
    Number of matched groups formed in total:  370
    Unmatched treated units:  644 out of a total of  1150 treated units
    Unmatched control units:  3187 out of a total of  4365 control units
    Number of matches made this iteration:  1684
    Number of matches made so far:  1684
    Covariates dropped so far:  set()
    Predictive error of covariate set used to match:  1199312680.0957854
</pre></div> </div> <p>(Note depending on how you binned ages, you may get slightly different results than this)</p> <p>But as we can see from this output, the algorithm found 1,684 perfect matches—pairs of observations (one treated, one untreated) that had <em>exactly</em> the same value of all the variables we included. But we also see we still have 644 <em>unmatched</em> treated units, so what do we do?</p> <p>The answer is that if we want to match more of our treatment variables, we have to try and match on a subset of our variables.</p> <p>But what variable should we drop? This is the secret sauce of DAME. DAME picks the variables to drop by trying to predict our outcome <span class="math notranslate nohighlight">\(Y\)</span> using all our variables (by default using a ridge regression), then it drops the matching variable that is contributing the least to that prediction. Since our goal in matching is to eliminate baseline differences (<span class="math notranslate nohighlight">\(E(Y_0|D=1) - E(Y_1|D=0)\)</span>), dropping the covariates least related to <span class="math notranslate nohighlight">\(Y\)</span> makes sense.</p> <p>As a result, in the second iteration (called iteration 1, since it uses 0-based indexing), we see that the variable it drops first is <code class="docutils literal notranslate"><span class=pre >county</span></code>, and it’s subsequently able to make another 3,626 new matches on the remaining variables!</p> <div class="highlight-none notranslate"><div class=highlight ><pre><span></span>Completed iteration 1 of matching
    Number of matched groups formed in total:  494
    Unmatched treated units:  25 out of a total of  1150 treated units
    Unmatched control units:  180 out of a total of  4365 control units
    Number of matches made this iteration:  3626
    Number of matches made so far:  5310
    Covariates dropped so far:  frozenset({'county'})
    Predictive error of covariate set used to match:  1199421883.1095908
</pre></div> </div> <p>And so DAME continues until after 8 iterations, it’s matched all treated observations.</p> </section> <section id=Exercise-8 > <h2 id=Exercise-8 >Exercise 8<a class=headerlink  href="#Exercise-8" title="Permalink to this heading">¶</a></h2> <p>Congratulations! You just on your first one-to-many matching!</p> <p>The next step is to think about which of the matches that DAME generated are good enough for inclusion in our analysis. As you may recall, one of the choices you have to make as a researcher when doing matching is how “good” a match has to be in order to be included in your final data set. By default, DAME will keep dropping matching variables until it has been able to match all the treated observations or runs out of variables. It will do this no matter how bad the matches start to become – if it ends up with the treated observation and a control observation that can only be matched on gender, it will match them just on gender, even though we probably don’t think that that’s a “good” match.</p> <p>The way to control this behavior is to tell DAME when to stop manually using the <code class="docutils literal notranslate"><span class=pre >early_stop_iterations</span></code> argument to tell the matching algorithm when to stop.</p> <p>So when is a good time to stop? There’s no objective or “right” answer to that question. It fundamentally comes down to a trade-off between bias (which gets higher is you allow more low quality matches into your data) and variance (which will go down as you increase the number of matches you keep).</p> <p>But one way to start the process of picking a cut point is to examine how the quality of matches evolves over iterations. DAME keeps this information in <code class="docutils literal notranslate"><span class=pre >model.pe_each_iter</span></code>. This shows, for each iteration, the “prediction error” resulting from dropping the variables excluded in each step. This “prediction error” is the difference in the mean-squared error of regressing <span class="math notranslate nohighlight">\(Y\)</span> on our matching variables (by default in a ridge regression) with all variables versus with the subset being used for matching in a given iteration. By design, of course, this is always increasing.</p> <p>To see how this evolves, plot your <code class="docutils literal notranslate"><span class=pre >pe</span></code> against iteration numbers. You can also see the <code class="docutils literal notranslate"><span class=pre >pe</span></code> values for each iteration reported in the output from when DAME ran above if you want to make your you’re lining up the errors with iterations right.</p> <p>Are there any points where the match quality seems to fall off dramatically?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[23]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >model</span><span class=o >.</span><span class=n >pe_each_iter</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[23]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
[1199312680.0957854,
 1199421883.1095908,
 1204727749.8949614,
 1204742613.479154,
 1205072671.3262901,
 1205171280.4727237,
 1210524158.7436352,
 1210539313.933855]
</pre></div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[24]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >for_pe</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >DataFrame</span><span class=p >(</span>
    <span class=p >{</span><span class=s2 >"pe"</span><span class=p >:</span> <span class=n >model</span><span class=o >.</span><span class=n >pe_each_iter</span><span class=p >,</span> <span class=s2 >"i"</span><span class=p >:</span> <span class=nb >range</span><span class=p >(</span><span class=mi >0</span><span class=p >,</span> <span class=nb >len</span><span class=p >(</span><span class=n >model</span><span class=o >.</span><span class=n >pe_each_iter</span><span class=p >))}</span>
<span class=p >)</span>
<span class=n >for_pe</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[24]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border=1  class=dataframe > <thead> <tr style="text-align: right;"> <th> <th>pe <th>i <tr> <th>0 <td>1.199313e+09 <td>0 <tr> <th>1 <td>1.199422e+09 <td>1 <tr> <th>2 <td>1.204728e+09 <td>2 <tr> <th>3 <td>1.204743e+09 <td>3 <tr> <th>4 <td>1.205073e+09 <td>4 <tr> <th>5 <td>1.205171e+09 <td>5 <tr> <th>6 <td>1.210524e+09 <td>6 <tr> <th>7 <td>1.210539e+09 <td>7 </table> </div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[25]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >alt</span><span class=o >.</span><span class=n >Chart</span><span class=p >(</span><span class=n >for_pe</span><span class=p >)</span><span class=o >.</span><span class=n >encode</span><span class=p >(</span><span class=n >x</span><span class=o >=</span><span class=s2 >"i"</span><span class=p >,</span> <span class=n >y</span><span class=o >=</span><span class=n >alt</span><span class=o >.</span><span class=n >Y</span><span class=p >(</span><span class=s2 >"pe"</span><span class=p >,</span> <span class=n >scale</span><span class=o >=</span><span class=n >alt</span><span class=o >.</span><span class=n >Scale</span><span class=p >(</span><span class=n >zero</span><span class=o >=</span><span class=kc >False</span><span class=p >)))</span><span class=o >.</span><span class=n >mark_line</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[25]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div id=altair-viz-ee1df7d789d3496f9065ef8dbedd76ef ></div> <script> var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG; (function(spec, embedOpt){ let outputDiv = document.currentScript.previousElementSibling; if (outputDiv.id !== "altair-viz-ee1df7d789d3496f9065ef8dbedd76ef") { outputDiv = document.getElementById("altair-viz-ee1df7d789d3496f9065ef8dbedd76ef"); } const paths = { "vega": "https://cdn.jsdelivr.net/npm//vega@5?noext", "vega-lib": "https://cdn.jsdelivr.net/npm//vega-lib?noext", "vega-lite": "https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext", "vega-embed": "https://cdn.jsdelivr.net/npm//vega-embed@6?noext", }; function maybeLoadScript(lib, version) { var key = `${lib.replace("-", "")}_version`; return (VEGA_DEBUG[key] == version) ? Promise.resolve(paths[lib]) : new Promise(function(resolve, reject) { var s = document.createElement('script'); document.getElementsByTagName("head")[0].appendChild(s); s.async = true; s.onload = () => { VEGA_DEBUG[key] = version; return resolve(paths[lib]); }; s.onerror = () => reject(`Error loading script: ${paths[lib]}`); s.src = paths[lib]; }); } function showError(err) { outputDiv.innerHTML = `<div class=error  style="color:red;">${err}</div>`; throw err; } function displayChart(vegaEmbed) { vegaEmbed(outputDiv, spec, embedOpt) .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`)); } if(typeof define === "function" && define.amd) { requirejs.config({paths}); require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`)); } else { maybeLoadScript("vega", "5") .then(() => maybeLoadScript("vega-lite", "4.17.0")) .then(() => maybeLoadScript("vega-embed", "6")) .catch(showError) .then(() => displayChart(vegaEmbed)); } })({"config": {"view": {"continuousWidth": 400, "continuousHeight": 300}}, "data": {"url": "http://localhost:52950/5daefbdc55be31bb427f0923f82460d3.json"}, "mark": "line", "encoding": {"x": {"field": "i", "type": "quantitative"}, "y": {"field": "pe", "scale": {"zero": false}, "type": "quantitative"}}, "$schema": "https://vega.github.io/schema/vega-lite/v4.17.0.json"}, {"mode": "vega-lite"}); </script></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[26]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Yup! Iteration 2 and 6 are the really the big ones...</span>
</pre></div> </div> </div> <section id=Exercise-9 > <h3 id=Exercise-9 >Exercise 9<a class=headerlink  href="#Exercise-9" title="Permalink to this heading">¶</a></h3> <p>Suppose we want to ensure we have at least 5,000 observations in our matched data—where might you cut off the data to get a sample size of at least that but before a big quality falloff?</p> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[27]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># I'd stop after iteration 1 (the second iteration)—things fall off fast</span>
<span class=c1 ># starting after that, but with very few added matches.</span>
</pre></div> </div> </div> </section> <section id=Exercise-10 > <h3 id=Exercise-10 >Exercise 10<a class=headerlink  href="#Exercise-10" title="Permalink to this heading">¶</a></h3> <p>Re-run your matching, stopping at the point you picked above using <code class="docutils literal notranslate"><span class=pre >early_stop_iterations</span></code>.</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[28]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >model</span> <span class=o >=</span> <span class=n >dame_flame</span><span class=o >.</span><span class=n >matching</span><span class=o >.</span><span class=n >DAME</span><span class=p >(</span>
    <span class=n >repeats</span><span class=o >=</span><span class=kc >False</span><span class=p >,</span> <span class=n >verbose</span><span class=o >=</span><span class=mi >3</span><span class=p >,</span> <span class=n >want_pe</span><span class=o >=</span><span class=kc >True</span><span class=p >,</span> <span class=n >early_stop_iterations</span><span class=o >=</span><span class=mi >1</span>
<span class=p >)</span>
<span class=n >model</span><span class=o >.</span><span class=n >fit</span><span class=p >(</span>
    <span class=n >for_matching</span><span class=p >,</span>
    <span class=n >treatment_column_name</span><span class=o >=</span><span class=s2 >"has_college"</span><span class=p >,</span>
    <span class=n >outcome_column_name</span><span class=o >=</span><span class=s2 >"annual_earnings"</span><span class=p >,</span>
<span class=p >)</span>
<span class=n >result</span> <span class=o >=</span> <span class=n >model</span><span class=o >.</span><span class=n >predict</span><span class=p >(</span><span class=n >for_matching</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
Completed iteration 0 of matching
        Number of matched groups formed in total:  370
        Unmatched treated units:  644 out of a total of  1150 treated units
        Unmatched control units:  3187 out of a total of  4365 control units
        Number of matches made this iteration:  1684
        Number of matches made so far:  1684
        Covariates dropped so far:  set()
        Predictive error of covariate set used to match:  1199312680.0957854
Completed iteration 1 of matching
        Number of matched groups formed in total:  494
        Unmatched treated units:  25 out of a total of  1150 treated units
        Unmatched control units:  180 out of a total of  4365 control units
        Number of matches made this iteration:  3626
        Number of matches made so far:  5310
        Covariates dropped so far:  frozenset({'county'})
        Predictive error of covariate set used to match:  1199421883.1095908
5310 units matched. We stopped after iteration 1
</pre></div></div> </div> </section> </section> <section id=Getting-Back-a-Dataset > <h2 id=Getting-Back-a-Dataset >Getting Back a Dataset<a class=headerlink  href="#Getting-Back-a-Dataset" title="Permalink to this heading">¶</a></h2> <p>OK, my one current complaint with DAME is that it doesn’t just give you back a nice dataset of your matches for analysis. If we look at our results – <code class="docutils literal notranslate"><span class=pre >matches</span></code> – it’s <em>almost</em> what we want, except it’s dropped our treatment and outcome columns, and it’s put a string <code class="docutils literal notranslate"><span class=pre >*</span></code> in any entry where a value <em>wasn’t</em> used for matching:</p> <div class="highlight-none notranslate"><div class=highlight ><pre><span></span>  female simplified_race   county   class94   discretized_age
0  1.0     0.0              10.0      3.0          5.0
1  0.0     2.0              *         3.0          3.0
2  0.0     0.0              8.0        3.0         6.0
3  0.0     0.0              *         1.0          4.0
4  0.0     0.0              24.0      3.0          3.0
</pre></div> </div> <p>So for now (though I think this will get updated in the package), we’ll have to do it ourselves! Just copy-paste this:</p> <div class="highlight-python notranslate"><div class=highlight ><pre><span></span><span class=k >def</span> <span class=nf >get_dataframe</span><span class=p >(</span><span class=n >model</span><span class=p >,</span> <span class=n >result_of_fit</span><span class=p >):</span>

    <span class=c1 ># Get original data</span>
    <span class=n >better</span> <span class=o >=</span> <span class=n >model</span><span class=o >.</span><span class=n >input_data</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >result_of_fit</span><span class=o >.</span><span class=n >index</span><span class=p >]</span>
    <span class=k >if</span> <span class=ow >not</span> <span class=n >better</span><span class=o >.</span><span class=n >index</span><span class=o >.</span><span class=n >is_unique</span><span class=p >:</span>
        <span class=k >raise</span> <span class=ne >ValueError</span><span class=p >(</span><span class=s2 >"Need index values in input data to be unique"</span><span class=p >)</span>

    <span class=c1 ># Get match groups for clustering</span>
    <span class=n >better</span><span class=p >[</span><span class=s2 >"match_group"</span><span class=p >]</span> <span class=o >=</span> <span class=n >np</span><span class=o >.</span><span class=n >nan</span>
    <span class=n >better</span><span class=p >[</span><span class=s2 >"match_group_size"</span><span class=p >]</span> <span class=o >=</span> <span class=n >np</span><span class=o >.</span><span class=n >nan</span>
    <span class=k >for</span> <span class=n >idx</span><span class=p >,</span> <span class=n >group</span> <span class=ow >in</span> <span class=nb >enumerate</span><span class=p >(</span><span class=n >model</span><span class=o >.</span><span class=n >units_per_group</span><span class=p >):</span>
        <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >group</span><span class=p >,</span> <span class=s2 >"match_group"</span><span class=p >]</span> <span class=o >=</span> <span class=n >idx</span>
        <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >group</span><span class=p >,</span> <span class=s2 >"match_group_size"</span><span class=p >]</span> <span class=o >=</span> <span class=nb >len</span><span class=p >(</span><span class=n >group</span><span class=p >)</span>

    <span class=c1 ># Get weights. I THINK this is right?! At least for with repeat=False?</span>
    <span class=n >t</span> <span class=o >=</span> <span class=n >model</span><span class=o >.</span><span class=n >treatment_column_name</span>
    <span class=n >better</span><span class=p >[</span><span class=s2 >"t_in_group"</span><span class=p >]</span> <span class=o >=</span> <span class=n >better</span><span class=o >.</span><span class=n >groupby</span><span class=p >(</span><span class=s2 >"match_group"</span><span class=p >)[</span><span class=n >t</span><span class=p >]</span><span class=o >.</span><span class=n >transform</span><span class=p >(</span><span class=n >np</span><span class=o >.</span><span class=n >sum</span><span class=p >)</span>

    <span class=c1 ># Make weights</span>
    <span class=n >better</span><span class=p >[</span><span class=s2 >"weights"</span><span class=p >]</span> <span class=o >=</span> <span class=n >np</span><span class=o >.</span><span class=n >nan</span>
    <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >1</span><span class=p >,</span> <span class=s2 >"weights"</span><span class=p >]</span> <span class=o >=</span> <span class=mi >1</span>  <span class=c1 ># treaments are 1</span>

    <span class=c1 ># Controls start as proportional to num of treatments</span>
    <span class=c1 ># each observation is matched to.</span>
    <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >,</span> <span class=s2 >"weights"</span><span class=p >]</span> <span class=o >=</span> <span class=n >better</span><span class=p >[</span><span class=s2 >"t_in_group"</span><span class=p >]</span> <span class=o >/</span> <span class=p >(</span>
        <span class=n >better</span><span class=p >[</span><span class=s2 >"match_group_size"</span><span class=p >]</span> <span class=o >-</span> <span class=n >better</span><span class=p >[</span><span class=s2 >"t_in_group"</span><span class=p >]</span>
    <span class=p >)</span>

    <span class=c1 ># Then re-normalize for num unique control observations.</span>
    <span class=n >control_weights</span> <span class=o >=</span> <span class=n >better</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >][</span><span class=s2 >"weights"</span><span class=p >]</span><span class=o >.</span><span class=n >sum</span><span class=p >()</span>

    <span class=n >num_control_obs</span> <span class=o >=</span> <span class=nb >len</span><span class=p >(</span><span class=n >better</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >]</span><span class=o >.</span><span class=n >index</span><span class=o >.</span><span class=n >drop_duplicates</span><span class=p >())</span>
    <span class=n >renormalization</span> <span class=o >=</span> <span class=n >num_control_obs</span> <span class=o >/</span> <span class=n >control_weights</span>
    <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >,</span> <span class=s2 >"weights"</span><span class=p >]</span> <span class=o >=</span> <span class=p >(</span>
        <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >,</span> <span class=s2 >"weights"</span><span class=p >]</span> <span class=o >*</span> <span class=n >renormalization</span>
    <span class=p >)</span>
    <span class=k >assert</span> <span class=n >better</span><span class=o >.</span><span class=n >weights</span><span class=o >.</span><span class=n >notnull</span><span class=p >()</span><span class=o >.</span><span class=n >all</span><span class=p >()</span>

    <span class=n >better</span> <span class=o >=</span> <span class=n >better</span><span class=o >.</span><span class=n >drop</span><span class=p >([</span><span class=s2 >"t_in_group"</span><span class=p >],</span> <span class=n >axis</span><span class=o >=</span><span class=s2 >"columns"</span><span class=p >)</span>

    <span class=c1 ># Make sure right length and values!</span>
    <span class=k >assert</span> <span class=nb >len</span><span class=p >(</span><span class=n >result_of_fit</span><span class=p >)</span> <span class=o >==</span> <span class=nb >len</span><span class=p >(</span><span class=n >better</span><span class=p >)</span>
    <span class=k >assert</span> <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >,</span> <span class=s2 >"weights"</span><span class=p >]</span><span class=o >.</span><span class=n >sum</span><span class=p >()</span> <span class=o >==</span> <span class=n >num_control_obs</span>

    <span class=k >return</span> <span class=n >better</span>
</pre></div> </div> <section id=Exercise-11 > <h3 id=Exercise-11 >Exercise 11<a class=headerlink  href="#Exercise-11" title="Permalink to this heading">¶</a></h3> <p>Copy-paste that code and run it with your original data, your (fit) model, and what you got back when you ran <code class="docutils literal notranslate"><span class=pre >result_of_fit</span></code>. Then we’ll work with the output of that. You should get back a single dataframe of the same length as your original model.</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[29]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >result</span>
<br/></pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[29]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border=1  class=dataframe > <thead> <tr style="text-align: right;"> <th> <th>female <th>simplified_race <th>county <th>class94 <th>discretized_age <tr> <th>0 <td>1.0 <td>0.0 <td>10.0 <td>3.0 <td>5.0 <tr> <th>1 <td>0.0 <td>2.0 <td>* <td>3.0 <td>3.0 <tr> <th>2 <td>0.0 <td>0.0 <td>8.0 <td>3.0 <td>6.0 <tr> <th>3 <td>0.0 <td>0.0 <td>* <td>1.0 <td>4.0 <tr> <th>4 <td>0.0 <td>0.0 <td>24.0 <td>3.0 <td>3.0 <tr> <th>... <td>... <td>... <td>... <td>... <td>... <tr> <th>5509 <td>0.0 <td>0.0 <td>* <td>3.0 <td>6.0 <tr> <th>5510 <td>1.0 <td>3.0 <td>247.0 <td>3.0 <td>3.0 <tr> <th>5511 <td>0.0 <td>3.0 <td>* <td>3.0 <td>5.0 <tr> <th>5512 <td>0.0 <td>2.0 <td>246.0 <td>3.0 <td>2.0 <tr> <th>5513 <td>0.0 <td>0.0 <td>99.0 <td>3.0 <td>2.0 </table> <p>5310 rows × 5 columns</p> </div></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[30]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=k >def</span> <span class=nf >get_dataframe</span><span class=p >(</span><span class=n >model</span><span class=p >,</span> <span class=n >result_of_fit</span><span class=p >):</span>

    <span class=c1 ># Get original data</span>
    <span class=n >better</span> <span class=o >=</span> <span class=n >model</span><span class=o >.</span><span class=n >input_data</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >result_of_fit</span><span class=o >.</span><span class=n >index</span><span class=p >]</span>
    <span class=k >if</span> <span class=ow >not</span> <span class=n >better</span><span class=o >.</span><span class=n >index</span><span class=o >.</span><span class=n >is_unique</span><span class=p >:</span>
        <span class=k >raise</span> <span class=ne >ValueError</span><span class=p >(</span><span class=s2 >"Need index values in input data to be unique"</span><span class=p >)</span>

    <span class=c1 ># Get match groups for clustering</span>
    <span class=n >better</span><span class=p >[</span><span class=s2 >"match_group"</span><span class=p >]</span> <span class=o >=</span> <span class=n >np</span><span class=o >.</span><span class=n >nan</span>
    <span class=n >better</span><span class=p >[</span><span class=s2 >"match_group_size"</span><span class=p >]</span> <span class=o >=</span> <span class=n >np</span><span class=o >.</span><span class=n >nan</span>
    <span class=k >for</span> <span class=n >idx</span><span class=p >,</span> <span class=n >group</span> <span class=ow >in</span> <span class=nb >enumerate</span><span class=p >(</span><span class=n >model</span><span class=o >.</span><span class=n >units_per_group</span><span class=p >):</span>
        <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >group</span><span class=p >,</span> <span class=s2 >"match_group"</span><span class=p >]</span> <span class=o >=</span> <span class=n >idx</span>
        <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >group</span><span class=p >,</span> <span class=s2 >"match_group_size"</span><span class=p >]</span> <span class=o >=</span> <span class=nb >len</span><span class=p >(</span><span class=n >group</span><span class=p >)</span>

    <span class=c1 ># Get weights. I THINK this is right?! At least for with repeat=False?</span>
    <span class=n >t</span> <span class=o >=</span> <span class=n >model</span><span class=o >.</span><span class=n >treatment_column_name</span>
    <span class=n >better</span><span class=p >[</span><span class=s2 >"t_in_group"</span><span class=p >]</span> <span class=o >=</span> <span class=n >better</span><span class=o >.</span><span class=n >groupby</span><span class=p >(</span><span class=s2 >"match_group"</span><span class=p >)[</span><span class=n >t</span><span class=p >]</span><span class=o >.</span><span class=n >transform</span><span class=p >(</span><span class=n >np</span><span class=o >.</span><span class=n >sum</span><span class=p >)</span>

    <span class=c1 ># Make weights</span>
    <span class=n >better</span><span class=p >[</span><span class=s2 >"weights"</span><span class=p >]</span> <span class=o >=</span> <span class=n >np</span><span class=o >.</span><span class=n >nan</span>
    <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >1</span><span class=p >,</span> <span class=s2 >"weights"</span><span class=p >]</span> <span class=o >=</span> <span class=mi >1</span>  <span class=c1 ># treaments are 1</span>

    <span class=c1 ># Controls start as proportional to num of treatments</span>
    <span class=c1 ># each observation is matched to.</span>
    <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >,</span> <span class=s2 >"weights"</span><span class=p >]</span> <span class=o >=</span> <span class=n >better</span><span class=p >[</span><span class=s2 >"t_in_group"</span><span class=p >]</span> <span class=o >/</span> <span class=p >(</span>
        <span class=n >better</span><span class=p >[</span><span class=s2 >"match_group_size"</span><span class=p >]</span> <span class=o >-</span> <span class=n >better</span><span class=p >[</span><span class=s2 >"t_in_group"</span><span class=p >]</span>
    <span class=p >)</span>

    <span class=c1 ># Then re-normalize for num unique control observations.</span>
    <span class=n >control_weights</span> <span class=o >=</span> <span class=n >better</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >][</span><span class=s2 >"weights"</span><span class=p >]</span><span class=o >.</span><span class=n >sum</span><span class=p >()</span>

    <span class=n >num_control_obs</span> <span class=o >=</span> <span class=nb >len</span><span class=p >(</span><span class=n >better</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >]</span><span class=o >.</span><span class=n >index</span><span class=o >.</span><span class=n >drop_duplicates</span><span class=p >())</span>
    <span class=n >renormalization</span> <span class=o >=</span> <span class=n >num_control_obs</span> <span class=o >/</span> <span class=n >control_weights</span>
    <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >,</span> <span class=s2 >"weights"</span><span class=p >]</span> <span class=o >=</span> <span class=p >(</span>
        <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >,</span> <span class=s2 >"weights"</span><span class=p >]</span> <span class=o >*</span> <span class=n >renormalization</span>
    <span class=p >)</span>
    <span class=k >assert</span> <span class=n >better</span><span class=o >.</span><span class=n >weights</span><span class=o >.</span><span class=n >notnull</span><span class=p >()</span><span class=o >.</span><span class=n >all</span><span class=p >()</span>

    <span class=n >better</span> <span class=o >=</span> <span class=n >better</span><span class=o >.</span><span class=n >drop</span><span class=p >([</span><span class=s2 >"t_in_group"</span><span class=p >],</span> <span class=n >axis</span><span class=o >=</span><span class=s2 >"columns"</span><span class=p >)</span>

    <span class=c1 ># Make sure right length and values!</span>
    <span class=k >assert</span> <span class=nb >len</span><span class=p >(</span><span class=n >result_of_fit</span><span class=p >)</span> <span class=o >==</span> <span class=nb >len</span><span class=p >(</span><span class=n >better</span><span class=p >)</span>
    <span class=k >assert</span> <span class=n >better</span><span class=o >.</span><span class=n >loc</span><span class=p >[</span><span class=n >better</span><span class=p >[</span><span class=n >t</span><span class=p >]</span> <span class=o >==</span> <span class=mi >0</span><span class=p >,</span> <span class=s2 >"weights"</span><span class=p >]</span><span class=o >.</span><span class=n >sum</span><span class=p >()</span> <span class=o >==</span> <span class=n >num_control_obs</span>

    <span class=k >return</span> <span class=n >better</span>
<br/></pre></div> </div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[31]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >matched_data</span> <span class=o >=</span> <span class=n >get_dataframe</span><span class=p >(</span><span class=n >model</span><span class=p >,</span> <span class=n >result</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[32]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >matched_data</span><span class=o >.</span><span class=n >head</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[32]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border=1  class=dataframe > <thead> <tr style="text-align: right;"> <th> <th>annual_earnings <th>female <th>simplified_race <th>has_college <th>county <th>class94 <th>discretized_age <th>match_group <th>match_group_size <th>weights <tr> <th>0 <td>42900.0 <td>1 <td>0.0 <td>0 <td>10 <td>3 <td>5 <td>59.0 <td>5.0 <td>0.930000 <tr> <th>1 <td>31200.0 <td>0 <td>2.0 <td>0 <td>31 <td>3 <td>3 <td>411.0 <td>108.0 <td>0.070189 <tr> <th>2 <td>20020.0 <td>0 <td>0.0 <td>1 <td>8 <td>3 <td>6 <td>52.0 <td>3.0 <td>1.000000 <tr> <th>3 <td>22859.2 <td>0 <td>0.0 <td>0 <td>44 <td>1 <td>4 <td>424.0 <td>28.0 <td>1.240000 <tr> <th>4 <td>73860.8 <td>0 <td>0.0 <td>1 <td>24 <td>3 <td>3 <td>106.0 <td>7.0 <td>1.000000 </table> </div></div> </div> </section> </section> <section id=Check-Your-Matches-and-Analyze > <h2 id=Check-Your-Matches-and-Analyze >Check Your Matches and Analyze<a class=headerlink  href="#Check-Your-Matches-and-Analyze" title="Permalink to this heading">¶</a></h2> <section id=Exercise-12 > <h3 id=Exercise-12 >Exercise 12<a class=headerlink  href="#Exercise-12" title="Permalink to this heading">¶</a></h3> <p>We previously tested balance on <code class="docutils literal notranslate"><span class=pre >simplified_race</span></code>, and by county. Check those again. Are there still statistically significant differences in college education by <code class="docutils literal notranslate"><span class=pre >simplified_race</span></code>?</p> <p>Note that when you test for this, you’ll need to take into account the <code class="docutils literal notranslate"><span class=pre >weights</span></code> column you got back from <code class="docutils literal notranslate"><span class=pre >get_dataframe</span></code>. What DAME does is not actually the 1-to-1 matching described in our readings – instead, however many observations that exact match it finds it puts in the same “group”. (These groups are identified in the dataframe you got from <code class="docutils literal notranslate"><span class=pre >get_dataframe</span></code> by the column <code class="docutils literal notranslate"><span class=pre >match_group</span></code>, and the size of each group is in <code class="docutils literal notranslate"><span class=pre >match_group_size</span></code>.)</p> <p>So to analyze the data, you need to use the <code class="docutils literal notranslate"><span class=pre >wls</span></code> (weighted least squares) function in <code class="docutils literal notranslate"><span class=pre >statsmodels</span></code>. For example, if your data is called <code class="docutils literal notranslate"><span class=pre >matched_data</span></code>, you might run:</p> <div class="highlight-python notranslate"><div class=highlight ><pre><span></span><span class=n >smf</span><span class=o >.</span><span class=n >wls</span><span class=p >(</span>
    <span class=s2 >"has_college ~ C(simplified_race)"</span><span class=p >,</span> <span class=n >matched_data</span><span class=p >,</span> <span class=n >weights</span><span class=o >=</span><span class=n >matched_data</span><span class=p >[</span><span class=s2 >"weights"</span><span class=p >]</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
</pre></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[33]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >statsmodels.formula.api</span> <span class=k >as</span> <span class=nn >smf</span>

<span class=n >smf</span><span class=o >.</span><span class=n >wls</span><span class=p >(</span>
    <span class=s2 >"has_college ~ C(simplified_race)"</span><span class=p >,</span> <span class=n >matched_data</span><span class=p >,</span> <span class=n >weights</span><span class=o >=</span><span class=n >matched_data</span><span class=p >[</span><span class=s2 >"weights"</span><span class=p >]</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[33]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>WLS Regression Results</caption> <tr> <th>Dep. Variable: <td>has_college <th> R-squared: <td> 0.000 <tr> <th>Model: <td>WLS <th> Adj. R-squared: <td> -0.001 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td>1.134e-12 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td> 1.00 <tr> <th>Time: <td>13:59:41 <th> Log-Likelihood: <td> -3736.0 <tr> <th>No. Observations: <td> 5310 <th> AIC: <td> 7480. <tr> <th>Df Residuals: <td> 5306 <th> BIC: <td> 7506. <tr> <th>Df Model: <td> 3 <th> <td> <tr> <th>Covariance Type: <td>nonrobust <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 0.2119 <td> 0.007 <td> 31.608 <td> 0.000 <td> 0.199 <td> 0.225 <tr> <th>C(simplified_race)[T.1.0] <td> 3.469e-17 <td> 0.018 <td> 1.92e-15 <td> 1.000 <td> -0.036 <td> 0.036 <tr> <th>C(simplified_race)[T.2.0] <td>-5.378e-17 <td> 0.019 <td>-2.86e-15 <td> 1.000 <td> -0.037 <td> 0.037 <tr> <th>C(simplified_race)[T.3.0] <td> 1.18e-16 <td> 0.020 <td> 5.83e-15 <td> 1.000 <td> -0.040 <td> 0.040 </table> <table> <tr> <th>Omnibus: <td>860.389 <th> Durbin-Watson: <td> 2.000 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>1353.227 <tr> <th>Skew: <td> 1.234 <th> Prob(JB): <td>1.41e-294 <tr> <th>Kurtosis: <td> 2.851 <th> Cond. No. <td> 3.95 </table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div> </div> </section> <section id=Exercise-13 > <h3 id=Exercise-13 >Exercise 13<a class=headerlink  href="#Exercise-13" title="Permalink to this heading">¶</a></h3> <p>Now use a weighted least squares regression on your matched data to regress annual earnings on <em>just</em> having a college eduction. What is the apparent effect of a BA? How does that compare to our initial estimate using the raw CPS data (before matching)?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[34]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >smf</span><span class=o >.</span><span class=n >wls</span><span class=p >(</span>
    <span class=s2 >"annual_earnings ~ has_college"</span><span class=p >,</span> <span class=n >matched_data</span><span class=p >,</span> <span class=n >weights</span><span class=o >=</span><span class=n >matched_data</span><span class=p >[</span><span class=s2 >"weights"</span><span class=p >]</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[34]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>WLS Regression Results</caption> <tr> <th>Dep. Variable: <td>annual_earnings <th> R-squared: <td> 0.058 <tr> <th>Model: <td>WLS <th> Adj. R-squared: <td> 0.057 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 324.1 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>2.19e-70 <tr> <th>Time: <td>13:59:41 <th> Log-Likelihood: <td> -61753. <tr> <th>No. Observations: <td> 5310 <th> AIC: <td>1.235e+05 <tr> <th>Df Residuals: <td> 5308 <th> BIC: <td>1.235e+05 <tr> <th>Df Model: <td> 1 <th> <td> <tr> <th>Covariance Type: <td>nonrobust <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 3.909e+04 <td> 351.293 <td> 111.287 <td> 0.000 <td> 3.84e+04 <td> 3.98e+04 <tr> <th>has_college <td> 1.374e+04 <td> 763.203 <td> 18.003 <td> 0.000 <td> 1.22e+04 <td> 1.52e+04 </table> <table> <tr> <th>Omnibus: <td>2934.035 <th> Durbin-Watson: <td> 2.006 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>33100.529 <tr> <th>Skew: <td> 2.424 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td>14.230 <th> Cond. No. <td> 2.58 </table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[35]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># dame_flame.utils.post_processing.ATE(matching_object=model)</span>
</pre></div> </div> </div> </section> <section id=Exercise-14 > <h3 id=Exercise-14 >Exercise 14<a class=headerlink  href="#Exercise-14" title="Permalink to this heading">¶</a></h3> <p>Now include our other matching variables as controls (e.g. all the coefficients you gave to DAME to use). Does the coefficient change?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[36]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >smf</span><span class=o >.</span><span class=n >wls</span><span class=p >(</span>
    <span class=s2 >"annual_earnings ~ has_college + C(simplified_race)"</span>
    <span class=s2 >" + C(discretized_age) + female + C(county)"</span><span class=p >,</span>
    <span class=n >matched_data</span><span class=p >,</span>
    <span class=n >weights</span><span class=o >=</span><span class=n >matched_data</span><span class=p >[</span><span class=s2 >"weights"</span><span class=p >],</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[36]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>WLS Regression Results</caption> <tr> <th>Dep. Variable: <td>annual_earnings <th> R-squared: <td> 0.238 <tr> <th>Model: <td>WLS <th> Adj. R-squared: <td> 0.188 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 4.786 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>1.62e-132 <tr> <th>Time: <td>13:59:42 <th> Log-Likelihood: <td> -61189. <tr> <th>No. Observations: <td> 5310 <th> AIC: <td>1.230e+05 <tr> <th>Df Residuals: <td> 4984 <th> BIC: <td>1.252e+05 <tr> <th>Df Model: <td> 325 <th> <td> <tr> <th>Covariance Type: <td>nonrobust <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 4.761e+04 <td> 2429.505 <td> 19.595 <td> 0.000 <td> 4.28e+04 <td> 5.24e+04 <tr> <th>C(simplified_race)[T.1.0] <td>-8344.9150 <td> 1067.331 <td> -7.818 <td> 0.000 <td>-1.04e+04 <td>-6252.476 <tr> <th>C(simplified_race)[T.2.0] <td>-6753.9175 <td> 1140.523 <td> -5.922 <td> 0.000 <td>-8989.844 <td>-4517.991 <tr> <th>C(simplified_race)[T.3.0] <td>-3220.6308 <td> 1202.997 <td> -2.677 <td> 0.007 <td>-5579.035 <td> -862.227 <tr> <th>C(discretized_age)[T.3] <td> 8584.0505 <td> 868.037 <td> 9.889 <td> 0.000 <td> 6882.316 <td> 1.03e+04 <tr> <th>C(discretized_age)[T.4] <td> 1.251e+04 <td> 923.078 <td> 13.558 <td> 0.000 <td> 1.07e+04 <td> 1.43e+04 <tr> <th>C(discretized_age)[T.5] <td> 1.266e+04 <td> 964.214 <td> 13.131 <td> 0.000 <td> 1.08e+04 <td> 1.46e+04 <tr> <th>C(discretized_age)[T.6] <td> 9235.0616 <td> 1189.062 <td> 7.767 <td> 0.000 <td> 6903.976 <td> 1.16e+04 <tr> <th>C(discretized_age)[T.7] <td> 1.347e+04 <td> 2975.342 <td> 4.528 <td> 0.000 <td> 7639.580 <td> 1.93e+04 <tr> <th>C(county)[T.1] <td>-1.114e+04 <td> 3231.653 <td> -3.446 <td> 0.001 <td>-1.75e+04 <td>-4799.550 <tr> <th>C(county)[T.2] <td>-1.279e+04 <td> 3245.734 <td> -3.942 <td> 0.000 <td>-1.92e+04 <td>-6430.115 <tr> <th>C(county)[T.3] <td>-9142.9921 <td> 1.19e+04 <td> -0.771 <td> 0.441 <td>-3.24e+04 <td> 1.41e+04 <tr> <th>C(county)[T.4] <td>-6471.4363 <td> 2990.234 <td> -2.164 <td> 0.030 <td>-1.23e+04 <td> -609.261 <tr> <th>C(county)[T.5] <td>-6378.3577 <td> 4178.131 <td> -1.527 <td> 0.127 <td>-1.46e+04 <td> 1812.617 <tr> <th>C(county)[T.6] <td>-1.627e+04 <td> 1.04e+04 <td> -1.566 <td> 0.118 <td>-3.66e+04 <td> 4103.579 <tr> <th>C(county)[T.7] <td>-1.023e+04 <td> 3835.754 <td> -2.666 <td> 0.008 <td>-1.77e+04 <td>-2706.649 <tr> <th>C(county)[T.8] <td>-1.153e+04 <td> 3175.916 <td> -3.629 <td> 0.000 <td>-1.78e+04 <td>-5300.388 <tr> <th>C(county)[T.9] <td>-1.382e+04 <td> 5130.249 <td> -2.694 <td> 0.007 <td>-2.39e+04 <td>-3762.096 <tr> <th>C(county)[T.10] <td>-1.501e+04 <td> 3427.926 <td> -4.380 <td> 0.000 <td>-2.17e+04 <td>-8293.693 <tr> <th>C(county)[T.11] <td>-1.418e+04 <td> 3040.008 <td> -4.664 <td> 0.000 <td>-2.01e+04 <td>-8218.173 <tr> <th>C(county)[T.12] <td>-6849.3954 <td> 3121.285 <td> -2.194 <td> 0.028 <td> -1.3e+04 <td> -730.303 <tr> <th>C(county)[T.13] <td>-1.381e+04 <td> 3368.446 <td> -4.101 <td> 0.000 <td>-2.04e+04 <td>-7209.235 <tr> <th>C(county)[T.14] <td>-1.369e+04 <td> 3918.748 <td> -3.493 <td> 0.000 <td>-2.14e+04 <td>-6007.378 <tr> <th>C(county)[T.15] <td>-9190.4689 <td> 4799.618 <td> -1.915 <td> 0.056 <td>-1.86e+04 <td> 218.895 <tr> <th>C(county)[T.16] <td>-1.061e+04 <td> 3616.372 <td> -2.935 <td> 0.003 <td>-1.77e+04 <td>-3523.982 <tr> <th>C(county)[T.17] <td>-1.601e+04 <td> 7731.556 <td> -2.070 <td> 0.038 <td>-3.12e+04 <td> -848.909 <tr> <th>C(county)[T.18] <td>-1788.7046 <td> 4787.690 <td> -0.374 <td> 0.709 <td>-1.12e+04 <td> 7597.275 <tr> <th>C(county)[T.19] <td>-1.684e+04 <td> 6555.900 <td> -2.569 <td> 0.010 <td>-2.97e+04 <td>-3989.067 <tr> <th>C(county)[T.20] <td> -1.4e+04 <td> 4328.098 <td> -3.235 <td> 0.001 <td>-2.25e+04 <td>-5515.772 <tr> <th>C(county)[T.21] <td>-6184.3776 <td> 3595.547 <td> -1.720 <td> 0.085 <td>-1.32e+04 <td> 864.476 <tr> <th>C(county)[T.22] <td>-1.826e+04 <td> 3694.928 <td> -4.941 <td> 0.000 <td>-2.55e+04 <td> -1.1e+04 <tr> <th>C(county)[T.23] <td>-1.242e+04 <td> 3244.837 <td> -3.828 <td> 0.000 <td>-1.88e+04 <td>-6059.940 <tr> <th>C(county)[T.24] <td>-1.104e+04 <td> 3171.193 <td> -3.482 <td> 0.001 <td>-1.73e+04 <td>-4824.300 <tr> <th>C(county)[T.25] <td>-1.506e+04 <td> 3496.105 <td> -4.309 <td> 0.000 <td>-2.19e+04 <td>-8211.049 <tr> <th>C(county)[T.26] <td>-1.391e+04 <td> 3137.745 <td> -4.432 <td> 0.000 <td>-2.01e+04 <td>-7755.819 <tr> <th>C(county)[T.27] <td>-1.337e+04 <td> 3345.523 <td> -3.997 <td> 0.000 <td>-1.99e+04 <td>-6814.638 <tr> <th>C(county)[T.28] <td>-1.297e+04 <td> 5671.204 <td> -2.287 <td> 0.022 <td>-2.41e+04 <td>-1853.870 <tr> <th>C(county)[T.29] <td>-4845.0790 <td> 5203.125 <td> -0.931 <td> 0.352 <td> -1.5e+04 <td> 5355.335 <tr> <th>C(county)[T.30] <td>-2248.8602 <td> 5067.398 <td> -0.444 <td> 0.657 <td>-1.22e+04 <td> 7685.469 <tr> <th>C(county)[T.31] <td>-1.155e+04 <td> 4710.979 <td> -2.452 <td> 0.014 <td>-2.08e+04 <td>-2313.897 <tr> <th>C(county)[T.32] <td>-7114.5598 <td> 3632.908 <td> -1.958 <td> 0.050 <td>-1.42e+04 <td> 7.538 <tr> <th>C(county)[T.33] <td>-1.272e+04 <td> 3067.035 <td> -4.149 <td> 0.000 <td>-1.87e+04 <td>-6711.354 <tr> <th>C(county)[T.34] <td> -1.32e+04 <td> 3443.339 <td> -3.833 <td> 0.000 <td>-1.99e+04 <td>-6447.428 <tr> <th>C(county)[T.35] <td>-9324.2429 <td> 3384.603 <td> -2.755 <td> 0.006 <td> -1.6e+04 <td>-2688.932 <tr> <th>C(county)[T.36] <td>-1.505e+04 <td> 3658.198 <td> -4.115 <td> 0.000 <td>-2.22e+04 <td>-7881.001 <tr> <th>C(county)[T.37] <td>-1.023e+04 <td> 3762.247 <td> -2.720 <td> 0.007 <td>-1.76e+04 <td>-2856.766 <tr> <th>C(county)[T.38] <td>-1.308e+04 <td> 3310.408 <td> -3.951 <td> 0.000 <td>-1.96e+04 <td>-6590.153 <tr> <th>C(county)[T.39] <td>-1.177e+04 <td> 3252.230 <td> -3.618 <td> 0.000 <td>-1.81e+04 <td>-5391.513 <tr> <th>C(county)[T.40] <td>-1.516e+04 <td> 3677.299 <td> -4.123 <td> 0.000 <td>-2.24e+04 <td>-7954.028 <tr> <th>C(county)[T.41] <td>-9224.6049 <td> 2690.524 <td> -3.429 <td> 0.001 <td>-1.45e+04 <td>-3949.994 <tr> <th>C(county)[T.42] <td>-1.365e+04 <td> 3460.095 <td> -3.944 <td> 0.000 <td>-2.04e+04 <td>-6864.991 <tr> <th>C(county)[T.43] <td>-1.165e+04 <td> 3698.161 <td> -3.151 <td> 0.002 <td>-1.89e+04 <td>-4404.402 <tr> <th>C(county)[T.44] <td> -1.07e+04 <td> 2961.782 <td> -3.611 <td> 0.000 <td>-1.65e+04 <td>-4889.799 <tr> <th>C(county)[T.45] <td>-7052.4496 <td> 3127.876 <td> -2.255 <td> 0.024 <td>-1.32e+04 <td> -920.437 <tr> <th>C(county)[T.46] <td>-9064.0230 <td> 3380.497 <td> -2.681 <td> 0.007 <td>-1.57e+04 <td>-2436.761 <tr> <th>C(county)[T.47] <td>-1.681e+04 <td> 3013.844 <td> -5.579 <td> 0.000 <td>-2.27e+04 <td>-1.09e+04 <tr> <th>C(county)[T.48] <td>-8897.8731 <td> 3296.249 <td> -2.699 <td> 0.007 <td>-1.54e+04 <td>-2435.774 <tr> <th>C(county)[T.49] <td> 2.125e+04 <td> 7993.324 <td> 2.659 <td> 0.008 <td> 5580.256 <td> 3.69e+04 <tr> <th>C(county)[T.50] <td>-2.251e+04 <td> 1.13e+04 <td> -1.997 <td> 0.046 <td>-4.46e+04 <td> -409.459 <tr> <th>C(county)[T.51] <td>-5880.2544 <td> 3452.043 <td> -1.703 <td> 0.089 <td>-1.26e+04 <td> 887.270 <tr> <th>C(county)[T.52] <td>-1.006e+04 <td> 8297.064 <td> -1.213 <td> 0.225 <td>-2.63e+04 <td> 6201.302 <tr> <th>C(county)[T.53] <td>-7396.8710 <td> 1.97e+04 <td> -0.376 <td> 0.707 <td>-4.59e+04 <td> 3.12e+04 <tr> <th>C(county)[T.54] <td>-1.349e+04 <td> 8853.843 <td> -1.524 <td> 0.128 <td>-3.08e+04 <td> 3865.030 <tr> <th>C(county)[T.55] <td> 6016.8132 <td> 9691.581 <td> 0.621 <td> 0.535 <td> -1.3e+04 <td> 2.5e+04 <tr> <th>C(county)[T.56] <td>-7435.2407 <td> 7281.280 <td> -1.021 <td> 0.307 <td>-2.17e+04 <td> 6839.272 <tr> <th>C(county)[T.57] <td> 8434.9441 <td> 1.4e+04 <td> 0.604 <td> 0.546 <td>-1.89e+04 <td> 3.58e+04 <tr> <th>C(county)[T.58] <td>-5918.5652 <td> 5278.657 <td> -1.121 <td> 0.262 <td>-1.63e+04 <td> 4429.925 <tr> <th>C(county)[T.59] <td>-1.631e+04 <td> 9894.838 <td> -1.649 <td> 0.099 <td>-3.57e+04 <td> 3086.114 <tr> <th>C(county)[T.60] <td>-1.499e+04 <td> 6719.761 <td> -2.231 <td> 0.026 <td>-2.82e+04 <td>-1819.273 <tr> <th>C(county)[T.61] <td>-8015.9218 <td> 1.09e+04 <td> -0.732 <td> 0.464 <td>-2.95e+04 <td> 1.34e+04 <tr> <th>C(county)[T.62] <td> 1.171e+04 <td> 1.32e+04 <td> 0.884 <td> 0.377 <td>-1.43e+04 <td> 3.77e+04 <tr> <th>C(county)[T.63] <td>-1.124e+04 <td> 8626.461 <td> -1.303 <td> 0.193 <td>-2.82e+04 <td> 5671.473 <tr> <th>C(county)[T.64] <td> 1.57e+04 <td> 8596.970 <td> 1.826 <td> 0.068 <td>-1156.314 <td> 3.26e+04 <tr> <th>C(county)[T.65] <td>-1.964e+04 <td> 9254.939 <td> -2.122 <td> 0.034 <td>-3.78e+04 <td>-1498.590 <tr> <th>C(county)[T.66] <td>-2.286e+04 <td> 1.47e+04 <td> -1.550 <td> 0.121 <td>-5.18e+04 <td> 6046.864 <tr> <th>C(county)[T.67] <td>-1.286e+04 <td> 2.97e+04 <td> -0.434 <td> 0.664 <td> -7.1e+04 <td> 4.53e+04 <tr> <th>C(county)[T.68] <td> 265.8046 <td> 9594.437 <td> 0.028 <td> 0.978 <td>-1.85e+04 <td> 1.91e+04 <tr> <th>C(county)[T.69] <td>-1.382e+04 <td> 9042.247 <td> -1.528 <td> 0.127 <td>-3.15e+04 <td> 3909.886 <tr> <th>C(county)[T.70] <td>-2.086e+04 <td> 1.33e+04 <td> -1.567 <td> 0.117 <td> -4.7e+04 <td> 5231.063 <tr> <th>C(county)[T.71] <td>-1.914e+04 <td> 8999.435 <td> -2.127 <td> 0.033 <td>-3.68e+04 <td>-1501.949 <tr> <th>C(county)[T.72] <td> 1.203e+04 <td> 1.91e+04 <td> 0.630 <td> 0.528 <td>-2.54e+04 <td> 4.95e+04 <tr> <th>C(county)[T.73] <td>-4151.5319 <td> 5648.737 <td> -0.735 <td> 0.462 <td>-1.52e+04 <td> 6922.479 <tr> <th>C(county)[T.74] <td>-1.341e+04 <td> 7534.403 <td> -1.780 <td> 0.075 <td>-2.82e+04 <td> 1357.560 <tr> <th>C(county)[T.75] <td>-1.719e+04 <td> 3924.766 <td> -4.381 <td> 0.000 <td>-2.49e+04 <td>-9500.690 <tr> <th>C(county)[T.76] <td>-3.746e+04 <td> 2.62e+04 <td> -1.430 <td> 0.153 <td>-8.88e+04 <td> 1.39e+04 <tr> <th>C(county)[T.77] <td> 237.8624 <td> 6897.951 <td> 0.034 <td> 0.972 <td>-1.33e+04 <td> 1.38e+04 <tr> <th>C(county)[T.78] <td> 6770.8989 <td> 2.24e+04 <td> 0.302 <td> 0.763 <td>-3.72e+04 <td> 5.07e+04 <tr> <th>C(county)[T.79] <td> 4.146e+04 <td> 8462.736 <td> 4.899 <td> 0.000 <td> 2.49e+04 <td> 5.8e+04 <tr> <th>C(county)[T.80] <td>-1.741e+04 <td> 5589.953 <td> -3.115 <td> 0.002 <td>-2.84e+04 <td>-6454.909 <tr> <th>C(county)[T.81] <td>-1.143e+04 <td> 5721.800 <td> -1.998 <td> 0.046 <td>-2.27e+04 <td> -216.304 <tr> <th>C(county)[T.82] <td>-1.658e+04 <td> 1.61e+04 <td> -1.032 <td> 0.302 <td>-4.81e+04 <td> 1.49e+04 <tr> <th>C(county)[T.83] <td>-2.307e+04 <td> 1.25e+04 <td> -1.840 <td> 0.066 <td>-4.77e+04 <td> 1514.953 <tr> <th>C(county)[T.84] <td>-8999.9730 <td> 1.22e+04 <td> -0.740 <td> 0.459 <td>-3.28e+04 <td> 1.48e+04 <tr> <th>C(county)[T.85] <td> 3419.8384 <td> 9046.856 <td> 0.378 <td> 0.705 <td>-1.43e+04 <td> 2.12e+04 <tr> <th>C(county)[T.86] <td> 1.824e+04 <td> 1.43e+04 <td> 1.279 <td> 0.201 <td>-9720.390 <td> 4.62e+04 <tr> <th>C(county)[T.87] <td>-2.403e+04 <td> 1.09e+04 <td> -2.205 <td> 0.027 <td>-4.54e+04 <td>-2667.316 <tr> <th>C(county)[T.88] <td>-1.326e+04 <td> 1.74e+04 <td> -0.763 <td> 0.445 <td>-4.73e+04 <td> 2.08e+04 <tr> <th>C(county)[T.89] <td>-1.574e+04 <td> 8531.472 <td> -1.845 <td> 0.065 <td>-3.25e+04 <td> 985.816 <tr> <th>C(county)[T.90] <td>-8870.8793 <td> 4968.614 <td> -1.785 <td> 0.074 <td>-1.86e+04 <td> 869.791 <tr> <th>C(county)[T.91] <td> -1.04e+04 <td> 9791.880 <td> -1.062 <td> 0.288 <td>-2.96e+04 <td> 8799.744 <tr> <th>C(county)[T.92] <td>-1.687e+04 <td> 1.17e+04 <td> -1.441 <td> 0.150 <td>-3.98e+04 <td> 6076.622 <tr> <th>C(county)[T.93] <td>-4593.8182 <td> 9052.966 <td> -0.507 <td> 0.612 <td>-2.23e+04 <td> 1.32e+04 <tr> <th>C(county)[T.94] <td> -66.5470 <td> 9761.637 <td> -0.007 <td> 0.995 <td>-1.92e+04 <td> 1.91e+04 <tr> <th>C(county)[T.95] <td>-1.199e+04 <td> 5085.007 <td> -2.357 <td> 0.018 <td> -2.2e+04 <td>-2017.441 <tr> <th>C(county)[T.96] <td> -1.27e+04 <td> 1.03e+04 <td> -1.228 <td> 0.219 <td> -3.3e+04 <td> 7572.284 <tr> <th>C(county)[T.97] <td>-2.457e+04 <td> 9432.408 <td> -2.605 <td> 0.009 <td>-4.31e+04 <td>-6080.404 <tr> <th>C(county)[T.98] <td> 2197.3011 <td> 1.53e+04 <td> 0.144 <td> 0.886 <td>-2.78e+04 <td> 3.22e+04 <tr> <th>C(county)[T.99] <td>-9289.2093 <td> 3098.282 <td> -2.998 <td> 0.003 <td>-1.54e+04 <td>-3215.213 <tr> <th>C(county)[T.100] <td> 1.121e+04 <td> 7876.656 <td> 1.423 <td> 0.155 <td>-4235.032 <td> 2.66e+04 <tr> <th>C(county)[T.101] <td>-1.684e+04 <td> 9598.189 <td> -1.754 <td> 0.079 <td>-3.57e+04 <td> 1979.720 <tr> <th>C(county)[T.102] <td>-2597.8743 <td> 1.35e+04 <td> -0.192 <td> 0.847 <td>-2.91e+04 <td> 2.39e+04 <tr> <th>C(county)[T.103] <td>-1.014e+04 <td> 9066.754 <td> -1.118 <td> 0.264 <td>-2.79e+04 <td> 7638.542 <tr> <th>C(county)[T.104] <td> -252.2631 <td> 1.16e+04 <td> -0.022 <td> 0.983 <td> -2.3e+04 <td> 2.25e+04 <tr> <th>C(county)[T.105] <td>-1.145e+04 <td> 1.3e+04 <td> -0.880 <td> 0.379 <td> -3.7e+04 <td> 1.41e+04 <tr> <th>C(county)[T.106] <td>-3.539e+04 <td> 3.35e+04 <td> -1.055 <td> 0.291 <td>-1.01e+05 <td> 3.03e+04 <tr> <th>C(county)[T.107] <td>-3.364e+04 <td> 1.71e+04 <td> -1.962 <td> 0.050 <td>-6.72e+04 <td> -29.720 <tr> <th>C(county)[T.109] <td>-4795.8027 <td> 8034.001 <td> -0.597 <td> 0.551 <td>-2.05e+04 <td> 1.1e+04 <tr> <th>C(county)[T.110] <td>-8716.5745 <td> 1.06e+04 <td> -0.822 <td> 0.411 <td>-2.95e+04 <td> 1.21e+04 <tr> <th>C(county)[T.111] <td>-1.946e+04 <td> 2.19e+04 <td> -0.889 <td> 0.374 <td>-6.24e+04 <td> 2.35e+04 <tr> <th>C(county)[T.112] <td>-7351.2007 <td> 1.42e+04 <td> -0.516 <td> 0.606 <td>-3.53e+04 <td> 2.06e+04 <tr> <th>C(county)[T.113] <td>-2.293e+04 <td> 2.6e+04 <td> -0.882 <td> 0.378 <td>-7.39e+04 <td> 2.8e+04 <tr> <th>C(county)[T.114] <td>-1.908e+04 <td> 1.61e+04 <td> -1.185 <td> 0.236 <td>-5.07e+04 <td> 1.25e+04 <tr> <th>C(county)[T.115] <td>-2798.0105 <td> 1e+04 <td> -0.280 <td> 0.780 <td>-2.24e+04 <td> 1.68e+04 <tr> <th>C(county)[T.116] <td>-8785.2988 <td> 1.35e+04 <td> -0.650 <td> 0.516 <td>-3.53e+04 <td> 1.77e+04 <tr> <th>C(county)[T.117] <td>-2.473e+04 <td> 4.28e+04 <td> -0.577 <td> 0.564 <td>-1.09e+05 <td> 5.92e+04 <tr> <th>C(county)[T.118] <td>-1.698e+04 <td> 1.1e+04 <td> -1.538 <td> 0.124 <td>-3.86e+04 <td> 4669.861 <tr> <th>C(county)[T.120] <td>-1.704e+04 <td> 1.32e+04 <td> -1.287 <td> 0.198 <td> -4.3e+04 <td> 8908.447 <tr> <th>C(county)[T.121] <td>-2.767e+04 <td> 1.32e+04 <td> -2.093 <td> 0.036 <td>-5.36e+04 <td>-1747.007 <tr> <th>C(county)[T.123] <td>-1.291e+04 <td> 5091.347 <td> -2.536 <td> 0.011 <td>-2.29e+04 <td>-2931.559 <tr> <th>C(county)[T.124] <td>-3.209e+04 <td> 1e+04 <td> -3.197 <td> 0.001 <td>-5.18e+04 <td>-1.24e+04 <tr> <th>C(county)[T.125] <td>-1.795e+04 <td> 1.25e+04 <td> -1.440 <td> 0.150 <td>-4.24e+04 <td> 6490.095 <tr> <th>C(county)[T.126] <td>-6948.1460 <td> 9793.690 <td> -0.709 <td> 0.478 <td>-2.61e+04 <td> 1.23e+04 <tr> <th>C(county)[T.127] <td>-4111.7736 <td> 9598.180 <td> -0.428 <td> 0.668 <td>-2.29e+04 <td> 1.47e+04 <tr> <th>C(county)[T.128] <td>-1.407e+04 <td> 3.35e+04 <td> -0.420 <td> 0.675 <td>-7.98e+04 <td> 5.17e+04 <tr> <th>C(county)[T.129] <td>-1.338e+04 <td> 1.22e+04 <td> -1.094 <td> 0.274 <td>-3.73e+04 <td> 1.06e+04 <tr> <th>C(county)[T.130] <td>-2.958e+04 <td> 1.24e+04 <td> -2.379 <td> 0.017 <td> -5.4e+04 <td>-5205.688 <tr> <th>C(county)[T.131] <td>-9462.1890 <td> 2.13e+04 <td> -0.445 <td> 0.656 <td>-5.11e+04 <td> 3.22e+04 <tr> <th>C(county)[T.132] <td>-7889.2394 <td> 5638.330 <td> -1.399 <td> 0.162 <td>-1.89e+04 <td> 3164.369 <tr> <th>C(county)[T.133] <td> 2175.4884 <td> 1.51e+04 <td> 0.144 <td> 0.886 <td>-2.75e+04 <td> 3.18e+04 <tr> <th>C(county)[T.134] <td> 5.467e+04 <td> 1.8e+04 <td> 3.045 <td> 0.002 <td> 1.95e+04 <td> 8.99e+04 <tr> <th>C(county)[T.135] <td>-2.083e+04 <td> 1.38e+04 <td> -1.509 <td> 0.131 <td>-4.79e+04 <td> 6228.141 <tr> <th>C(county)[T.136] <td>-4420.8608 <td> 5997.620 <td> -0.737 <td> 0.461 <td>-1.62e+04 <td> 7337.113 <tr> <th>C(county)[T.137] <td>-4087.2387 <td> 8100.626 <td> -0.505 <td> 0.614 <td> -2e+04 <td> 1.18e+04 <tr> <th>C(county)[T.138] <td>-7939.1789 <td> 8029.739 <td> -0.989 <td> 0.323 <td>-2.37e+04 <td> 7802.643 <tr> <th>C(county)[T.139] <td> -692.3178 <td> 1.02e+04 <td> -0.068 <td> 0.946 <td>-2.08e+04 <td> 1.94e+04 <tr> <th>C(county)[T.140] <td>-1.651e+04 <td> 1.37e+04 <td> -1.202 <td> 0.229 <td>-4.34e+04 <td> 1.04e+04 <tr> <th>C(county)[T.141] <td>-8251.4595 <td> 1.22e+04 <td> -0.676 <td> 0.499 <td>-3.22e+04 <td> 1.57e+04 <tr> <th>C(county)[T.142] <td>-1373.8309 <td> 2.13e+04 <td> -0.065 <td> 0.948 <td> -4.3e+04 <td> 4.03e+04 <tr> <th>C(county)[T.143] <td>-5545.8845 <td> 5862.828 <td> -0.946 <td> 0.344 <td> -1.7e+04 <td> 5947.838 <tr> <th>C(county)[T.144] <td>-4.741e+04 <td> 2.12e+04 <td> -2.232 <td> 0.026 <td>-8.91e+04 <td>-5771.921 <tr> <th>C(county)[T.145] <td>-9556.0440 <td> 3.47e+04 <td> -0.276 <td> 0.783 <td>-7.75e+04 <td> 5.84e+04 <tr> <th>C(county)[T.146] <td>-1.903e+04 <td> 1.59e+04 <td> -1.196 <td> 0.232 <td>-5.02e+04 <td> 1.22e+04 <tr> <th>C(county)[T.147] <td> -2.8e+04 <td> 1.52e+04 <td> -1.848 <td> 0.065 <td>-5.77e+04 <td> 1707.239 <tr> <th>C(county)[T.148] <td>-2.012e+04 <td> 1.76e+04 <td> -1.146 <td> 0.252 <td>-5.45e+04 <td> 1.43e+04 <tr> <th>C(county)[T.149] <td>-1.012e+04 <td> 4824.670 <td> -2.097 <td> 0.036 <td>-1.96e+04 <td> -657.758 <tr> <th>C(county)[T.150] <td>-2.052e+04 <td> 3.35e+04 <td> -0.612 <td> 0.541 <td>-8.63e+04 <td> 4.52e+04 <tr> <th>C(county)[T.151] <td>-2.235e+04 <td> 1.13e+04 <td> -1.974 <td> 0.048 <td>-4.45e+04 <td> -157.867 <tr> <th>C(county)[T.152] <td>-1.249e+04 <td> 7332.914 <td> -1.703 <td> 0.089 <td>-2.69e+04 <td> 1887.273 <tr> <th>C(county)[T.153] <td>-1.074e+04 <td> 2.99e+04 <td> -0.360 <td> 0.719 <td>-6.93e+04 <td> 4.78e+04 <tr> <th>C(county)[T.155] <td>-1.174e+04 <td> 1.32e+04 <td> -0.892 <td> 0.373 <td>-3.75e+04 <td> 1.41e+04 <tr> <th>C(county)[T.157] <td>-2.379e+04 <td> 1.34e+04 <td> -1.777 <td> 0.076 <td> -5e+04 <td> 2454.505 <tr> <th>C(county)[T.158] <td> -3.57e+04 <td> 1.24e+04 <td> -2.878 <td> 0.004 <td> -6e+04 <td>-1.14e+04 <tr> <th>C(county)[T.159] <td>-3961.2072 <td> 2.67e+04 <td> -0.149 <td> 0.882 <td>-5.62e+04 <td> 4.83e+04 <tr> <th>C(county)[T.160] <td>-1.811e+04 <td> 8356.451 <td> -2.167 <td> 0.030 <td>-3.45e+04 <td>-1729.232 <tr> <th>C(county)[T.161] <td> 6091.1910 <td> 8574.294 <td> 0.710 <td> 0.477 <td>-1.07e+04 <td> 2.29e+04 <tr> <th>C(county)[T.162] <td> 9087.0830 <td> 1.55e+04 <td> 0.586 <td> 0.558 <td>-2.13e+04 <td> 3.95e+04 <tr> <th>C(county)[T.163] <td>-2.133e+04 <td> 2.02e+04 <td> -1.054 <td> 0.292 <td> -6.1e+04 <td> 1.84e+04 <tr> <th>C(county)[T.164] <td>-2.283e+04 <td> 1.51e+04 <td> -1.511 <td> 0.131 <td>-5.24e+04 <td> 6795.581 <tr> <th>C(county)[T.165] <td> -2.21e+04 <td> 2.13e+04 <td> -1.037 <td> 0.300 <td>-6.39e+04 <td> 1.97e+04 <tr> <th>C(county)[T.166] <td>-1.551e+04 <td> 9441.670 <td> -1.642 <td> 0.101 <td> -3.4e+04 <td> 3002.990 <tr> <th>C(county)[T.167] <td>-3.947e+04 <td> 3.24e+04 <td> -1.218 <td> 0.223 <td>-1.03e+05 <td> 2.41e+04 <tr> <th>C(county)[T.168] <td> 1.007e+04 <td> 7103.076 <td> 1.417 <td> 0.156 <td>-3857.374 <td> 2.4e+04 <tr> <th>C(county)[T.169] <td> 1.283e+04 <td> 1.14e+04 <td> 1.121 <td> 0.262 <td>-9600.934 <td> 3.53e+04 <tr> <th>C(county)[T.170] <td>-1.615e+04 <td> 1.4e+04 <td> -1.150 <td> 0.250 <td>-4.37e+04 <td> 1.14e+04 <tr> <th>C(county)[T.171] <td> 2.365e+04 <td> 7177.844 <td> 3.295 <td> 0.001 <td> 9576.024 <td> 3.77e+04 <tr> <th>C(county)[T.172] <td>-3.626e+04 <td> 3.24e+04 <td> -1.119 <td> 0.263 <td>-9.98e+04 <td> 2.73e+04 <tr> <th>C(county)[T.173] <td>-2.629e+04 <td> 2.38e+04 <td> -1.106 <td> 0.269 <td>-7.29e+04 <td> 2.03e+04 <tr> <th>C(county)[T.174] <td>-2.314e+04 <td> 1.59e+04 <td> -1.458 <td> 0.145 <td>-5.43e+04 <td> 7983.357 <tr> <th>C(county)[T.176] <td>-8331.5679 <td> 1.76e+04 <td> -0.472 <td> 0.637 <td>-4.29e+04 <td> 2.62e+04 <tr> <th>C(county)[T.177] <td>-7787.9729 <td> 6943.898 <td> -1.122 <td> 0.262 <td>-2.14e+04 <td> 5825.123 <tr> <th>C(county)[T.178] <td>-8426.9047 <td> 9527.061 <td> -0.885 <td> 0.376 <td>-2.71e+04 <td> 1.03e+04 <tr> <th>C(county)[T.179] <td> 5061.4958 <td> 9108.387 <td> 0.556 <td> 0.578 <td>-1.28e+04 <td> 2.29e+04 <tr> <th>C(county)[T.180] <td>-9156.0300 <td> 7253.999 <td> -1.262 <td> 0.207 <td>-2.34e+04 <td> 5065.000 <tr> <th>C(county)[T.181] <td>-6042.8525 <td> 1.16e+04 <td> -0.522 <td> 0.602 <td>-2.87e+04 <td> 1.67e+04 <tr> <th>C(county)[T.182] <td> -1.6e+04 <td> 8180.157 <td> -1.956 <td> 0.051 <td> -3.2e+04 <td> 40.230 <tr> <th>C(county)[T.183] <td> 1688.4654 <td> 4051.315 <td> 0.417 <td> 0.677 <td>-6253.894 <td> 9630.825 <tr> <th>C(county)[T.184] <td>-1.566e+04 <td> 3739.789 <td> -4.189 <td> 0.000 <td> -2.3e+04 <td>-8333.281 <tr> <th>C(county)[T.185] <td>-1.158e+04 <td> 1.5e+04 <td> -0.769 <td> 0.442 <td>-4.11e+04 <td> 1.79e+04 <tr> <th>C(county)[T.186] <td>-1.279e+04 <td> 1.07e+04 <td> -1.198 <td> 0.231 <td>-3.37e+04 <td> 8134.088 <tr> <th>C(county)[T.187] <td>-6652.3137 <td> 8781.097 <td> -0.758 <td> 0.449 <td>-2.39e+04 <td> 1.06e+04 <tr> <th>C(county)[T.188] <td>-1.083e+04 <td> 3548.268 <td> -3.053 <td> 0.002 <td>-1.78e+04 <td>-3878.254 <tr> <th>C(county)[T.189] <td>-2.122e+04 <td> 5407.161 <td> -3.925 <td> 0.000 <td>-3.18e+04 <td>-1.06e+04 <tr> <th>C(county)[T.190] <td>-2.661e+04 <td> 1.48e+04 <td> -1.803 <td> 0.071 <td>-5.55e+04 <td> 2321.109 <tr> <th>C(county)[T.191] <td>-3036.3270 <td> 1.92e+04 <td> -0.158 <td> 0.874 <td>-4.06e+04 <td> 3.45e+04 <tr> <th>C(county)[T.192] <td> 6940.9690 <td> 9281.647 <td> 0.748 <td> 0.455 <td>-1.13e+04 <td> 2.51e+04 <tr> <th>C(county)[T.193] <td>-9444.8116 <td> 1.05e+04 <td> -0.902 <td> 0.367 <td> -3e+04 <td> 1.11e+04 <tr> <th>C(county)[T.194] <td> 2498.3312 <td> 1.35e+04 <td> 0.185 <td> 0.853 <td> -2.4e+04 <td> 2.9e+04 <tr> <th>C(county)[T.195] <td> -2.03e+04 <td> 9595.165 <td> -2.116 <td> 0.034 <td>-3.91e+04 <td>-1493.798 <tr> <th>C(county)[T.196] <td>-2753.6229 <td> 6585.461 <td> -0.418 <td> 0.676 <td>-1.57e+04 <td> 1.02e+04 <tr> <th>C(county)[T.197] <td> 1.33e+04 <td> 5757.604 <td> 2.311 <td> 0.021 <td> 2015.983 <td> 2.46e+04 <tr> <th>C(county)[T.198] <td> 7328.9890 <td> 7484.437 <td> 0.979 <td> 0.328 <td>-7343.801 <td> 2.2e+04 <tr> <th>C(county)[T.199] <td>-2.136e+04 <td> 8594.063 <td> -2.485 <td> 0.013 <td>-3.82e+04 <td>-4510.853 <tr> <th>C(county)[T.200] <td>-7508.9207 <td> 3016.843 <td> -2.489 <td> 0.013 <td>-1.34e+04 <td>-1594.581 <tr> <th>C(county)[T.201] <td>-2.737e+04 <td> 1.51e+04 <td> -1.811 <td> 0.070 <td> -5.7e+04 <td> 2251.151 <tr> <th>C(county)[T.202] <td>-1237.8204 <td> 2.25e+04 <td> -0.055 <td> 0.956 <td>-4.54e+04 <td> 4.29e+04 <tr> <th>C(county)[T.203] <td>-6666.3212 <td> 1.53e+04 <td> -0.435 <td> 0.664 <td>-3.67e+04 <td> 2.34e+04 <tr> <th>C(county)[T.204] <td>-1.464e+04 <td> 9850.437 <td> -1.486 <td> 0.137 <td>-3.39e+04 <td> 4674.099 <tr> <th>C(county)[T.205] <td>-1.706e+04 <td> 6442.944 <td> -2.648 <td> 0.008 <td>-2.97e+04 <td>-4427.328 <tr> <th>C(county)[T.206] <td>-3.733e+04 <td> 1.51e+04 <td> -2.465 <td> 0.014 <td> -6.7e+04 <td>-7640.473 <tr> <th>C(county)[T.209] <td> 6087.6907 <td> 1.35e+04 <td> 0.452 <td> 0.651 <td>-2.03e+04 <td> 3.25e+04 <tr> <th>C(county)[T.210] <td>-2.578e+04 <td> 2.65e+04 <td> -0.973 <td> 0.330 <td>-7.77e+04 <td> 2.61e+04 <tr> <th>C(county)[T.211] <td>-1093.8388 <td> 7382.081 <td> -0.148 <td> 0.882 <td>-1.56e+04 <td> 1.34e+04 <tr> <th>C(county)[T.213] <td>-2.153e+04 <td> 2.35e+04 <td> -0.916 <td> 0.360 <td>-6.76e+04 <td> 2.45e+04 <tr> <th>C(county)[T.214] <td>-2.351e+04 <td> 1.27e+04 <td> -1.858 <td> 0.063 <td>-4.83e+04 <td> 1299.507 <tr> <th>C(county)[T.215] <td> -1.66e+04 <td> 1.12e+04 <td> -1.488 <td> 0.137 <td>-3.85e+04 <td> 5271.613 <tr> <th>C(county)[T.216] <td>-9052.8944 <td> 5337.794 <td> -1.696 <td> 0.090 <td>-1.95e+04 <td> 1411.531 <tr> <th>C(county)[T.217] <td>-2.914e+04 <td> 9643.602 <td> -3.021 <td> 0.003 <td> -4.8e+04 <td>-1.02e+04 <tr> <th>C(county)[T.218] <td>-1.642e+04 <td> 1.66e+04 <td> -0.987 <td> 0.324 <td> -4.9e+04 <td> 1.62e+04 <tr> <th>C(county)[T.219] <td> -482.9429 <td> 8190.878 <td> -0.059 <td> 0.953 <td>-1.65e+04 <td> 1.56e+04 <tr> <th>C(county)[T.220] <td> 1.038e+04 <td> 1.11e+04 <td> 0.934 <td> 0.350 <td>-1.14e+04 <td> 3.22e+04 <tr> <th>C(county)[T.221] <td> 7271.3058 <td> 1.15e+04 <td> 0.634 <td> 0.526 <td>-1.52e+04 <td> 2.97e+04 <tr> <th>C(county)[T.222] <td>-1.622e+04 <td> 1.02e+04 <td> -1.588 <td> 0.112 <td>-3.63e+04 <td> 3804.653 <tr> <th>C(county)[T.223] <td>-1.878e+04 <td> 5199.813 <td> -3.612 <td> 0.000 <td> -2.9e+04 <td>-8586.505 <tr> <th>C(county)[T.224] <td>-9192.1466 <td> 1.45e+04 <td> -0.636 <td> 0.525 <td>-3.75e+04 <td> 1.92e+04 <tr> <th>C(county)[T.225] <td> 2641.2389 <td> 1.98e+04 <td> 0.134 <td> 0.894 <td>-3.61e+04 <td> 4.14e+04 <tr> <th>C(county)[T.226] <td>-8830.2891 <td> 6639.675 <td> -1.330 <td> 0.184 <td>-2.18e+04 <td> 4186.397 <tr> <th>C(county)[T.227] <td>-2.143e+04 <td> 1.09e+04 <td> -1.970 <td> 0.049 <td>-4.28e+04 <td> -102.683 <tr> <th>C(county)[T.228] <td> 3.233e+04 <td> 1.71e+04 <td> 1.894 <td> 0.058 <td>-1135.703 <td> 6.58e+04 <tr> <th>C(county)[T.229] <td>-1.428e+04 <td> 1.91e+04 <td> -0.748 <td> 0.454 <td>-5.17e+04 <td> 2.31e+04 <tr> <th>C(county)[T.230] <td> -1.28e+04 <td> 6264.355 <td> -2.043 <td> 0.041 <td>-2.51e+04 <td> -517.493 <tr> <th>C(county)[T.231] <td>-8271.2748 <td> 7245.759 <td> -1.142 <td> 0.254 <td>-2.25e+04 <td> 5933.602 <tr> <th>C(county)[T.232] <td>-2.299e+04 <td> 8519.159 <td> -2.699 <td> 0.007 <td>-3.97e+04 <td>-6289.960 <tr> <th>C(county)[T.233] <td>-1.285e+04 <td> 8491.101 <td> -1.513 <td> 0.130 <td>-2.95e+04 <td> 3796.614 <tr> <th>C(county)[T.234] <td>-1.735e+04 <td> 3.1e+04 <td> -0.559 <td> 0.576 <td>-7.82e+04 <td> 4.35e+04 <tr> <th>C(county)[T.235] <td>-1.766e+04 <td> 3.16e+04 <td> -0.559 <td> 0.576 <td>-7.96e+04 <td> 4.43e+04 <tr> <th>C(county)[T.236] <td>-1.217e+04 <td> 8349.230 <td> -1.457 <td> 0.145 <td>-2.85e+04 <td> 4200.746 <tr> <th>C(county)[T.237] <td>-1.141e+04 <td> 4505.618 <td> -2.533 <td> 0.011 <td>-2.02e+04 <td>-2581.176 <tr> <th>C(county)[T.238] <td>-1.613e+04 <td> 7139.990 <td> -2.258 <td> 0.024 <td>-3.01e+04 <td>-2127.974 <tr> <th>C(county)[T.239] <td>-2.712e+04 <td> 2.14e+04 <td> -1.266 <td> 0.206 <td>-6.91e+04 <td> 1.49e+04 <tr> <th>C(county)[T.240] <td> 6490.6376 <td> 9154.156 <td> 0.709 <td> 0.478 <td>-1.15e+04 <td> 2.44e+04 <tr> <th>C(county)[T.241] <td>-3359.7031 <td> 6189.659 <td> -0.543 <td> 0.587 <td>-1.55e+04 <td> 8774.753 <tr> <th>C(county)[T.242] <td>-1.613e+04 <td> 1.27e+04 <td> -1.272 <td> 0.203 <td> -4.1e+04 <td> 8724.775 <tr> <th>C(county)[T.243] <td>-1.788e+04 <td> 1.39e+04 <td> -1.286 <td> 0.199 <td>-4.51e+04 <td> 9383.449 <tr> <th>C(county)[T.244] <td>-3.071e+04 <td> 1.43e+04 <td> -2.150 <td> 0.032 <td>-5.87e+04 <td>-2703.321 <tr> <th>C(county)[T.245] <td>-8153.4624 <td> 1.35e+04 <td> -0.603 <td> 0.547 <td>-3.47e+04 <td> 1.84e+04 <tr> <th>C(county)[T.246] <td> 5281.9970 <td> 4036.138 <td> 1.309 <td> 0.191 <td>-2630.610 <td> 1.32e+04 <tr> <th>C(county)[T.247] <td>-9765.4698 <td> 5639.622 <td> -1.732 <td> 0.083 <td>-2.08e+04 <td> 1290.671 <tr> <th>C(county)[T.248] <td> 143.0204 <td> 8692.204 <td> 0.016 <td> 0.987 <td>-1.69e+04 <td> 1.72e+04 <tr> <th>C(county)[T.249] <td>-1.476e+04 <td> 3.35e+04 <td> -0.440 <td> 0.660 <td>-8.05e+04 <td> 5.1e+04 <tr> <th>C(county)[T.250] <td> 1.616e+04 <td> 1.05e+04 <td> 1.541 <td> 0.123 <td>-4398.223 <td> 3.67e+04 <tr> <th>C(county)[T.251] <td>-1.651e+04 <td> 9569.822 <td> -1.726 <td> 0.084 <td>-3.53e+04 <td> 2247.701 <tr> <th>C(county)[T.252] <td> -1.57e+04 <td> 2.01e+04 <td> -0.781 <td> 0.435 <td>-5.51e+04 <td> 2.37e+04 <tr> <th>C(county)[T.253] <td>-1.801e+04 <td> 1.58e+04 <td> -1.141 <td> 0.254 <td>-4.89e+04 <td> 1.29e+04 <tr> <th>C(county)[T.254] <td>-5819.5313 <td> 1.24e+04 <td> -0.470 <td> 0.638 <td>-3.01e+04 <td> 1.85e+04 <tr> <th>C(county)[T.256] <td>-9352.6145 <td> 1.31e+04 <td> -0.712 <td> 0.476 <td>-3.51e+04 <td> 1.64e+04 <tr> <th>C(county)[T.257] <td>-1.474e+04 <td> 4650.454 <td> -3.170 <td> 0.002 <td>-2.39e+04 <td>-5626.575 <tr> <th>C(county)[T.258] <td> -2.95e+04 <td> 1.86e+04 <td> -1.587 <td> 0.113 <td> -6.6e+04 <td> 6945.417 <tr> <th>C(county)[T.259] <td> 5.662e+04 <td> 1.78e+04 <td> 3.176 <td> 0.002 <td> 2.17e+04 <td> 9.16e+04 <tr> <th>C(county)[T.260] <td>-2.075e+04 <td> 1.42e+04 <td> -1.461 <td> 0.144 <td>-4.86e+04 <td> 7093.704 <tr> <th>C(county)[T.261] <td>-1.214e+04 <td> 9508.704 <td> -1.277 <td> 0.202 <td>-3.08e+04 <td> 6499.043 <tr> <th>C(county)[T.262] <td>-1.499e+04 <td> 3.16e+04 <td> -0.474 <td> 0.635 <td>-7.69e+04 <td> 4.7e+04 <tr> <th>C(county)[T.263] <td> 1.094e+04 <td> 1.25e+04 <td> 0.872 <td> 0.383 <td>-1.36e+04 <td> 3.55e+04 <tr> <th>C(county)[T.264] <td>-2479.7477 <td> 1.18e+04 <td> -0.210 <td> 0.834 <td>-2.57e+04 <td> 2.07e+04 <tr> <th>C(county)[T.265] <td>-2.203e+04 <td> 1.05e+04 <td> -2.105 <td> 0.035 <td>-4.25e+04 <td>-1517.160 <tr> <th>C(county)[T.266] <td> 6210.2882 <td> 3.35e+04 <td> 0.185 <td> 0.853 <td>-5.95e+04 <td> 7.19e+04 <tr> <th>C(county)[T.267] <td>-1.138e+04 <td> 2.33e+04 <td> -0.488 <td> 0.626 <td>-5.71e+04 <td> 3.44e+04 <tr> <th>C(county)[T.268] <td>-2.097e+04 <td> 1.51e+04 <td> -1.389 <td> 0.165 <td>-5.06e+04 <td> 8629.225 <tr> <th>C(county)[T.269] <td>-1.836e+04 <td> 7924.529 <td> -2.317 <td> 0.021 <td>-3.39e+04 <td>-2824.110 <tr> <th>C(county)[T.270] <td>-1.361e+04 <td> 1.72e+04 <td> -0.789 <td> 0.430 <td>-4.74e+04 <td> 2.02e+04 <tr> <th>C(county)[T.271] <td>-1.204e+04 <td> 1.55e+04 <td> -0.777 <td> 0.437 <td>-4.24e+04 <td> 1.84e+04 <tr> <th>C(county)[T.272] <td>-1.485e+04 <td> 8880.399 <td> -1.672 <td> 0.095 <td>-3.23e+04 <td> 2561.281 <tr> <th>C(county)[T.273] <td>-1.149e+04 <td> 2.63e+04 <td> -0.438 <td> 0.662 <td> -6.3e+04 <td> 4e+04 <tr> <th>C(county)[T.274] <td>-9891.3781 <td> 4694.196 <td> -2.107 <td> 0.035 <td>-1.91e+04 <td> -688.687 <tr> <th>C(county)[T.275] <td>-5173.7930 <td> 1.15e+04 <td> -0.449 <td> 0.653 <td>-2.77e+04 <td> 1.74e+04 <tr> <th>C(county)[T.276] <td>-1.966e+04 <td> 1.66e+04 <td> -1.182 <td> 0.237 <td>-5.22e+04 <td> 1.29e+04 <tr> <th>C(county)[T.277] <td>-3.402e+04 <td> 2.86e+04 <td> -1.188 <td> 0.235 <td>-9.01e+04 <td> 2.21e+04 <tr> <th>C(county)[T.278] <td> 2322.2439 <td> 1.9e+04 <td> 0.122 <td> 0.903 <td>-3.49e+04 <td> 3.95e+04 <tr> <th>C(county)[T.279] <td>-1.119e+04 <td> 1.84e+04 <td> -0.609 <td> 0.543 <td>-4.72e+04 <td> 2.48e+04 <tr> <th>C(county)[T.280] <td>-1.345e+04 <td> 6306.646 <td> -2.133 <td> 0.033 <td>-2.58e+04 <td>-1085.930 <tr> <th>C(county)[T.281] <td>-8403.4354 <td> 2.99e+04 <td> -0.281 <td> 0.778 <td>-6.69e+04 <td> 5.01e+04 <tr> <th>C(county)[T.282] <td>-3681.0429 <td> 1.2e+04 <td> -0.307 <td> 0.759 <td>-2.72e+04 <td> 1.99e+04 <tr> <th>C(county)[T.283] <td>-5339.8789 <td> 9936.127 <td> -0.537 <td> 0.591 <td>-2.48e+04 <td> 1.41e+04 <tr> <th>C(county)[T.284] <td>-1.452e+04 <td> 8179.287 <td> -1.775 <td> 0.076 <td>-3.06e+04 <td> 1519.240 <tr> <th>C(county)[T.285] <td> -3.43e+04 <td> 2.13e+04 <td> -1.613 <td> 0.107 <td> -7.6e+04 <td> 7382.687 <tr> <th>C(county)[T.286] <td> 7684.0660 <td> 1.16e+04 <td> 0.664 <td> 0.507 <td> -1.5e+04 <td> 3.04e+04 <tr> <th>C(county)[T.287] <td>-1.775e+04 <td> 5134.756 <td> -3.456 <td> 0.001 <td>-2.78e+04 <td>-7680.041 <tr> <th>C(county)[T.288] <td> 2038.4699 <td> 1.76e+04 <td> 0.116 <td> 0.908 <td>-3.26e+04 <td> 3.66e+04 <tr> <th>C(county)[T.289] <td>-8041.0146 <td> 1.11e+04 <td> -0.726 <td> 0.468 <td>-2.97e+04 <td> 1.37e+04 <tr> <th>C(county)[T.290] <td>-1.581e+04 <td> 7099.249 <td> -2.227 <td> 0.026 <td>-2.97e+04 <td>-1889.232 <tr> <th>C(county)[T.291] <td>-7663.1814 <td> 1.35e+04 <td> -0.567 <td> 0.571 <td>-3.42e+04 <td> 1.88e+04 <tr> <th>C(county)[T.292] <td>-1.567e+04 <td> 7319.153 <td> -2.141 <td> 0.032 <td> -3e+04 <td>-1323.652 <tr> <th>C(county)[T.293] <td>-5825.2555 <td> 1.34e+04 <td> -0.433 <td> 0.665 <td>-3.22e+04 <td> 2.05e+04 <tr> <th>C(county)[T.294] <td> 1.947e+04 <td> 9840.528 <td> 1.978 <td> 0.048 <td> 177.105 <td> 3.88e+04 <tr> <th>C(county)[T.295] <td> -1.75e+04 <td> 1.76e+04 <td> -0.996 <td> 0.319 <td> -5.2e+04 <td> 1.7e+04 <tr> <th>C(county)[T.296] <td>-1096.1249 <td> 1.8e+04 <td> -0.061 <td> 0.951 <td>-3.64e+04 <td> 3.42e+04 <tr> <th>C(county)[T.297] <td>-1.141e+04 <td> 4502.234 <td> -2.535 <td> 0.011 <td>-2.02e+04 <td>-2586.102 <tr> <th>C(county)[T.298] <td>-8732.4700 <td> 2.87e+04 <td> -0.304 <td> 0.761 <td> -6.5e+04 <td> 4.75e+04 <tr> <th>C(county)[T.299] <td> -1.74e+04 <td> 2.99e+04 <td> -0.583 <td> 0.560 <td>-7.59e+04 <td> 4.11e+04 <tr> <th>C(county)[T.300] <td>-1.986e+04 <td> 1.04e+04 <td> -1.907 <td> 0.057 <td>-4.03e+04 <td> 560.482 <tr> <th>C(county)[T.301] <td>-4.329e+04 <td> 3.24e+04 <td> -1.336 <td> 0.182 <td>-1.07e+05 <td> 2.03e+04 <tr> <th>C(county)[T.302] <td> 4581.0131 <td> 7593.047 <td> 0.603 <td> 0.546 <td>-1.03e+04 <td> 1.95e+04 <tr> <th>C(county)[T.303] <td>-1.484e+04 <td> 7473.001 <td> -1.985 <td> 0.047 <td>-2.95e+04 <td> -186.892 <tr> <th>C(county)[T.304] <td>-2.222e+04 <td> 8772.347 <td> -2.533 <td> 0.011 <td>-3.94e+04 <td>-5022.926 <tr> <th>C(county)[T.305] <td>-2514.2672 <td> 7217.330 <td> -0.348 <td> 0.728 <td>-1.67e+04 <td> 1.16e+04 <tr> <th>C(county)[T.306] <td>-2.336e+04 <td> 1.99e+04 <td> -1.174 <td> 0.240 <td>-6.24e+04 <td> 1.57e+04 <tr> <th>C(county)[T.307] <td>-1.116e+04 <td> 9796.527 <td> -1.139 <td> 0.255 <td>-3.04e+04 <td> 8045.695 <tr> <th>C(county)[T.308] <td> 8.973e+04 <td> 1.66e+04 <td> 5.411 <td> 0.000 <td> 5.72e+04 <td> 1.22e+05 <tr> <th>C(county)[T.309] <td>-1.179e+04 <td> 5120.504 <td> -2.302 <td> 0.021 <td>-2.18e+04 <td>-1747.726 <tr> <th>C(county)[T.310] <td>-1.268e+04 <td> 3.35e+04 <td> -0.378 <td> 0.705 <td>-7.84e+04 <td> 5.31e+04 <tr> <th>C(county)[T.311] <td>-1.624e+04 <td> 1.01e+04 <td> -1.611 <td> 0.107 <td> -3.6e+04 <td> 3524.476 <tr> <th>C(county)[T.312] <td>-9191.1488 <td> 9873.286 <td> -0.931 <td> 0.352 <td>-2.85e+04 <td> 1.02e+04 <tr> <th>C(county)[T.313] <td>-1.765e+04 <td> 4.28e+04 <td> -0.412 <td> 0.680 <td>-1.02e+05 <td> 6.63e+04 <tr> <th>C(county)[T.314] <td>-1.793e+04 <td> 7170.454 <td> -2.501 <td> 0.012 <td> -3.2e+04 <td>-3875.671 <tr> <th>C(county)[T.315] <td> 879.4379 <td> 1.04e+04 <td> 0.084 <td> 0.933 <td>-1.96e+04 <td> 2.13e+04 <tr> <th>C(county)[T.316] <td>-5807.9640 <td> 6758.678 <td> -0.859 <td> 0.390 <td>-1.91e+04 <td> 7442.020 <tr> <th>C(county)[T.317] <td> 1.794e+04 <td> 9335.924 <td> 1.922 <td> 0.055 <td> -362.354 <td> 3.62e+04 <tr> <th>C(county)[T.318] <td>-4980.2142 <td> 8582.095 <td> -0.580 <td> 0.562 <td>-2.18e+04 <td> 1.18e+04 <tr> <th>C(county)[T.319] <td> 1051.3237 <td> 1.42e+04 <td> 0.074 <td> 0.941 <td>-2.68e+04 <td> 2.89e+04 <tr> <th>C(county)[T.320] <td>-1.431e+04 <td> 1.5e+04 <td> -0.951 <td> 0.341 <td>-4.38e+04 <td> 1.52e+04 <tr> <th>C(county)[T.321] <td>-1.684e+04 <td> 6968.208 <td> -2.416 <td> 0.016 <td>-3.05e+04 <td>-3176.799 <tr> <th>C(county)[T.322] <td> -406.6903 <td> 6523.846 <td> -0.062 <td> 0.950 <td>-1.32e+04 <td> 1.24e+04 <tr> <th>C(county)[T.323] <td>-1.853e+04 <td> 5726.625 <td> -3.236 <td> 0.001 <td>-2.98e+04 <td>-7302.079 <tr> <th>C(county)[T.324] <td>-2501.1256 <td> 7866.013 <td> -0.318 <td> 0.751 <td>-1.79e+04 <td> 1.29e+04 <tr> <th>C(county)[T.325] <td>-1.951e+04 <td> 2.24e+04 <td> -0.873 <td> 0.383 <td>-6.33e+04 <td> 2.43e+04 <tr> <th>has_college <td> 1.325e+04 <td> 742.630 <td> 17.843 <td> 0.000 <td> 1.18e+04 <td> 1.47e+04 <tr> <th>female <td>-8657.2875 <td> 609.011 <td> -14.215 <td> 0.000 <td>-9851.217 <td>-7463.358 </table> <table> <tr> <th>Omnibus: <td>2414.039 <th> Durbin-Watson: <td> 1.981 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>22245.534 <tr> <th>Skew: <td> 1.945 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td>12.242 <th> Cond. No. <td> 198. </table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div> </div> </section> <section id=Exercise-15 > <h3 id=Exercise-15 >Exercise 15<a class=headerlink  href="#Exercise-15" title="Permalink to this heading">¶</a></h3> <p>If you stopped matching after the second iteration (Iteration 1) back in Exercise 10, you may be wondering if that was a good choice! Let’s check by restricting our attention to ONLY exact matches (<code class="docutils literal notranslate"><span class=pre >iteration</span> <span class=pre >=</span> <span class=pre >0</span></code>). Run that match.</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[37]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >model2</span> <span class=o >=</span> <span class=n >dame_flame</span><span class=o >.</span><span class=n >matching</span><span class=o >.</span><span class=n >DAME</span><span class=p >(</span>
    <span class=n >repeats</span><span class=o >=</span><span class=kc >False</span><span class=p >,</span> <span class=n >verbose</span><span class=o >=</span><span class=mi >3</span><span class=p >,</span> <span class=n >want_pe</span><span class=o >=</span><span class=kc >True</span><span class=p >,</span> <span class=n >early_stop_iterations</span><span class=o >=</span><span class=mi >0</span>
<span class=p >)</span>
<span class=n >model2</span><span class=o >.</span><span class=n >fit</span><span class=p >(</span>
    <span class=n >for_matching</span><span class=p >,</span>
    <span class=n >treatment_column_name</span><span class=o >=</span><span class=s2 >"has_college"</span><span class=p >,</span>
    <span class=n >outcome_column_name</span><span class=o >=</span><span class=s2 >"annual_earnings"</span><span class=p >,</span>
<span class=p >)</span>
<span class=n >result2</span> <span class=o >=</span> <span class=n >model2</span><span class=o >.</span><span class=n >predict</span><span class=p >(</span><span class=n >for_matching</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
Completed iteration 0 of matching
        Number of matched groups formed in total:  370
        Unmatched treated units:  644 out of a total of  1150 treated units
        Unmatched control units:  3187 out of a total of  4365 control units
        Number of matches made this iteration:  1684
        Number of matches made so far:  1684
        Covariates dropped so far:  set()
        Predictive error of covariate set used to match:  1199312680.0957854
1684 units matched. We stopped after iteration 0
</pre></div></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[38]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >matched_data2</span> <span class=o >=</span> <span class=n >get_dataframe</span><span class=p >(</span><span class=n >model2</span><span class=p >,</span> <span class=n >result2</span><span class=p >)</span>
</pre></div> </div> </div> </section> <section id=Exercise-16 > <h3 id=Exercise-16 >Exercise 16<a class=headerlink  href="#Exercise-16" title="Permalink to this heading">¶</a></h3> <p>Now use a weighted linear regression on your matched data to regress annual earnings on <em>just</em> having a college eduction. Is that different from what you had when you allowed more low quality matches?</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[39]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >smf</span><span class=o >.</span><span class=n >wls</span><span class=p >(</span>
    <span class=s2 >"annual_earnings ~ has_college"</span><span class=p >,</span> <span class=n >matched_data2</span><span class=p >,</span> <span class=n >weights</span><span class=o >=</span><span class=n >matched_data2</span><span class=p >[</span><span class=s2 >"weights"</span><span class=p >]</span>
<span class=p >)</span><span class=o >.</span><span class=n >fit</span><span class=p >()</span><span class=o >.</span><span class=n >summary</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[39]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table> <caption>WLS Regression Results</caption> <tr> <th>Dep. Variable: <td>annual_earnings <th> R-squared: <td> 0.049 <tr> <th>Model: <td>WLS <th> Adj. R-squared: <td> 0.048 <tr> <th>Method: <td>Least Squares <th> F-statistic: <td> 86.65 <tr> <th>Date: <td>Sat, 04 Mar 2023 <th> Prob (F-statistic): <td>3.92e-20 <tr> <th>Time: <td>13:59:42 <th> Log-Likelihood: <td> -19512. <tr> <th>No. Observations: <td> 1684 <th> AIC: <td>3.903e+04 <tr> <th>Df Residuals: <td> 1682 <th> BIC: <td>3.904e+04 <tr> <th>Df Model: <td> 1 <th> <td> <tr> <th>Covariance Type: <td>nonrobust <th> <td> </table> <table> <tr> <td> <th>coef <th>std err <th>t <th>P&gt;|t| <th>[0.025 <th>0.975] <tr> <th>Intercept <td> 3.914e+04 <td> 664.386 <td> 58.907 <td> 0.000 <td> 3.78e+04 <td> 4.04e+04 <tr> <th>has_college <td> 1.128e+04 <td> 1212.039 <td> 9.308 <td> 0.000 <td> 8904.805 <td> 1.37e+04 </table> <table> <tr> <th>Omnibus: <td>855.250 <th> Durbin-Watson: <td> 2.037 <tr> <th>Prob(Omnibus): <td> 0.000 <th> Jarque-Bera (JB): <td>6653.000 <tr> <th>Skew: <td> 2.256 <th> Prob(JB): <td> 0.00 <tr> <th>Kurtosis: <td>11.629 <th> Cond. No. <td> 2.42 </table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div> </div> </section> </section> <section id=Other-Forms-of-Matching > <h2 id=Other-Forms-of-Matching >Other Forms of Matching<a class=headerlink  href="#Other-Forms-of-Matching" title="Permalink to this heading">¶</a></h2> <p>OK, hopefully this gives you a taste of matching! There are, of course, <em>many</em> other permutations to be aware of though.</p> <ul class=simple > <li><p>Matching with replacement. In this exercise, we set <code class="docutils literal notranslate"><span class=pre >repeat=False</span></code>, so each observation could only end up in our final dataset once. However, if we use <code class="docutils literal notranslate"><span class=pre >repeat=True</span></code>, if an untreated observation is the closest observation to multiple treated observations, it may get put in the dataset multiple times. We can still use this dataset in <em>almost</em> the same way, though, except we have to make use of weights so that if an observation appears, say, twice, each observation has a weight that’s 1/2 the weight of an observation only appearing once.</p> <li><p>Matching with continuous variables: DAME is used for exact matching, but if you have lots of continuous variables, you can also match on those. In fact, the Almost Exact Matching Lab also has a library called <a class="reference external" href="https://almost-matching-exactly.github.io/MALTS/">MALTS</a> that will do matching with continuous variables. That package does something <em>like</em> Mahalanobis Distance matching, but ulike Mahalanobis, which calculates the distance between observations in terms of the difference in all the matching variables normalized by each matching variable’s standard deviation, MALTS does something much more clever. (Here’s <a class="reference external" href="https://arxiv.org/abs/1811.07415">the paper</a> describing the technique if you want all the details). Basically, it figures out how well each matching variable predicts our outcome <span class="math notranslate nohighlight">\(Y\)</span>, then weights the different variables by their predictive power instead of just normalizing by something arbitrary like their standard deviation. As a result, final matches will prioritize matching more closely on variables that are outcome-relevant. In addition, when it sees a categorical variable, it recognizes that and only pairs observations when they are an exact match on that categorical variable.</p> <li><p>If you’re dataset is huge, use <code class="docutils literal notranslate"><span class=pre >FLAME</span></code>: this dataset is small, but if you have lots of observations and lots of matching variable, the computational complexity of this task explodes, so the AEML created FLAME, which works with millions of observations at only a small cost to match quality.</p> </ul> </section> <section id="Absolutely-positively-need-the-solutions?"> <h2 id="Absolutely-positively-need-the-solutions?">Absolutely positively need the solutions?<a class=headerlink  href="#Absolutely-positively-need-the-solutions?" title="Permalink to this heading">¶</a></h2> <p><em>Don’t use this link until you’ve really, really spent time struggling with your code!</em> Doing so only results in you cheating yourself.</p> <p><a class="reference internal" href="../solutions_warning.html"><span class=doc >Link</span></a></p> </section> </section> </article> </div> </div> </main> </div> <footer class=md-footer > <div class=md-footer-nav > <nav class="md-footer-nav__inner md-grid"> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright > <div class=md-footer-copyright__highlight > &#169; Copyright 2022, Nick Eubank. </div> Created using <a href="http://www.sphinx-doc.org/">Sphinx</a> 5.0.2. and <a href="https://github.com/bashtage/sphinx-material/">Material for Sphinx</a> </div> </div> </div> </footer> <script src="../_static/javascripts/application.js"></script> <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>